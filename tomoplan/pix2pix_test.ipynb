{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvEnc(nn.Module):\n",
    "\tdef __init__(self, in_chan, out_chan, normalize=True, stride=2):\n",
    "\t\tsuper(ConvEnc, self).__init__()\n",
    "\n",
    "\t\tconv = nn.Conv2d(in_chan, out_chan, 4, stride=stride, padding=1)\n",
    "\t\tnn.init.normal_(conv.weight, 0, 0.02)\n",
    "\t\tmodel = [conv]\n",
    "\n",
    "\t\tif normalize:\n",
    "\t\t\tnorm = nn.InstanceNorm2d(out_chan)\n",
    "\t\t\tmodel += [norm]\n",
    "\n",
    "\t\tmodel += [nn.LeakyReLU(0.2)]\n",
    "\t\tself.model = nn.Sequential(*model)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvDec(nn.Module):\n",
    "\tdef __init__(self, in_chan, out_chan, dropout=False):\n",
    "\t\tsuper(ConvDec, self).__init__()\n",
    "\n",
    "\t\tconv = nn.ConvTranspose2d(in_chan, out_chan, 4, stride=2, padding=1)\n",
    "\t\tnn.init.normal_(conv.weight, 0, 0.02)\n",
    "\t\tmodel = [conv]\n",
    "\n",
    "\t\tnorm = nn.InstanceNorm2d(out_chan)\n",
    "\t\tmodel += [norm]\n",
    "\n",
    "\t\tif dropout:\n",
    "\t\t\tmodel += [nn.Dropout(0.5)]\n",
    "\n",
    "\t\tmodel += [nn.ReLU()]\n",
    "\t\tself.model = nn.Sequential(*model)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\treturn self.model(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Generator, self).__init__()\n",
    "\t\tself.enc1 = ConvEnc(3, 64, normalize=False)\n",
    "\t\tself.enc2 = ConvEnc(64, 128)\n",
    "\t\tself.enc3 = ConvEnc(128, 256)\n",
    "\t\tself.enc4 = ConvEnc(256, 512)\n",
    "\t\tself.enc5 = ConvEnc(512, 512)\n",
    "\t\tself.enc6 = ConvEnc(512, 512)\n",
    "\t\tself.enc7 = ConvEnc(512, 512)\n",
    "\t\tself.bott = ConvEnc(512, 512, normalize=False)\n",
    "\n",
    "\t\tself.dec7 = ConvDec(512, 512, dropout=True)\n",
    "\t\tself.dec6 = ConvDec(1024, 512, dropout=True)\n",
    "\t\tself.dec5 = ConvDec(1024, 512, dropout=True)\n",
    "\t\tself.dec4 = ConvDec(1024, 512)\n",
    "\t\tself.dec3 = ConvDec(1024, 256)\n",
    "\t\tself.dec2 = ConvDec(512, 128)\n",
    "\t\tself.dec1 = ConvDec(256, 64)\n",
    "\n",
    "\t\tself.conv = nn.ConvTranspose2d(128, 3, 4, stride=2, padding=1)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tenc1 = self.enc1(x)\n",
    "\t\tenc2 = self.enc2(enc1)\n",
    "\t\tenc3 = self.enc3(enc2)\n",
    "\t\tenc4 = self.enc4(enc3)\n",
    "\t\tenc5 = self.enc5(enc4)\n",
    "\t\tenc6 = self.enc6(enc5)\n",
    "\t\tenc7 = self.enc7(enc6)\n",
    "\n",
    "\t\tbott = self.bott(enc7)\n",
    "\n",
    "\t\tdec7 = self.dec7(bott)\n",
    "\t\tdec6 = self.dec6(torch.cat((dec7, enc7), 1))\n",
    "\t\tdec5 = self.dec5(torch.cat((dec6, enc6), 1))\n",
    "\t\tdec4 = self.dec4(torch.cat((dec5, enc5), 1))\n",
    "\t\tdec3 = self.dec3(torch.cat((dec4, enc4), 1))\n",
    "\t\tdec2 = self.dec2(torch.cat((dec3, enc3), 1))\n",
    "\t\tdec1 = self.dec1(torch.cat((dec2, enc2), 1))\n",
    "\t\tconv = self.conv(torch.cat((dec1, enc1), 1))\n",
    "\n",
    "\t\treturn torch.tanh(conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(Discriminator, self).__init__()\n",
    "\t\tself.conv1 = ConvEnc(6, 64, normalize=False)\n",
    "\t\tself.conv2 = ConvEnc(64, 128)\n",
    "\t\tself.conv3 = ConvEnc(128, 256)\n",
    "\t\tself.conv4 = ConvEnc(256, 512, stride=1)\n",
    "\t\tself.conv5 = nn.Conv2d(512, 1, 4, padding=1)\n",
    "\n",
    "\tdef forward(self, a, b):\n",
    "\t\tx = torch.cat((a, b), 1)\n",
    "\t\tx = self.conv1(x)\n",
    "\t\tx = self.conv2(x)\n",
    "\t\tx = self.conv3(x)\n",
    "\t\tx = self.conv4(x)\n",
    "\t\tx = self.conv5(x)\n",
    "\t\treturn x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(G, D, optim_G, optim_D, train_loader, val_loader, epoch):\n",
    "\tG.train()\n",
    "\tD.train()\n",
    "\n",
    "\tG_loss, D_loss = [], []\n",
    "\tgan_loss = F.binary_cross_entropy_with_logits\n",
    "\n",
    "\tfor i, (a, b) in enumerate(train_loader):\n",
    "\n",
    "\t\ta = a.to(device)\n",
    "\t\tb = b.to(device)\n",
    "\n",
    "\t\treal = torch.ones((a.size(0), 1, 30, 30)).to(device)\n",
    "\t\tfake = torch.zeros((a.size(0), 1, 30, 30)).to(device)\n",
    "\n",
    "\t\t# update generator\n",
    "\n",
    "\t\toptim_G.zero_grad()\n",
    "\n",
    "\t\tfake_b = G(a)\n",
    "\t\tpred = D(a, fake_b)\n",
    "\n",
    "\t\tloss_G = gan_loss(pred, real) + F.l1_loss(b, fake_b) * 100\n",
    "\n",
    "\t\tloss_G.backward()\n",
    "\t\toptim_G.step()\n",
    "\n",
    "\t\t# update discriminator\n",
    "\n",
    "\t\toptim_D.zero_grad()\n",
    "\n",
    "\t\tpred_real = D(a, b)\n",
    "\t\tloss_real = gan_loss(pred_real, real)\n",
    "\n",
    "\t\tpred_fake = D(a, fake_b.detach())\n",
    "\t\tloss_fake = gan_loss(pred_fake, fake)\n",
    "\n",
    "\t\tloss_D = (loss_real + loss_fake) * 0.5\n",
    "\n",
    "\t\tloss_D.backward()\n",
    "\t\toptim_D.step()\n",
    "\n",
    "\t\tG_loss.append(loss_G.item())\n",
    "\t\tD_loss.append(loss_D.item())\n",
    "\n",
    "\t\tif (i+1) % 10 == 0:\n",
    "\t\t\tg_mean = np.mean(G_loss[-10:])\n",
    "\t\t\td_mean = np.mean(D_loss[-10:])\n",
    "\t\t\tprint(\"\\rEpoch %d [%d/%d] [G loss: %f] [D loss: %f]\" %\n",
    "\t\t\t\t\t(epoch, i, len(train_loader), g_mean, d_mean))\n",
    "\n",
    "\t\titers = epoch * len(train_loader) + i\n",
    "\t\tif iters % 500 == 0:\n",
    "\t\t\timgs = []\n",
    "\t\t\tfor j, (a, b) in enumerate(val_loader):\n",
    "\t\t\t\ta = a.to(device)\n",
    "\t\t\t\tb = b.to(device)\n",
    "\t\t\t\twith torch.no_grad():\n",
    "\t\t\t\t\tfake_b = G(a)\n",
    "\t\t\t\timgs += [a[0], fake_b[0], b[0]]\n",
    "\t\t\t\tif j == 2:\n",
    "\t\t\t\t\tbreak\n",
    "\t\t\timgs = torch.stack(imgs).detach().cpu()\n",
    "\t\t\tsave_image(imgs, \"images/%s.png\"%iters, nrow=3, normalize=True)\n",
    "\n",
    "\treturn np.mean(G_loss), np.mean(D_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(file):\n",
    "\timg = Image.open(file)\n",
    "\timg_b = img.crop((0,0,256,256))\n",
    "\timg_a = img.crop((256,0,512,256))\n",
    "\tT = transforms.Compose([\n",
    "\t\ttransforms.ToTensor(),\n",
    "\t\ttransforms.Normalize((0.5, 0.5, 0.5),\n",
    "\t\t                     (0.5, 0.5, 0.5)),\n",
    "\t])\n",
    "\treturn T(img_a), T(img_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "\tdef __init__(self, root, mode):\n",
    "\t\tself.files = glob.glob('%s/%s/*'%(root, mode))\n",
    "\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.files)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\ta, b = load_image(self.files[idx])\n",
    "\t\treturn a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "\t# if len(sys.argv) != 2:\n",
    "\t# \tprint('usage: pix2pix.py <dataset>')\n",
    "\t# \treturn 1\n",
    "\n",
    "\troot = sys.argv[1]\n",
    "\tos.makedirs(\"images/\", exist_ok=True)\n",
    "\n",
    "\tG = Generator()\n",
    "\tD = Discriminator()\n",
    "\n",
    "\tepoch0 = -1\n",
    "\tif os.path.exists('model.pt'):\n",
    "\t\tstate = torch.load('model.pt', map_location='cpu')\n",
    "\t\tG.load_state_dict(state['G'])\n",
    "\t\tD.load_state_dict(state['D'])\n",
    "\t\tepoch0 = state['epoch']\n",
    "\n",
    "\toptim_G = optim.Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\toptim_D = optim.Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "\ttrain_loader = DataLoader(dataset(root, \"train\"), 1, shuffle=True)\n",
    "\tval_loader = DataLoader(dataset(root, \"val\"), 1, shuffle=True)\n",
    "\n",
    "\tfor epoch in range(epoch0+1, 100):\n",
    "\t\tG_loss, D_loss = train(G, D, optim_G, optim_D, train_loader, val_loader, epoch)\n",
    "\n",
    "\t\tprint('\\nG_loss: %.4f\tD_loss: %.4f\\n'%(G_loss, D_loss))\n",
    "\n",
    "\t\twith open('log.txt', 'a') as f:\n",
    "\t\t\tprint('%d\\t%.4f\\t%.4f'%(epoch, G_loss, D_loss), file=f)\n",
    "\n",
    "\t\ttorch.save({\n",
    "\t\t\t'epoch': epoch,\n",
    "\t\t\t'G': G.state_dict(),\n",
    "\t\t\t'D': D.state_dict(),\n",
    "\t\t\t}, \"model.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/xiaogangyang/pyprojects/tomoplan/tomoplan/pix2pix_test.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/xiaogangyang/pyprojects/tomoplan/tomoplan/pix2pix_test.ipynb#ch0000010?line=0'>1</a>\u001b[0m main()\n",
      "\u001b[1;32m/Users/xiaogangyang/pyprojects/tomoplan/tomoplan/pix2pix_test.ipynb Cell 11\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaogangyang/pyprojects/tomoplan/tomoplan/pix2pix_test.ipynb#ch0000010?line=19'>20</a>\u001b[0m optim_G \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(G\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.0002\u001b[39m, betas\u001b[39m=\u001b[39m(\u001b[39m0.5\u001b[39m, \u001b[39m0.999\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaogangyang/pyprojects/tomoplan/tomoplan/pix2pix_test.ipynb#ch0000010?line=20'>21</a>\u001b[0m optim_D \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(D\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.0002\u001b[39m, betas\u001b[39m=\u001b[39m(\u001b[39m0.5\u001b[39m, \u001b[39m0.999\u001b[39m))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/xiaogangyang/pyprojects/tomoplan/tomoplan/pix2pix_test.ipynb#ch0000010?line=22'>23</a>\u001b[0m train_loader \u001b[39m=\u001b[39m DataLoader(dataset(root, \u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m), \u001b[39m1\u001b[39;49m, shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaogangyang/pyprojects/tomoplan/tomoplan/pix2pix_test.ipynb#ch0000010?line=23'>24</a>\u001b[0m val_loader \u001b[39m=\u001b[39m DataLoader(dataset(root, \u001b[39m\"\u001b[39m\u001b[39mval\u001b[39m\u001b[39m\"\u001b[39m), \u001b[39m1\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/xiaogangyang/pyprojects/tomoplan/tomoplan/pix2pix_test.ipynb#ch0000010?line=25'>26</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epoch0\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m100\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/dataloader.py:277\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# map-style\u001b[39;00m\n\u001b[1;32m    276\u001b[0m     \u001b[39mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 277\u001b[0m         sampler \u001b[39m=\u001b[39m RandomSampler(dataset, generator\u001b[39m=\u001b[39;49mgenerator)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m         sampler \u001b[39m=\u001b[39m SequentialSampler(dataset)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/utils/data/sampler.py:97\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mreplacement should be a boolean value, but got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mreplacement=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplacement))\n\u001b[1;32m     96\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples, \u001b[39mint\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m---> 97\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnum_samples should be a positive integer \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mvalue, but got num_samples=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_samples))\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cad7b6e3b95476d8958f3ee39b0f484928100374557f3c8c24193fd13a9f03ad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
