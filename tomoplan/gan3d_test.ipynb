{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tomopy \n",
    "import matplotlib.pyplot as plt\n",
    "from tomoplan.gan3d import GAN3d\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 32.000046\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "data = tomopy.shepp3d()\n",
    "ang = tomopy.angles(181)\n",
    "prj = tomopy.project(data, ang, pad=False)\n",
    "train_input = prj[0]\n",
    "plt.imshow(train_input)\n",
    "plt.show()\n",
    "print(train_input.min(), train_input.max())\n",
    "print(data.min(), data.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_output = np.swapaxes(data, 0, 1)\n",
    "plt.imshow(train_output[64,:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-08 14:02:02.732953: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-08-08 14:02:03.116133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46152 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:65:00.0, compute capability: 8.6\n",
      "2022-08-08 14:02:06.604673: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8204\n",
      "2022-08-08 14:02:08.460930: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: G_loss is 5.1431989669799805 and D_loss is 1.3758819103240967\n",
      "Iteration 2: G_loss is 2.6219258308410645 and D_loss is 1.3620946407318115\n",
      "Iteration 3: G_loss is 2.2200794219970703 and D_loss is 1.3507602214813232\n",
      "Iteration 4: G_loss is 2.0926575660705566 and D_loss is 1.3388009071350098\n",
      "Iteration 5: G_loss is 1.9166450500488281 and D_loss is 1.3415663242340088\n",
      "Iteration 6: G_loss is 1.802001714706421 and D_loss is 1.4202224016189575\n",
      "Iteration 7: G_loss is 1.7052743434906006 and D_loss is 1.324178695678711\n",
      "Iteration 8: G_loss is 1.6229901313781738 and D_loss is 1.3435930013656616\n",
      "Iteration 9: G_loss is 1.5599843263626099 and D_loss is 1.4140993356704712\n",
      "Iteration 10: G_loss is 1.5285372734069824 and D_loss is 1.3324158191680908\n",
      "Iteration 11: G_loss is 1.500539779663086 and D_loss is 1.2439059019088745\n",
      "Iteration 12: G_loss is 1.4916651248931885 and D_loss is 1.2918353080749512\n",
      "Iteration 13: G_loss is 1.4821515083312988 and D_loss is 1.374443769454956\n",
      "Iteration 14: G_loss is 1.4776227474212646 and D_loss is 1.215458631515503\n",
      "Iteration 15: G_loss is 1.460639476776123 and D_loss is 1.1797220706939697\n",
      "Iteration 16: G_loss is 1.4660297632217407 and D_loss is 1.1575067043304443\n",
      "Iteration 17: G_loss is 1.4685965776443481 and D_loss is 1.1341246366500854\n",
      "Iteration 18: G_loss is 1.4646416902542114 and D_loss is 1.2313430309295654\n",
      "Iteration 19: G_loss is 1.4622597694396973 and D_loss is 1.1100395917892456\n",
      "Iteration 20: G_loss is 1.4578492641448975 and D_loss is 1.1356449127197266\n",
      "Iteration 21: G_loss is 1.4625804424285889 and D_loss is 1.087219476699829\n",
      "Iteration 22: G_loss is 1.4557276964187622 and D_loss is 1.0474445819854736\n",
      "Iteration 23: G_loss is 1.463087558746338 and D_loss is 0.9887485504150391\n",
      "Iteration 24: G_loss is 1.4477872848510742 and D_loss is 1.0245769023895264\n",
      "Iteration 25: G_loss is 1.4595144987106323 and D_loss is 0.896259605884552\n",
      "Iteration 26: G_loss is 1.4559781551361084 and D_loss is 0.858677864074707\n",
      "Iteration 27: G_loss is 1.4491312503814697 and D_loss is 0.882774829864502\n",
      "Iteration 28: G_loss is 1.4525151252746582 and D_loss is 0.8830189108848572\n",
      "Iteration 29: G_loss is 1.4525399208068848 and D_loss is 0.8438110947608948\n",
      "Iteration 30: G_loss is 1.4445545673370361 and D_loss is 0.8429197072982788\n",
      "Iteration 31: G_loss is 1.4380393028259277 and D_loss is 0.8536840677261353\n",
      "Iteration 32: G_loss is 1.429166555404663 and D_loss is 0.7746221423149109\n",
      "Iteration 33: G_loss is 1.3987315893173218 and D_loss is 0.8599337935447693\n",
      "Iteration 34: G_loss is 1.399376392364502 and D_loss is 0.839056134223938\n",
      "Iteration 35: G_loss is 1.3763996362686157 and D_loss is 0.8319498896598816\n",
      "Iteration 36: G_loss is 1.3318541049957275 and D_loss is 0.9038981795310974\n",
      "Iteration 37: G_loss is 1.3493057489395142 and D_loss is 0.8528600931167603\n",
      "Iteration 38: G_loss is 1.3463298082351685 and D_loss is 0.8357374668121338\n",
      "Iteration 39: G_loss is 1.2496984004974365 and D_loss is 0.9665598273277283\n",
      "Iteration 40: G_loss is 1.3214061260223389 and D_loss is 0.8622258305549622\n",
      "Iteration 41: G_loss is 1.2735294103622437 and D_loss is 0.9506988525390625\n",
      "Iteration 42: G_loss is 1.216888427734375 and D_loss is 1.0362108945846558\n",
      "Iteration 43: G_loss is 1.1698238849639893 and D_loss is 1.1186012029647827\n",
      "Iteration 44: G_loss is 1.2175778150558472 and D_loss is 1.037192463874817\n",
      "Iteration 45: G_loss is 1.3089587688446045 and D_loss is 0.9150634407997131\n",
      "Iteration 46: G_loss is 1.3070639371871948 and D_loss is 0.958240270614624\n",
      "Iteration 47: G_loss is 1.392663836479187 and D_loss is 0.8697667121887207\n",
      "Iteration 48: G_loss is 1.345798134803772 and D_loss is 0.9149937033653259\n",
      "Iteration 49: G_loss is 1.318143606185913 and D_loss is 0.9712918996810913\n",
      "Iteration 50: G_loss is 1.4882664680480957 and D_loss is 0.7216365337371826\n",
      "Iteration 51: G_loss is 1.4869232177734375 and D_loss is 0.7097325325012207\n",
      "Iteration 52: G_loss is 1.5890376567840576 and D_loss is 0.6257936954498291\n",
      "Iteration 53: G_loss is 1.589672327041626 and D_loss is 0.6575074195861816\n",
      "Iteration 54: G_loss is 1.595133662223816 and D_loss is 0.6576881408691406\n",
      "Iteration 55: G_loss is 1.4718642234802246 and D_loss is 0.6987529993057251\n",
      "Iteration 56: G_loss is 1.3994781970977783 and D_loss is 0.769659698009491\n",
      "Iteration 57: G_loss is 1.5807645320892334 and D_loss is 0.6098502278327942\n",
      "Iteration 58: G_loss is 1.6869466304779053 and D_loss is 0.6250307559967041\n",
      "Iteration 59: G_loss is 1.6482625007629395 and D_loss is 0.5870460271835327\n",
      "Iteration 60: G_loss is 1.5740571022033691 and D_loss is 0.6739917993545532\n",
      "Iteration 61: G_loss is 1.588232159614563 and D_loss is 0.6310470700263977\n",
      "Iteration 62: G_loss is 1.5843768119812012 and D_loss is 0.6355738043785095\n",
      "Iteration 63: G_loss is 1.6712706089019775 and D_loss is 0.5738686323165894\n",
      "Iteration 64: G_loss is 1.5459682941436768 and D_loss is 0.6613141298294067\n",
      "Iteration 65: G_loss is 1.5883984565734863 and D_loss is 0.6349022388458252\n",
      "Iteration 66: G_loss is 1.544901967048645 and D_loss is 0.641849160194397\n",
      "Iteration 67: G_loss is 1.5185424089431763 and D_loss is 0.677712082862854\n",
      "Iteration 68: G_loss is 1.5165228843688965 and D_loss is 0.6539315581321716\n",
      "Iteration 69: G_loss is 1.52398681640625 and D_loss is 0.6400879621505737\n",
      "Iteration 70: G_loss is 1.4799158573150635 and D_loss is 0.6880142092704773\n",
      "Iteration 71: G_loss is 1.4841078519821167 and D_loss is 0.6743867993354797\n",
      "Iteration 72: G_loss is 1.4990947246551514 and D_loss is 0.6634834408760071\n",
      "Iteration 73: G_loss is 1.469267725944519 and D_loss is 0.6825516819953918\n",
      "Iteration 74: G_loss is 1.4843049049377441 and D_loss is 0.6956499218940735\n",
      "Iteration 75: G_loss is 1.4858765602111816 and D_loss is 0.6647818088531494\n",
      "Iteration 76: G_loss is 1.5033187866210938 and D_loss is 0.6445725560188293\n",
      "Iteration 77: G_loss is 1.466984510421753 and D_loss is 0.6757280826568604\n",
      "Iteration 78: G_loss is 1.431913137435913 and D_loss is 0.7161808013916016\n",
      "Iteration 79: G_loss is 1.4556269645690918 and D_loss is 0.6939419507980347\n",
      "Iteration 80: G_loss is 1.4463071823120117 and D_loss is 0.6998165845870972\n",
      "Iteration 81: G_loss is 1.4433060884475708 and D_loss is 0.6965420842170715\n",
      "Iteration 82: G_loss is 1.4578999280929565 and D_loss is 0.6777147650718689\n",
      "Iteration 83: G_loss is 1.4385958909988403 and D_loss is 0.7008176445960999\n",
      "Iteration 84: G_loss is 1.437013864517212 and D_loss is 0.7011640667915344\n",
      "Iteration 85: G_loss is 1.4427125453948975 and D_loss is 0.7165552377700806\n",
      "Iteration 86: G_loss is 1.4388607740402222 and D_loss is 0.7012243866920471\n",
      "Iteration 87: G_loss is 1.4296536445617676 and D_loss is 0.7291059494018555\n",
      "Iteration 88: G_loss is 1.4520316123962402 and D_loss is 0.6807941198348999\n",
      "Iteration 89: G_loss is 1.414363145828247 and D_loss is 0.727428138256073\n",
      "Iteration 90: G_loss is 1.433870792388916 and D_loss is 0.698462963104248\n",
      "Iteration 91: G_loss is 1.4716987609863281 and D_loss is 0.6791025996208191\n",
      "Iteration 92: G_loss is 1.5149744749069214 and D_loss is 0.6379103660583496\n",
      "Iteration 93: G_loss is 1.5716208219528198 and D_loss is 0.6229737997055054\n",
      "Iteration 94: G_loss is 1.5738279819488525 and D_loss is 0.588481605052948\n",
      "Iteration 95: G_loss is 1.639723777770996 and D_loss is 0.5570034384727478\n",
      "Iteration 96: G_loss is 1.6264811754226685 and D_loss is 0.5511338114738464\n",
      "Iteration 97: G_loss is 1.6699978113174438 and D_loss is 0.5283851623535156\n",
      "Iteration 98: G_loss is 1.5983678102493286 and D_loss is 0.6184385418891907\n",
      "Iteration 99: G_loss is 1.595635175704956 and D_loss is 0.6218583583831787\n",
      "Iteration 100: G_loss is 1.6349866390228271 and D_loss is 0.575324535369873\n",
      "Iteration 101: G_loss is 1.6406476497650146 and D_loss is 0.5564374923706055\n",
      "Iteration 102: G_loss is 1.6264541149139404 and D_loss is 0.5523271560668945\n",
      "Iteration 103: G_loss is 1.6363859176635742 and D_loss is 0.5553497672080994\n",
      "Iteration 104: G_loss is 1.652919054031372 and D_loss is 0.554233193397522\n",
      "Iteration 105: G_loss is 1.596827745437622 and D_loss is 0.5689350366592407\n",
      "Iteration 106: G_loss is 1.6200668811798096 and D_loss is 0.5582404732704163\n",
      "Iteration 107: G_loss is 1.6134514808654785 and D_loss is 0.5633583664894104\n",
      "Iteration 108: G_loss is 1.636894941329956 and D_loss is 0.5601276159286499\n",
      "Iteration 109: G_loss is 1.6363985538482666 and D_loss is 0.5432369709014893\n",
      "Iteration 110: G_loss is 1.6218616962432861 and D_loss is 0.5569499135017395\n",
      "Iteration 111: G_loss is 1.669042706489563 and D_loss is 0.5231895446777344\n",
      "Iteration 112: G_loss is 1.6458126306533813 and D_loss is 0.5408651828765869\n",
      "Iteration 113: G_loss is 1.6558430194854736 and D_loss is 0.5460577011108398\n",
      "Iteration 114: G_loss is 1.5849251747131348 and D_loss is 0.6270178556442261\n",
      "Iteration 115: G_loss is 1.6425437927246094 and D_loss is 0.5418394207954407\n",
      "Iteration 116: G_loss is 1.6262845993041992 and D_loss is 0.5573623180389404\n",
      "Iteration 117: G_loss is 1.588646411895752 and D_loss is 0.5932508707046509\n",
      "Iteration 118: G_loss is 1.6160705089569092 and D_loss is 0.5666460990905762\n",
      "Iteration 119: G_loss is 1.4535117149353027 and D_loss is 0.7470861077308655\n",
      "Iteration 120: G_loss is 1.2127976417541504 and D_loss is 1.5942895412445068\n",
      "Iteration 121: G_loss is 1.2366375923156738 and D_loss is 1.8051122426986694\n",
      "Iteration 122: G_loss is 1.193268060684204 and D_loss is 2.2404963970184326\n",
      "Iteration 123: G_loss is 1.2225638628005981 and D_loss is 2.055924892425537\n",
      "Iteration 124: G_loss is 1.4446603059768677 and D_loss is 1.2272132635116577\n",
      "Iteration 125: G_loss is 1.7511670589447021 and D_loss is 1.0048823356628418\n",
      "Iteration 126: G_loss is 2.1398985385894775 and D_loss is 0.3958781361579895\n",
      "Iteration 127: G_loss is 1.814091444015503 and D_loss is 0.6352025270462036\n",
      "Iteration 128: G_loss is 1.8040618896484375 and D_loss is 0.5356927514076233\n",
      "Iteration 129: G_loss is 1.9256610870361328 and D_loss is 0.7026163339614868\n",
      "Iteration 130: G_loss is 1.5865814685821533 and D_loss is 0.6591726541519165\n",
      "Iteration 131: G_loss is 1.5242992639541626 and D_loss is 0.6460524797439575\n",
      "Iteration 132: G_loss is 1.4649286270141602 and D_loss is 0.7565549612045288\n",
      "Iteration 133: G_loss is 1.6604338884353638 and D_loss is 0.5379291772842407\n",
      "Iteration 134: G_loss is 1.501328945159912 and D_loss is 0.67323899269104\n",
      "Iteration 135: G_loss is 1.5102436542510986 and D_loss is 0.7857391834259033\n",
      "Iteration 136: G_loss is 1.5525755882263184 and D_loss is 0.6141486167907715\n",
      "Iteration 137: G_loss is 1.5392671823501587 and D_loss is 0.6990286111831665\n",
      "Iteration 138: G_loss is 1.5128438472747803 and D_loss is 0.6395975351333618\n",
      "Iteration 139: G_loss is 1.3467249870300293 and D_loss is 0.8342007994651794\n",
      "Iteration 140: G_loss is 1.5449573993682861 and D_loss is 0.6356768608093262\n",
      "Iteration 141: G_loss is 1.367701768875122 and D_loss is 0.8140767812728882\n",
      "Iteration 142: G_loss is 1.652940034866333 and D_loss is 0.5780744552612305\n",
      "Iteration 143: G_loss is 1.6699010133743286 and D_loss is 0.5300269722938538\n",
      "Iteration 144: G_loss is 1.5910791158676147 and D_loss is 0.6598271131515503\n",
      "Iteration 145: G_loss is 1.6646010875701904 and D_loss is 0.5848597288131714\n",
      "Iteration 146: G_loss is 1.557478904724121 and D_loss is 0.7090324759483337\n",
      "Iteration 147: G_loss is 1.6018338203430176 and D_loss is 0.6477296948432922\n",
      "Iteration 148: G_loss is 1.4998645782470703 and D_loss is 0.879470944404602\n",
      "Iteration 149: G_loss is 1.3643900156021118 and D_loss is 0.8610278964042664\n",
      "Iteration 150: G_loss is 1.3965271711349487 and D_loss is 0.7914948463439941\n",
      "Iteration 151: G_loss is 1.7454748153686523 and D_loss is 0.512698769569397\n",
      "Iteration 152: G_loss is 1.6869057416915894 and D_loss is 0.569849967956543\n",
      "Iteration 153: G_loss is 1.5216164588928223 and D_loss is 0.6618189811706543\n",
      "Iteration 154: G_loss is 1.7119966745376587 and D_loss is 0.6910086274147034\n",
      "Iteration 155: G_loss is 1.3515570163726807 and D_loss is 0.9730294942855835\n",
      "Iteration 156: G_loss is 1.6344220638275146 and D_loss is 0.605963945388794\n",
      "Iteration 157: G_loss is 1.707850456237793 and D_loss is 0.5903578400611877\n",
      "Iteration 158: G_loss is 1.9042253494262695 and D_loss is 0.4420734643936157\n",
      "Iteration 159: G_loss is 1.6017677783966064 and D_loss is 0.6054608821868896\n",
      "Iteration 160: G_loss is 1.7528002262115479 and D_loss is 0.535618782043457\n",
      "Iteration 161: G_loss is 1.9905198812484741 and D_loss is 0.4122142791748047\n",
      "Iteration 162: G_loss is 1.8371777534484863 and D_loss is 0.5132743120193481\n",
      "Iteration 163: G_loss is 1.8551979064941406 and D_loss is 0.4732542932033539\n",
      "Iteration 164: G_loss is 2.0013809204101562 and D_loss is 0.3626424968242645\n",
      "Iteration 165: G_loss is 1.9358267784118652 and D_loss is 0.42592653632164\n",
      "Iteration 166: G_loss is 1.769134283065796 and D_loss is 0.5173617601394653\n",
      "Iteration 167: G_loss is 1.8898961544036865 and D_loss is 0.47331371903419495\n",
      "Iteration 168: G_loss is 2.0148236751556396 and D_loss is 0.35591745376586914\n",
      "Iteration 169: G_loss is 1.9062020778656006 and D_loss is 0.4087177813053131\n",
      "Iteration 170: G_loss is 1.8280236721038818 and D_loss is 0.4865957498550415\n",
      "Iteration 171: G_loss is 1.8673111200332642 and D_loss is 0.426311731338501\n",
      "Iteration 172: G_loss is 1.746827244758606 and D_loss is 0.48330241441726685\n",
      "Iteration 173: G_loss is 1.902159571647644 and D_loss is 0.41558972001075745\n",
      "Iteration 174: G_loss is 1.8084840774536133 and D_loss is 0.44080469012260437\n",
      "Iteration 175: G_loss is 1.7191307544708252 and D_loss is 0.5752341151237488\n",
      "Iteration 176: G_loss is 1.8105108737945557 and D_loss is 0.4336727559566498\n",
      "Iteration 177: G_loss is 1.8090219497680664 and D_loss is 0.4460681676864624\n",
      "Iteration 178: G_loss is 1.842604398727417 and D_loss is 0.4293360710144043\n",
      "Iteration 179: G_loss is 1.8295817375183105 and D_loss is 0.427498996257782\n",
      "Iteration 180: G_loss is 1.8019256591796875 and D_loss is 0.4489123523235321\n",
      "Iteration 181: G_loss is 1.7913662195205688 and D_loss is 0.44455647468566895\n",
      "Iteration 182: G_loss is 1.7955892086029053 and D_loss is 0.4582063853740692\n",
      "Iteration 183: G_loss is 1.8317615985870361 and D_loss is 0.4391043782234192\n",
      "Iteration 184: G_loss is 1.8015012741088867 and D_loss is 0.4666316509246826\n",
      "Iteration 185: G_loss is 1.7736403942108154 and D_loss is 0.45726242661476135\n",
      "Iteration 186: G_loss is 1.8033382892608643 and D_loss is 0.4469311237335205\n",
      "Iteration 187: G_loss is 1.8270432949066162 and D_loss is 0.43637293577194214\n",
      "Iteration 188: G_loss is 1.7822890281677246 and D_loss is 0.45090121030807495\n",
      "Iteration 189: G_loss is 1.8110883235931396 and D_loss is 0.4383489489555359\n",
      "Iteration 190: G_loss is 1.845578670501709 and D_loss is 0.41946932673454285\n",
      "Iteration 191: G_loss is 1.8616374731063843 and D_loss is 0.41870537400245667\n",
      "Iteration 192: G_loss is 1.8656818866729736 and D_loss is 0.41264018416404724\n",
      "Iteration 193: G_loss is 1.8331623077392578 and D_loss is 0.42406564950942993\n",
      "Iteration 194: G_loss is 1.8290672302246094 and D_loss is 0.43166542053222656\n",
      "Iteration 195: G_loss is 1.8817884922027588 and D_loss is 0.4017961919307709\n",
      "Iteration 196: G_loss is 1.8770906925201416 and D_loss is 0.40551066398620605\n",
      "Iteration 197: G_loss is 1.8574557304382324 and D_loss is 0.41703179478645325\n",
      "Iteration 198: G_loss is 1.9014767408370972 and D_loss is 0.39686137437820435\n",
      "Iteration 199: G_loss is 1.8817670345306396 and D_loss is 0.406999796628952\n",
      "Iteration 200: G_loss is 1.9027869701385498 and D_loss is 0.3977695405483246\n",
      "Iteration 201: G_loss is 1.904320478439331 and D_loss is 0.41693297028541565\n",
      "Iteration 202: G_loss is 1.9508812427520752 and D_loss is 0.3940942883491516\n",
      "Iteration 203: G_loss is 1.8825507164001465 and D_loss is 0.4120703935623169\n",
      "Iteration 204: G_loss is 1.9801051616668701 and D_loss is 0.3666260242462158\n",
      "Iteration 205: G_loss is 1.9526052474975586 and D_loss is 0.37360745668411255\n",
      "Iteration 206: G_loss is 1.9761183261871338 and D_loss is 0.36172547936439514\n",
      "Iteration 207: G_loss is 1.9768136739730835 and D_loss is 0.3705472946166992\n",
      "Iteration 208: G_loss is 1.9678064584732056 and D_loss is 0.3634973466396332\n",
      "Iteration 209: G_loss is 2.057425022125244 and D_loss is 0.34485286474227905\n",
      "Iteration 210: G_loss is 1.9758951663970947 and D_loss is 0.36311212182044983\n",
      "Iteration 211: G_loss is 2.067605495452881 and D_loss is 0.3568056523799896\n",
      "Iteration 212: G_loss is 2.089632511138916 and D_loss is 0.3320223391056061\n",
      "Iteration 213: G_loss is 2.0213253498077393 and D_loss is 0.3763066530227661\n",
      "Iteration 214: G_loss is 2.0228500366210938 and D_loss is 0.35131582617759705\n",
      "Iteration 215: G_loss is 1.9983608722686768 and D_loss is 0.36004653573036194\n",
      "Iteration 216: G_loss is 1.9713826179504395 and D_loss is 0.37982577085494995\n",
      "Iteration 217: G_loss is 1.919175624847412 and D_loss is 0.38590964674949646\n",
      "Iteration 218: G_loss is 1.9643638134002686 and D_loss is 0.3670862317085266\n",
      "Iteration 219: G_loss is 1.9780951738357544 and D_loss is 0.36262938380241394\n",
      "Iteration 220: G_loss is 1.9249694347381592 and D_loss is 0.38602015376091003\n",
      "Iteration 221: G_loss is 1.926998257637024 and D_loss is 0.4038698971271515\n",
      "Iteration 222: G_loss is 1.8919177055358887 and D_loss is 0.4254903197288513\n",
      "Iteration 223: G_loss is 1.894140601158142 and D_loss is 0.41353851556777954\n",
      "Iteration 224: G_loss is 1.9343581199645996 and D_loss is 0.3946448266506195\n",
      "Iteration 225: G_loss is 1.8689019680023193 and D_loss is 0.454135924577713\n",
      "Iteration 226: G_loss is 1.891979694366455 and D_loss is 0.44491949677467346\n",
      "Iteration 227: G_loss is 1.8828508853912354 and D_loss is 0.4275321066379547\n",
      "Iteration 228: G_loss is 1.8935915231704712 and D_loss is 0.43548452854156494\n",
      "Iteration 229: G_loss is 1.9443217515945435 and D_loss is 0.4143933057785034\n",
      "Iteration 230: G_loss is 1.9239591360092163 and D_loss is 0.4125365912914276\n",
      "Iteration 231: G_loss is 1.9514589309692383 and D_loss is 0.39242807030677795\n",
      "Iteration 232: G_loss is 2.031928777694702 and D_loss is 0.3597397804260254\n",
      "Iteration 233: G_loss is 1.9473367929458618 and D_loss is 0.4087591767311096\n",
      "Iteration 234: G_loss is 2.0129828453063965 and D_loss is 0.36729347705841064\n",
      "Iteration 235: G_loss is 2.0538170337677 and D_loss is 0.37987303733825684\n",
      "Iteration 236: G_loss is 2.0325961112976074 and D_loss is 0.363362193107605\n",
      "Iteration 237: G_loss is 2.0608460903167725 and D_loss is 0.355846107006073\n",
      "Iteration 238: G_loss is 2.0989699363708496 and D_loss is 0.35848110914230347\n",
      "Iteration 239: G_loss is 2.195443630218506 and D_loss is 0.3254595994949341\n",
      "Iteration 240: G_loss is 2.266267776489258 and D_loss is 0.29128798842430115\n",
      "Iteration 241: G_loss is 2.209399461746216 and D_loss is 0.31857097148895264\n",
      "Iteration 242: G_loss is 2.413994789123535 and D_loss is 0.2644485831260681\n",
      "Iteration 243: G_loss is 2.539440631866455 and D_loss is 0.21404145658016205\n",
      "Iteration 244: G_loss is 2.777794361114502 and D_loss is 0.16215108335018158\n",
      "Iteration 245: G_loss is 3.010131597518921 and D_loss is 0.13002584874629974\n",
      "Iteration 246: G_loss is 2.768238067626953 and D_loss is 0.3070143461227417\n",
      "Iteration 247: G_loss is 3.1068716049194336 and D_loss is 0.11379827558994293\n",
      "Iteration 248: G_loss is 3.037090301513672 and D_loss is 0.13229624927043915\n",
      "Iteration 249: G_loss is 3.4174537658691406 and D_loss is 0.07775411754846573\n",
      "Iteration 250: G_loss is 3.347926139831543 and D_loss is 0.08824285864830017\n",
      "Iteration 251: G_loss is 3.2706215381622314 and D_loss is 0.08751758188009262\n",
      "Iteration 252: G_loss is 3.087557792663574 and D_loss is 0.10582468658685684\n",
      "Iteration 253: G_loss is 3.0799267292022705 and D_loss is 0.10572909563779831\n",
      "Iteration 254: G_loss is 3.103020191192627 and D_loss is 0.10285019129514694\n",
      "Iteration 255: G_loss is 3.0572900772094727 and D_loss is 0.10842206329107285\n",
      "Iteration 256: G_loss is 3.0996265411376953 and D_loss is 0.10276975482702255\n",
      "Iteration 257: G_loss is 2.9705629348754883 and D_loss is 0.11764799058437347\n",
      "Iteration 258: G_loss is 3.087723731994629 and D_loss is 0.10389232635498047\n",
      "Iteration 259: G_loss is 2.897414445877075 and D_loss is 0.12714968621730804\n",
      "Iteration 260: G_loss is 2.984105110168457 and D_loss is 0.11609288305044174\n",
      "Iteration 261: G_loss is 3.270866870880127 and D_loss is 0.08618427813053131\n",
      "Iteration 262: G_loss is 2.886228561401367 and D_loss is 0.12843754887580872\n",
      "Iteration 263: G_loss is 3.0313467979431152 and D_loss is 0.11010795831680298\n",
      "Iteration 264: G_loss is 2.9738337993621826 and D_loss is 0.11696463078260422\n",
      "Iteration 265: G_loss is 3.0663485527038574 and D_loss is 0.10621123015880585\n",
      "Iteration 266: G_loss is 2.93074631690979 and D_loss is 0.12242446839809418\n",
      "Iteration 267: G_loss is 3.035810947418213 and D_loss is 0.10945746302604675\n",
      "Iteration 268: G_loss is 3.1577234268188477 and D_loss is 0.09638279676437378\n",
      "Iteration 269: G_loss is 3.1086978912353516 and D_loss is 0.10143633931875229\n",
      "Iteration 270: G_loss is 3.218019962310791 and D_loss is 0.09071983397006989\n",
      "Iteration 271: G_loss is 3.052922248840332 and D_loss is 0.10760610550642014\n",
      "Iteration 272: G_loss is 3.256551504135132 and D_loss is 0.08689393103122711\n",
      "Iteration 273: G_loss is 3.22727370262146 and D_loss is 0.0930996835231781\n",
      "Iteration 274: G_loss is 3.3730599880218506 and D_loss is 0.08781574666500092\n",
      "Iteration 275: G_loss is 3.340153932571411 and D_loss is 0.08126722276210785\n",
      "Iteration 276: G_loss is 3.563087224960327 and D_loss is 0.06371469050645828\n",
      "Iteration 277: G_loss is 3.3510680198669434 and D_loss is 0.07916916161775589\n",
      "Iteration 278: G_loss is 3.4919393062591553 and D_loss is 0.06840359419584274\n",
      "Iteration 279: G_loss is 3.3272321224212646 and D_loss is 0.08207393437623978\n",
      "Iteration 280: G_loss is 3.496429443359375 and D_loss is 0.1967911422252655\n",
      "Iteration 281: G_loss is 3.3495116233825684 and D_loss is 0.07934528589248657\n",
      "Iteration 282: G_loss is 3.384998321533203 and D_loss is 0.07814464718103409\n",
      "Iteration 283: G_loss is 3.4076035022735596 and D_loss is 0.07505816221237183\n",
      "Iteration 284: G_loss is 2.9392998218536377 and D_loss is 0.12276840209960938\n",
      "Iteration 285: G_loss is 3.0301599502563477 and D_loss is 0.1110604777932167\n",
      "Iteration 286: G_loss is 3.059540271759033 and D_loss is 0.10786550492048264\n",
      "Iteration 287: G_loss is 3.1677558422088623 and D_loss is 0.09645644575357437\n",
      "Iteration 288: G_loss is 2.9515347480773926 and D_loss is 0.121723972260952\n",
      "Iteration 289: G_loss is 2.9662508964538574 and D_loss is 0.12000863999128342\n",
      "Iteration 290: G_loss is 2.9376065731048584 and D_loss is 0.12368648499250412\n",
      "Iteration 291: G_loss is 3.117945432662964 and D_loss is 0.10215741395950317\n",
      "Iteration 292: G_loss is 3.2591376304626465 and D_loss is 0.08803974837064743\n",
      "Iteration 293: G_loss is 3.3863449096679688 and D_loss is 0.0769771859049797\n",
      "Iteration 294: G_loss is 3.050858736038208 and D_loss is 0.10939601808786392\n",
      "Iteration 295: G_loss is 2.8975653648376465 and D_loss is 0.1284019947052002\n",
      "Iteration 296: G_loss is 3.2947194576263428 and D_loss is 0.08437421917915344\n",
      "Iteration 297: G_loss is 3.3392906188964844 and D_loss is 0.08059122413396835\n",
      "Iteration 298: G_loss is 3.222944974899292 and D_loss is 0.09093975275754929\n",
      "Iteration 299: G_loss is 3.394498348236084 and D_loss is 0.07608132064342499\n",
      "Iteration 300: G_loss is 3.6283152103424072 and D_loss is 0.05985678359866142\n",
      "Iteration 301: G_loss is 3.690843343734741 and D_loss is 0.056228943169116974\n",
      "Iteration 302: G_loss is 3.6478652954101562 and D_loss is 0.0588524304330349\n",
      "Iteration 303: G_loss is 3.622037649154663 and D_loss is 0.06210463494062424\n",
      "Iteration 304: G_loss is 4.096592426300049 and D_loss is 0.0441642627120018\n",
      "Iteration 305: G_loss is 4.133615493774414 and D_loss is 0.06593096256256104\n",
      "Iteration 306: G_loss is 4.110083103179932 and D_loss is 0.05687345191836357\n",
      "Iteration 307: G_loss is 3.7456982135772705 and D_loss is 0.05304273962974548\n",
      "Iteration 308: G_loss is 3.950531005859375 and D_loss is 0.04590979218482971\n",
      "Iteration 309: G_loss is 4.182918548583984 and D_loss is 0.05162415653467178\n",
      "Iteration 310: G_loss is 4.34995698928833 and D_loss is 0.12156420201063156\n",
      "Iteration 311: G_loss is 4.408975601196289 and D_loss is 0.03361594304442406\n",
      "Iteration 312: G_loss is 3.393212080001831 and D_loss is 0.0759410634636879\n",
      "Iteration 313: G_loss is 3.2606911659240723 and D_loss is 0.08721259236335754\n",
      "Iteration 314: G_loss is 3.6237194538116455 and D_loss is 0.059872791171073914\n",
      "Iteration 315: G_loss is 3.484980344772339 and D_loss is 0.06903185695409775\n",
      "Iteration 316: G_loss is 3.2318978309631348 and D_loss is 0.09014426171779633\n",
      "Iteration 317: G_loss is 3.2674875259399414 and D_loss is 0.08670362830162048\n",
      "Iteration 318: G_loss is 3.3880679607391357 and D_loss is 0.07733256369829178\n",
      "Iteration 319: G_loss is 3.4715638160705566 and D_loss is 0.07022207975387573\n",
      "Iteration 320: G_loss is 2.9172730445861816 and D_loss is 0.12563516199588776\n",
      "Iteration 321: G_loss is 3.298427104949951 and D_loss is 0.0841478705406189\n",
      "Iteration 322: G_loss is 3.774921178817749 and D_loss is 0.05148588493466377\n",
      "Iteration 323: G_loss is 3.6482787132263184 and D_loss is 0.05866103991866112\n",
      "Iteration 324: G_loss is 3.6237144470214844 and D_loss is 0.060059644281864166\n",
      "Iteration 325: G_loss is 2.5916972160339355 and D_loss is 0.17848601937294006\n",
      "Iteration 326: G_loss is 3.911712884902954 and D_loss is 0.0447276346385479\n",
      "Iteration 327: G_loss is 4.110808849334717 and D_loss is 0.03788768872618675\n",
      "Iteration 328: G_loss is 4.243425369262695 and D_loss is 0.03186776861548424\n",
      "Iteration 329: G_loss is 3.811269998550415 and D_loss is 0.050274040549993515\n",
      "Iteration 330: G_loss is 4.641763687133789 and D_loss is 0.021274609491229057\n",
      "Iteration 331: G_loss is 4.629306793212891 and D_loss is 0.02157202735543251\n",
      "Iteration 332: G_loss is 4.944770812988281 and D_loss is 0.0220682043582201\n",
      "Iteration 333: G_loss is 4.854323387145996 and D_loss is 0.017267031595110893\n",
      "Iteration 334: G_loss is 4.444806098937988 and D_loss is 0.08788871765136719\n",
      "Iteration 335: G_loss is 4.719258785247803 and D_loss is 0.05179895460605621\n",
      "Iteration 336: G_loss is 4.822554588317871 and D_loss is 0.179274782538414\n",
      "Iteration 337: G_loss is 4.638905048370361 and D_loss is 0.021138573065400124\n",
      "Iteration 338: G_loss is 4.213611125946045 and D_loss is 0.0324377678334713\n",
      "Iteration 339: G_loss is 4.083797454833984 and D_loss is 0.037016380578279495\n",
      "Iteration 340: G_loss is 4.095909118652344 and D_loss is 0.03656601533293724\n",
      "Iteration 341: G_loss is 3.594425678253174 and D_loss is 0.061097826808691025\n",
      "Iteration 342: G_loss is 3.811434268951416 and D_loss is 0.04889490455389023\n",
      "Iteration 343: G_loss is 3.1808998584747314 and D_loss is 0.09399408102035522\n",
      "Iteration 344: G_loss is 3.1072800159454346 and D_loss is 0.10161498934030533\n",
      "Iteration 345: G_loss is 2.974538564682007 and D_loss is 0.1170407235622406\n",
      "Iteration 346: G_loss is 2.8088111877441406 and D_loss is 0.14003470540046692\n",
      "Iteration 347: G_loss is 2.143491506576538 and D_loss is 0.29433512687683105\n",
      "Iteration 348: G_loss is 2.461212158203125 and D_loss is 0.20609669387340546\n",
      "Iteration 349: G_loss is 2.7210588455200195 and D_loss is 0.1553165167570114\n",
      "Iteration 350: G_loss is 2.2611050605773926 and D_loss is 0.25930941104888916\n",
      "Iteration 351: G_loss is 2.6321029663085938 and D_loss is 0.17223447561264038\n",
      "Iteration 352: G_loss is 2.914829730987549 and D_loss is 0.12706054747104645\n",
      "Iteration 353: G_loss is 3.4321846961975098 and D_loss is 0.07398578524589539\n",
      "Iteration 354: G_loss is 4.280331134796143 and D_loss is 0.03110472485423088\n",
      "Iteration 355: G_loss is 3.901808023452759 and D_loss is 0.04575514420866966\n",
      "Iteration 356: G_loss is 4.296353816986084 and D_loss is 0.030594995245337486\n",
      "Iteration 357: G_loss is 5.568123817443848 and D_loss is 0.008469233289361\n",
      "Iteration 358: G_loss is 4.451776504516602 and D_loss is 0.02598274126648903\n",
      "Iteration 359: G_loss is 4.47345495223999 and D_loss is 0.02528676576912403\n",
      "Iteration 360: G_loss is 4.417991638183594 and D_loss is 0.026627933606505394\n",
      "Iteration 361: G_loss is 5.115726947784424 and D_loss is 0.01311585959047079\n",
      "Iteration 362: G_loss is 5.682885646820068 and D_loss is 0.007392574567347765\n",
      "Iteration 363: G_loss is 5.354528903961182 and D_loss is 0.010250478982925415\n",
      "Iteration 364: G_loss is 4.926536560058594 and D_loss is 0.01573706604540348\n",
      "Iteration 365: G_loss is 4.821432113647461 and D_loss is 0.017475055530667305\n",
      "Iteration 366: G_loss is 5.500006675720215 and D_loss is 0.008820096962153912\n",
      "Iteration 367: G_loss is 5.2594075202941895 and D_loss is 0.011313927359879017\n",
      "Iteration 368: G_loss is 5.305871486663818 and D_loss is 0.01070678886026144\n",
      "Iteration 369: G_loss is 5.503756523132324 and D_loss is 0.00877910666167736\n",
      "Iteration 370: G_loss is 5.121279239654541 and D_loss is 0.012892119586467743\n",
      "Iteration 371: G_loss is 6.156622886657715 and D_loss is 0.004560387693345547\n",
      "Iteration 372: G_loss is 5.739015579223633 and D_loss is 0.0069458382204174995\n",
      "Iteration 373: G_loss is 5.679183483123779 and D_loss is 0.008047247305512428\n",
      "Iteration 374: G_loss is 5.060628890991211 and D_loss is 0.013694481924176216\n",
      "Iteration 375: G_loss is 5.9284892082214355 and D_loss is 0.005763967987149954\n",
      "Iteration 376: G_loss is 5.2791666984558105 and D_loss is 0.011014563962817192\n",
      "Iteration 377: G_loss is 5.059407711029053 and D_loss is 0.013784520328044891\n",
      "Iteration 378: G_loss is 5.334505081176758 and D_loss is 0.010416027158498764\n",
      "Iteration 379: G_loss is 5.452492713928223 and D_loss is 0.04374225437641144\n",
      "Iteration 380: G_loss is 4.819761753082275 and D_loss is 0.01783718355000019\n",
      "Iteration 381: G_loss is 5.4498467445373535 and D_loss is 0.009685267694294453\n",
      "Iteration 382: G_loss is 4.559295654296875 and D_loss is 0.02277803048491478\n",
      "Iteration 383: G_loss is 5.327841758728027 and D_loss is 0.010504720732569695\n",
      "Iteration 384: G_loss is 5.206880569458008 and D_loss is 0.012306777760386467\n",
      "Iteration 385: G_loss is 5.579986095428467 and D_loss is 0.008170905523002148\n",
      "Iteration 386: G_loss is 4.980998516082764 and D_loss is 0.0149257006123662\n",
      "Iteration 387: G_loss is 5.602240562438965 and D_loss is 0.008009863086044788\n",
      "Iteration 388: G_loss is 4.280132293701172 and D_loss is 0.03045468032360077\n",
      "Iteration 389: G_loss is 4.711270332336426 and D_loss is 0.019752612337470055\n",
      "Iteration 390: G_loss is 5.220892906188965 and D_loss is 0.011830007657408714\n",
      "Iteration 391: G_loss is 4.404986381530762 and D_loss is 0.02697967365384102\n",
      "Iteration 392: G_loss is 4.161067485809326 and D_loss is 0.03448258340358734\n",
      "Iteration 393: G_loss is 4.5615458488464355 and D_loss is 0.023052815347909927\n",
      "Iteration 394: G_loss is 3.9218478202819824 and D_loss is 0.04386993125081062\n",
      "Iteration 395: G_loss is 3.526461601257324 and D_loss is 0.06594903767108917\n",
      "Iteration 396: G_loss is 4.143168926239014 and D_loss is 0.03504420816898346\n",
      "Iteration 397: G_loss is 4.755429267883301 and D_loss is 0.018911410123109818\n",
      "Iteration 398: G_loss is 3.9839091300964355 and D_loss is 0.04142441973090172\n",
      "Iteration 399: G_loss is 4.414306640625 and D_loss is 0.026778357103466988\n",
      "Iteration 400: G_loss is 4.537411689758301 and D_loss is 0.02357708103954792\n",
      "Iteration 401: G_loss is 3.7039759159088135 and D_loss is 0.05767430365085602\n",
      "Iteration 402: G_loss is 3.6902928352355957 and D_loss is 0.073656365275383\n",
      "Iteration 403: G_loss is 3.4784700870513916 and D_loss is 0.07116981595754623\n",
      "Iteration 404: G_loss is 3.640129566192627 and D_loss is 0.08830687403678894\n",
      "Iteration 405: G_loss is 3.0928876399993896 and D_loss is 0.10658108443021774\n",
      "Iteration 406: G_loss is 4.5494208335876465 and D_loss is 0.02614729106426239\n",
      "Iteration 407: G_loss is 4.434206962585449 and D_loss is 0.5662089586257935\n",
      "Iteration 408: G_loss is 2.630737066268921 and D_loss is 0.17506207525730133\n",
      "Iteration 409: G_loss is 2.768054485321045 and D_loss is 0.15007363259792328\n",
      "Iteration 410: G_loss is 2.3749403953552246 and D_loss is 0.231175497174263\n",
      "Iteration 411: G_loss is 1.8969396352767944 and D_loss is 0.4029756486415863\n",
      "Iteration 412: G_loss is 1.8622736930847168 and D_loss is 0.4223784804344177\n",
      "Iteration 413: G_loss is 1.6295735836029053 and D_loss is 0.5746020078659058\n",
      "Iteration 414: G_loss is 1.616422414779663 and D_loss is 0.5906782150268555\n",
      "Iteration 415: G_loss is 2.4749176502227783 and D_loss is 0.21095822751522064\n",
      "Iteration 416: G_loss is 2.8567006587982178 and D_loss is 0.13989613950252533\n",
      "Iteration 417: G_loss is 3.707488775253296 and D_loss is 0.057345662266016006\n",
      "Iteration 418: G_loss is 4.451592922210693 and D_loss is 0.02666293829679489\n",
      "Iteration 419: G_loss is 4.533353805541992 and D_loss is 0.024696364998817444\n",
      "Iteration 420: G_loss is 5.121087551116943 and D_loss is 0.01344600971788168\n",
      "Iteration 421: G_loss is 5.667749881744385 and D_loss is 0.008377508260309696\n",
      "Iteration 422: G_loss is 5.384444713592529 and D_loss is 0.01036764308810234\n",
      "Iteration 423: G_loss is 5.778026580810547 and D_loss is 0.00926005095243454\n",
      "Iteration 424: G_loss is 6.14794397354126 and D_loss is 0.031595923006534576\n",
      "Iteration 425: G_loss is 5.989828586578369 and D_loss is 0.15805505216121674\n",
      "Iteration 426: G_loss is 5.668834209442139 and D_loss is 0.007654113695025444\n",
      "Iteration 427: G_loss is 4.875115871429443 and D_loss is 0.017143353819847107\n",
      "Iteration 428: G_loss is 5.1738996505737305 and D_loss is 0.013109276071190834\n",
      "Iteration 429: G_loss is 5.137374401092529 and D_loss is 0.014374583959579468\n",
      "Iteration 430: G_loss is 5.646556377410889 and D_loss is 0.007821272127330303\n",
      "Iteration 431: G_loss is 4.988933086395264 and D_loss is 0.015193005092442036\n",
      "Iteration 432: G_loss is 4.917616844177246 and D_loss is 0.016292667016386986\n",
      "Iteration 433: G_loss is 5.157955169677734 and D_loss is 0.013049151748418808\n",
      "Iteration 434: G_loss is 4.5613627433776855 and D_loss is 0.025239206850528717\n",
      "Iteration 435: G_loss is 5.035514831542969 and D_loss is 0.014604384079575539\n",
      "Iteration 436: G_loss is 4.649036407470703 and D_loss is 0.0213663037866354\n",
      "Iteration 437: G_loss is 4.613833904266357 and D_loss is 0.022216886281967163\n",
      "Iteration 438: G_loss is 4.178416728973389 and D_loss is 0.03442297503352165\n",
      "Iteration 439: G_loss is 4.400730133056641 and D_loss is 0.02753152698278427\n",
      "Iteration 440: G_loss is 4.773318767547607 and D_loss is 0.01898249052464962\n",
      "Iteration 441: G_loss is 4.245379447937012 and D_loss is 0.032419197261333466\n",
      "Iteration 442: G_loss is 4.287144660949707 and D_loss is 0.03128385171294212\n",
      "Iteration 443: G_loss is 4.312833309173584 and D_loss is 0.030652664601802826\n",
      "Iteration 444: G_loss is 5.3680500984191895 and D_loss is 0.010671481490135193\n",
      "Iteration 445: G_loss is 4.504783630371094 and D_loss is 0.02647262066602707\n",
      "Iteration 446: G_loss is 4.619439125061035 and D_loss is 0.02237739972770214\n",
      "Iteration 447: G_loss is 4.546584129333496 and D_loss is 0.024170879274606705\n",
      "Iteration 448: G_loss is 4.349432945251465 and D_loss is 0.02959996461868286\n",
      "Iteration 449: G_loss is 4.128836631774902 and D_loss is 0.03745442256331444\n",
      "Iteration 450: G_loss is 4.6068949699401855 and D_loss is 0.023289460688829422\n",
      "Iteration 451: G_loss is 4.4563775062561035 and D_loss is 0.02692573331296444\n",
      "Iteration 452: G_loss is 4.4515204429626465 and D_loss is 0.027034297585487366\n",
      "Iteration 453: G_loss is 4.7260541915893555 and D_loss is 0.020711855962872505\n",
      "Iteration 454: G_loss is 4.955277442932129 and D_loss is 0.016437841579318047\n",
      "Iteration 455: G_loss is 5.082789421081543 and D_loss is 0.01598755642771721\n",
      "Iteration 456: G_loss is 5.721734046936035 and D_loss is 0.008559681475162506\n",
      "Iteration 457: G_loss is 5.398873329162598 and D_loss is 0.011676319874823093\n",
      "Iteration 458: G_loss is 4.972374439239502 and D_loss is 0.017298633232712746\n",
      "Iteration 459: G_loss is 6.277453899383545 and D_loss is 0.005003767088055611\n",
      "Iteration 460: G_loss is 6.473248481750488 and D_loss is 0.04190240427851677\n",
      "Iteration 461: G_loss is 5.213122367858887 and D_loss is 0.01864437386393547\n",
      "Iteration 462: G_loss is 5.357914924621582 and D_loss is 0.010844431817531586\n",
      "Iteration 463: G_loss is 4.638955593109131 and D_loss is 0.025904908776283264\n",
      "Iteration 464: G_loss is 5.505084991455078 and D_loss is 0.009361464530229568\n",
      "Iteration 465: G_loss is 4.370669841766357 and D_loss is 0.028866171836853027\n",
      "Iteration 466: G_loss is 5.117976188659668 and D_loss is 0.014226268976926804\n",
      "Iteration 467: G_loss is 5.48634147644043 and D_loss is 0.009412476792931557\n",
      "Iteration 468: G_loss is 5.335533618927002 and D_loss is 0.011070282198488712\n",
      "Iteration 469: G_loss is 5.246051788330078 and D_loss is 0.012051325291395187\n",
      "Iteration 470: G_loss is 4.643831729888916 and D_loss is 0.022059455513954163\n",
      "Iteration 471: G_loss is 5.444217205047607 and D_loss is 0.010036483407020569\n",
      "Iteration 472: G_loss is 4.883191108703613 and D_loss is 0.017141681164503098\n",
      "Iteration 473: G_loss is 3.7014009952545166 and D_loss is 0.05685523524880409\n",
      "Iteration 474: G_loss is 4.204883575439453 and D_loss is 0.034058380872011185\n",
      "Iteration 475: G_loss is 4.0397257804870605 and D_loss is 0.041913654655218124\n",
      "Iteration 476: G_loss is 4.303015232086182 and D_loss is 0.030471568927168846\n",
      "Iteration 477: G_loss is 5.207464694976807 and D_loss is 0.013348273932933807\n",
      "Iteration 478: G_loss is 4.760946750640869 and D_loss is 0.01917775720357895\n",
      "Iteration 479: G_loss is 4.422644138336182 and D_loss is 0.03544146195054054\n",
      "Iteration 480: G_loss is 4.877780914306641 and D_loss is 0.017110513523221016\n",
      "Iteration 481: G_loss is 4.524655342102051 and D_loss is 0.02545149438083172\n",
      "Iteration 482: G_loss is 5.025732040405273 and D_loss is 0.027957966551184654\n",
      "Iteration 483: G_loss is 5.49514102935791 and D_loss is 0.01029464602470398\n",
      "Iteration 484: G_loss is 5.065229415893555 and D_loss is 0.013984568417072296\n",
      "Iteration 485: G_loss is 5.166919708251953 and D_loss is 0.0126483254134655\n",
      "Iteration 486: G_loss is 5.35004186630249 and D_loss is 0.011059993878006935\n",
      "Iteration 487: G_loss is 5.272291660308838 and D_loss is 0.016740519553422928\n",
      "Iteration 488: G_loss is 4.964810848236084 and D_loss is 0.015636740252375603\n",
      "Iteration 489: G_loss is 5.627645492553711 and D_loss is 0.00916694849729538\n",
      "Iteration 490: G_loss is 5.013956546783447 and D_loss is 0.041343118995428085\n",
      "Iteration 491: G_loss is 5.263698577880859 and D_loss is 0.012762117199599743\n",
      "Iteration 492: G_loss is 6.07636833190918 and D_loss is 0.008516650646924973\n",
      "Iteration 493: G_loss is 5.332775592803955 and D_loss is 0.11217111349105835\n",
      "Iteration 494: G_loss is 5.576361656188965 and D_loss is 0.01107784453779459\n",
      "Iteration 495: G_loss is 5.052479267120361 and D_loss is 0.015434008091688156\n",
      "Iteration 496: G_loss is 4.524281024932861 and D_loss is 0.02397434040904045\n",
      "Iteration 497: G_loss is 4.350699424743652 and D_loss is 0.028667710721492767\n",
      "Iteration 498: G_loss is 5.354260444641113 and D_loss is 0.010433296672999859\n",
      "Iteration 499: G_loss is 4.502232551574707 and D_loss is 0.025700731202960014\n",
      "Iteration 500: G_loss is 5.178872108459473 and D_loss is 0.012365092523396015\n",
      "Iteration 501: G_loss is 4.002699851989746 and D_loss is 0.040659330785274506\n",
      "Iteration 502: G_loss is 5.366684913635254 and D_loss is 0.010225223377346992\n",
      "Iteration 503: G_loss is 4.574229717254639 and D_loss is 0.023675279691815376\n",
      "Iteration 504: G_loss is 5.219504356384277 and D_loss is 0.011910323053598404\n",
      "Iteration 505: G_loss is 5.5253496170043945 and D_loss is 0.008770189248025417\n",
      "Iteration 506: G_loss is 5.119736194610596 and D_loss is 0.013262464664876461\n",
      "Iteration 507: G_loss is 6.137372016906738 and D_loss is 0.004754093941301107\n",
      "Iteration 508: G_loss is 5.8868584632873535 and D_loss is 0.006107266992330551\n",
      "Iteration 509: G_loss is 5.716292381286621 and D_loss is 0.007235947996377945\n",
      "Iteration 510: G_loss is 6.34946346282959 and D_loss is 0.0038279122672975063\n",
      "Iteration 511: G_loss is 4.597239017486572 and D_loss is 0.022174222394824028\n",
      "Iteration 512: G_loss is 5.961477279663086 and D_loss is 0.005636471323668957\n",
      "Iteration 513: G_loss is 5.9271240234375 and D_loss is 0.00587307708337903\n",
      "Iteration 514: G_loss is 6.272589683532715 and D_loss is 0.004180518910288811\n",
      "Iteration 515: G_loss is 5.018040180206299 and D_loss is 0.014512714929878712\n",
      "Iteration 516: G_loss is 5.964672088623047 and D_loss is 0.005592667032033205\n",
      "Iteration 517: G_loss is 6.8000569343566895 and D_loss is 0.00242207245901227\n",
      "Iteration 518: G_loss is 4.106688976287842 and D_loss is 0.03651980310678482\n",
      "Iteration 519: G_loss is 5.924718856811523 and D_loss is 0.006017510779201984\n",
      "Iteration 520: G_loss is 5.829347133636475 and D_loss is 0.006420233752578497\n",
      "Iteration 521: G_loss is 4.738579273223877 and D_loss is 0.01930728368461132\n",
      "Iteration 522: G_loss is 4.8860368728637695 and D_loss is 0.016665484756231308\n",
      "Iteration 523: G_loss is 5.74601936340332 and D_loss is 0.007166734896600246\n",
      "Iteration 524: G_loss is 5.342477798461914 and D_loss is 0.01045923214405775\n",
      "Iteration 525: G_loss is 6.0792765617370605 and D_loss is 0.005003680475056171\n",
      "Iteration 526: G_loss is 6.565151691436768 and D_loss is 0.003852316178381443\n",
      "Iteration 527: G_loss is 4.626543045043945 and D_loss is 0.02210296504199505\n",
      "Iteration 528: G_loss is 4.323625564575195 and D_loss is 0.029358940199017525\n",
      "Iteration 529: G_loss is 5.444753646850586 and D_loss is 0.00950724259018898\n",
      "Iteration 530: G_loss is 5.5867204666137695 and D_loss is 0.008256086148321629\n",
      "Iteration 531: G_loss is 4.230910778045654 and D_loss is 0.03239840269088745\n",
      "Iteration 532: G_loss is 5.034490585327148 and D_loss is 0.01437080092728138\n",
      "Iteration 533: G_loss is 5.979228973388672 and D_loss is 0.00575335742905736\n",
      "Iteration 534: G_loss is 5.173125743865967 and D_loss is 0.030464284121990204\n",
      "Iteration 535: G_loss is 5.265728950500488 and D_loss is 0.016562001779675484\n",
      "Iteration 536: G_loss is 4.982278823852539 and D_loss is 0.015966981649398804\n",
      "Iteration 537: G_loss is 5.5767011642456055 and D_loss is 0.008725124411284924\n",
      "Iteration 538: G_loss is 6.063173770904541 and D_loss is 0.006099001970142126\n",
      "Iteration 539: G_loss is 5.541319847106934 and D_loss is 0.010982764884829521\n",
      "Iteration 540: G_loss is 6.297566890716553 and D_loss is 0.011020451784133911\n",
      "Iteration 541: G_loss is 5.8257598876953125 and D_loss is 0.0066786278039216995\n",
      "Iteration 542: G_loss is 6.533511161804199 and D_loss is 0.7321847677230835\n",
      "Iteration 543: G_loss is 5.253769397735596 and D_loss is 0.011415180750191212\n",
      "Iteration 544: G_loss is 3.2029459476470947 and D_loss is 0.09215559810400009\n",
      "Iteration 545: G_loss is 2.6936943531036377 and D_loss is 0.15837204456329346\n",
      "Iteration 546: G_loss is 2.615584373474121 and D_loss is 0.17266875505447388\n",
      "Iteration 547: G_loss is 1.8572803735733032 and D_loss is 0.41518574953079224\n",
      "Iteration 548: G_loss is 1.9036791324615479 and D_loss is 0.3924044668674469\n",
      "Iteration 549: G_loss is 2.178119659423828 and D_loss is 0.2851530611515045\n",
      "Iteration 550: G_loss is 2.2062225341796875 and D_loss is 0.27522939443588257\n",
      "Iteration 551: G_loss is 4.568207263946533 and D_loss is 0.02302304469048977\n",
      "Iteration 552: G_loss is 2.9175169467926025 and D_loss is 0.12671397626399994\n",
      "Iteration 553: G_loss is 3.0300116539001465 and D_loss is 0.112545445561409\n",
      "Iteration 554: G_loss is 4.92099142074585 and D_loss is 0.016323616728186607\n",
      "Iteration 555: G_loss is 4.545263290405273 and D_loss is 0.024097424000501633\n",
      "Iteration 556: G_loss is 5.9749250411987305 and D_loss is 0.005641368683427572\n",
      "Iteration 557: G_loss is 6.60435676574707 and D_loss is 0.0029857291374355555\n",
      "Iteration 558: G_loss is 8.17526912689209 and D_loss is 0.0006239485810510814\n",
      "Iteration 559: G_loss is 9.0669584274292 and D_loss is 0.0002564040769357234\n",
      "Iteration 560: G_loss is 9.057281494140625 and D_loss is 0.00026089409948326647\n",
      "Iteration 561: G_loss is 9.607095718383789 and D_loss is 0.00015509557852055877\n",
      "Iteration 562: G_loss is 8.973685264587402 and D_loss is 0.00028597423806786537\n",
      "Iteration 563: G_loss is 7.974363327026367 and D_loss is 0.0007522702217102051\n",
      "Iteration 564: G_loss is 8.29831600189209 and D_loss is 0.0005633397377096117\n",
      "Iteration 565: G_loss is 8.68099594116211 and D_loss is 0.00037322522257454693\n",
      "Iteration 566: G_loss is 9.506647109985352 and D_loss is 0.00016842724289745092\n",
      "Iteration 567: G_loss is 10.19070053100586 and D_loss is 8.827317651594058e-05\n",
      "Iteration 568: G_loss is 9.237112045288086 and D_loss is 0.00022913246357347816\n",
      "Iteration 569: G_loss is 8.289810180664062 and D_loss is 0.0005455607897602022\n",
      "Iteration 570: G_loss is 9.141034126281738 and D_loss is 0.00023410696303471923\n",
      "Iteration 571: G_loss is 7.367179870605469 and D_loss is 0.0013627078151330352\n",
      "Iteration 572: G_loss is 8.348444938659668 and D_loss is 0.000511971942614764\n",
      "Iteration 573: G_loss is 8.134559631347656 and D_loss is 0.0006351539632305503\n",
      "Iteration 574: G_loss is 6.890281677246094 and D_loss is 0.0022352358791977167\n",
      "Iteration 575: G_loss is 7.717172145843506 and D_loss is 0.0009655138710513711\n",
      "Iteration 576: G_loss is 7.263181209564209 and D_loss is 0.0015156097942963243\n",
      "Iteration 577: G_loss is 6.2027788162231445 and D_loss is 0.004382577259093523\n",
      "Iteration 578: G_loss is 7.7100043296813965 and D_loss is 0.0009822403080761433\n",
      "Iteration 579: G_loss is 6.549099922180176 and D_loss is 0.0031328576151281595\n",
      "Iteration 580: G_loss is 7.329761981964111 and D_loss is 0.0014953762292861938\n",
      "Iteration 581: G_loss is 6.142058849334717 and D_loss is 0.004729852546006441\n",
      "Iteration 582: G_loss is 6.352209568023682 and D_loss is 0.004026845563203096\n",
      "Iteration 583: G_loss is 6.095272064208984 and D_loss is 0.005012204870581627\n",
      "Iteration 584: G_loss is 6.418038845062256 and D_loss is 0.0036195318680256605\n",
      "Iteration 585: G_loss is 5.691300392150879 and D_loss is 0.007467928808182478\n",
      "Iteration 586: G_loss is 5.674709796905518 and D_loss is 0.007550900802016258\n",
      "Iteration 587: G_loss is 5.931859493255615 and D_loss is 0.0060972487553954124\n",
      "Iteration 588: G_loss is 4.719461917877197 and D_loss is 0.020054588094353676\n",
      "Iteration 589: G_loss is 4.020360946655273 and D_loss is 0.040464822202920914\n",
      "Iteration 590: G_loss is 3.863870620727539 and D_loss is 0.04782310873270035\n",
      "Iteration 591: G_loss is 4.078085899353027 and D_loss is 0.038674090057611465\n",
      "Iteration 592: G_loss is 3.64434814453125 and D_loss is 0.06013412028551102\n",
      "Iteration 593: G_loss is 4.5984954833984375 and D_loss is 0.022669795900583267\n",
      "Iteration 594: G_loss is 4.342928409576416 and D_loss is 0.029521141201257706\n",
      "Iteration 595: G_loss is 3.7961339950561523 and D_loss is 0.05155888944864273\n",
      "Iteration 596: G_loss is 3.026010036468506 and D_loss is 0.11488725244998932\n",
      "Iteration 597: G_loss is 4.587273120880127 and D_loss is 0.02402082085609436\n",
      "Iteration 598: G_loss is 3.560025215148926 and D_loss is 0.06647592782974243\n",
      "Iteration 599: G_loss is 4.740400314331055 and D_loss is 0.019870104268193245\n",
      "Iteration 600: G_loss is 3.525949239730835 and D_loss is 0.06903358548879623\n",
      "Iteration 601: G_loss is 4.9517693519592285 and D_loss is 0.016248246654868126\n",
      "Iteration 602: G_loss is 4.051226615905762 and D_loss is 0.0435374490916729\n",
      "Iteration 603: G_loss is 4.384562969207764 and D_loss is 0.029077572748064995\n",
      "Iteration 604: G_loss is 5.128605365753174 and D_loss is 0.018439527601003647\n",
      "Iteration 605: G_loss is 7.140572547912598 and D_loss is 0.004142484627664089\n",
      "Iteration 606: G_loss is 5.478026390075684 and D_loss is 0.00946437194943428\n",
      "Iteration 607: G_loss is 5.856155872344971 and D_loss is 0.008862768299877644\n",
      "Iteration 608: G_loss is 6.016242027282715 and D_loss is 0.006574103143066168\n",
      "Iteration 609: G_loss is 6.344815731048584 and D_loss is 0.07788926362991333\n",
      "Iteration 610: G_loss is 5.202208995819092 and D_loss is 0.014807891100645065\n",
      "Iteration 611: G_loss is 6.398903846740723 and D_loss is 0.0037466154899448156\n",
      "Iteration 612: G_loss is 6.879257678985596 and D_loss is 0.0033640165347605944\n",
      "Iteration 613: G_loss is 7.089605331420898 and D_loss is 0.0020743825007230043\n",
      "Iteration 614: G_loss is 6.5509867668151855 and D_loss is 0.012785712257027626\n",
      "Iteration 615: G_loss is 6.14559268951416 and D_loss is 0.006374614778906107\n",
      "Iteration 616: G_loss is 6.9897990226745605 and D_loss is 0.0026857340708374977\n",
      "Iteration 617: G_loss is 6.5664753913879395 and D_loss is 0.03065822832286358\n",
      "Iteration 618: G_loss is 7.127636909484863 and D_loss is 0.015125809237360954\n",
      "Iteration 619: G_loss is 6.499893665313721 and D_loss is 0.0035430004354566336\n",
      "Iteration 620: G_loss is 6.391451835632324 and D_loss is 0.004463608376681805\n",
      "Iteration 621: G_loss is 7.479092121124268 and D_loss is 0.0021817274391651154\n",
      "Iteration 622: G_loss is 6.513607978820801 and D_loss is 0.0033492797520011663\n",
      "Iteration 623: G_loss is 6.786004066467285 and D_loss is 0.0027422027196735144\n",
      "Iteration 624: G_loss is 7.143993854522705 and D_loss is 0.012007178738713264\n",
      "Iteration 625: G_loss is 7.195283889770508 and D_loss is 0.0018708218121901155\n",
      "Iteration 626: G_loss is 7.492383003234863 and D_loss is 0.001616747584193945\n",
      "Iteration 627: G_loss is 6.6959099769592285 and D_loss is 0.003061804221943021\n",
      "Iteration 628: G_loss is 6.692658424377441 and D_loss is 0.0033243130892515182\n",
      "Iteration 629: G_loss is 7.232369422912598 and D_loss is 0.0023663153406232595\n",
      "Iteration 630: G_loss is 6.549994945526123 and D_loss is 0.0063858311623334885\n",
      "Iteration 631: G_loss is 6.583474636077881 and D_loss is 0.0032482692040503025\n",
      "Iteration 632: G_loss is 7.603342533111572 and D_loss is 0.0011324523948132992\n",
      "Iteration 633: G_loss is 6.646212100982666 and D_loss is 0.0029115863144397736\n",
      "Iteration 634: G_loss is 6.744578838348389 and D_loss is 0.003834268543869257\n",
      "Iteration 635: G_loss is 6.7152099609375 and D_loss is 0.0027496074326336384\n",
      "Iteration 636: G_loss is 5.811553955078125 and D_loss is 0.006716020870953798\n",
      "Iteration 637: G_loss is 5.686444282531738 and D_loss is 0.007669301703572273\n",
      "Iteration 638: G_loss is 6.412039756774902 and D_loss is 0.0038107444997876883\n",
      "Iteration 639: G_loss is 5.330804824829102 and D_loss is 0.012287575751543045\n",
      "Iteration 640: G_loss is 5.640490531921387 and D_loss is 0.008178957737982273\n",
      "Iteration 641: G_loss is 6.240874767303467 and D_loss is 0.004504575859755278\n",
      "Iteration 642: G_loss is 5.378617286682129 and D_loss is 0.010435163974761963\n",
      "Iteration 643: G_loss is 6.726230144500732 and D_loss is 0.002717766910791397\n",
      "Iteration 644: G_loss is 5.257374286651611 and D_loss is 0.011996218003332615\n",
      "Iteration 645: G_loss is 6.751064777374268 and D_loss is 0.0029244422912597656\n",
      "Iteration 646: G_loss is 4.9144182205200195 and D_loss is 0.016659757122397423\n",
      "Iteration 647: G_loss is 5.651831150054932 and D_loss is 0.008012723177671432\n",
      "Iteration 648: G_loss is 6.598811626434326 and D_loss is 0.003122311783954501\n",
      "Iteration 649: G_loss is 6.159546375274658 and D_loss is 0.021998971700668335\n",
      "Iteration 650: G_loss is 5.24241304397583 and D_loss is 0.020701870322227478\n",
      "Iteration 651: G_loss is 4.7419586181640625 and D_loss is 0.02002938650548458\n",
      "Iteration 652: G_loss is 6.031597137451172 and D_loss is 0.005506729707121849\n",
      "Iteration 653: G_loss is 5.443881988525391 and D_loss is 0.010026906616985798\n",
      "Iteration 654: G_loss is 6.146297454833984 and D_loss is 0.004902930464595556\n",
      "Iteration 655: G_loss is 5.200748920440674 and D_loss is 0.012759575620293617\n",
      "Iteration 656: G_loss is 5.011727809906006 and D_loss is 0.01664111576974392\n",
      "Iteration 657: G_loss is 6.164247035980225 and D_loss is 0.004826399497687817\n",
      "Iteration 658: G_loss is 6.876552104949951 and D_loss is 0.002459548180922866\n",
      "Iteration 659: G_loss is 6.56357479095459 and D_loss is 0.003213367657735944\n",
      "Iteration 660: G_loss is 5.927822589874268 and D_loss is 0.008246507495641708\n",
      "Iteration 661: G_loss is 4.793536186218262 and D_loss is 0.019230009987950325\n",
      "Iteration 662: G_loss is 5.158095359802246 and D_loss is 0.013231285847723484\n",
      "Iteration 663: G_loss is 6.757874965667725 and D_loss is 0.0027769540902227163\n",
      "Iteration 664: G_loss is 6.822719573974609 and D_loss is 0.0025005240458995104\n",
      "Iteration 665: G_loss is 4.765960693359375 and D_loss is 0.019656671211123466\n",
      "Iteration 666: G_loss is 5.581149101257324 and D_loss is 0.016695111989974976\n",
      "Iteration 667: G_loss is 5.468616485595703 and D_loss is 0.016985278576612473\n",
      "Iteration 668: G_loss is 6.355867862701416 and D_loss is 0.004348967224359512\n",
      "Iteration 669: G_loss is 6.198764801025391 and D_loss is 0.006143172271549702\n",
      "Iteration 670: G_loss is 5.3369245529174805 and D_loss is 0.011291984468698502\n",
      "Iteration 671: G_loss is 4.7671051025390625 and D_loss is 0.021357720717787743\n",
      "Iteration 672: G_loss is 5.758037090301514 and D_loss is 0.08325344324111938\n",
      "Iteration 673: G_loss is 4.279394149780273 and D_loss is 0.03443562239408493\n",
      "Iteration 674: G_loss is 4.871332168579102 and D_loss is 0.01767692156136036\n",
      "Iteration 675: G_loss is 4.44967794418335 and D_loss is 0.027377068996429443\n",
      "Iteration 676: G_loss is 5.406582832336426 and D_loss is 0.010932253673672676\n",
      "Iteration 677: G_loss is 5.581659317016602 and D_loss is 0.01367265172302723\n",
      "Iteration 678: G_loss is 3.6178698539733887 and D_loss is 0.06349008530378342\n",
      "Iteration 679: G_loss is 2.48045015335083 and D_loss is 0.20718064904212952\n",
      "Iteration 680: G_loss is 5.741729736328125 and D_loss is 0.009390545077621937\n",
      "Iteration 681: G_loss is 5.640979290008545 and D_loss is 0.009833836928009987\n",
      "Iteration 682: G_loss is 9.666638374328613 and D_loss is 0.08128878474235535\n",
      "Iteration 683: G_loss is 6.093730449676514 and D_loss is 0.006151237525045872\n",
      "Iteration 684: G_loss is 8.220123291015625 and D_loss is 0.0008433310431428254\n",
      "Iteration 685: G_loss is 9.039527893066406 and D_loss is 0.00034765113377943635\n",
      "Iteration 686: G_loss is 5.453484535217285 and D_loss is 0.009572578594088554\n",
      "Iteration 687: G_loss is 8.786418914794922 and D_loss is 0.0004102978273294866\n",
      "Iteration 688: G_loss is 6.742923736572266 and D_loss is 0.003523405874148011\n",
      "Iteration 689: G_loss is 10.129288673400879 and D_loss is 8.850535959936678e-05\n",
      "Iteration 690: G_loss is 6.295589447021484 and D_loss is 0.010255547240376472\n",
      "Iteration 691: G_loss is 5.880288124084473 and D_loss is 0.006325544789433479\n",
      "Iteration 692: G_loss is 5.83447265625 and D_loss is 0.006514032371342182\n",
      "Iteration 693: G_loss is 6.374749660491943 and D_loss is 0.00399470841512084\n",
      "Iteration 694: G_loss is 5.559624195098877 and D_loss is 0.008461388759315014\n",
      "Iteration 695: G_loss is 4.3735198974609375 and D_loss is 0.2881651222705841\n",
      "Iteration 696: G_loss is 4.523412227630615 and D_loss is 0.02378859370946884\n",
      "Iteration 697: G_loss is 4.544026851654053 and D_loss is 0.023359324783086777\n",
      "Iteration 698: G_loss is 1.9351353645324707 and D_loss is 0.3738906979560852\n",
      "Iteration 699: G_loss is 3.3723487854003906 and D_loss is 0.0769229531288147\n",
      "Iteration 700: G_loss is 2.8646047115325928 and D_loss is 0.13181054592132568\n",
      "Iteration 701: G_loss is 2.791840076446533 and D_loss is 0.14201538264751434\n",
      "Iteration 702: G_loss is 5.41290283203125 and D_loss is 0.009708297438919544\n",
      "Iteration 703: G_loss is 4.6771721839904785 and D_loss is 0.020225469022989273\n",
      "Iteration 704: G_loss is 7.714964389801025 and D_loss is 0.0010575195774435997\n",
      "Iteration 705: G_loss is 6.10652494430542 and D_loss is 0.004951441660523415\n",
      "Iteration 706: G_loss is 4.920723915100098 and D_loss is 0.017105616629123688\n",
      "Iteration 707: G_loss is 7.1340837478637695 and D_loss is 0.003000241471454501\n",
      "Iteration 708: G_loss is 5.3314385414123535 and D_loss is 0.012115630321204662\n",
      "Iteration 709: G_loss is 4.192803382873535 and D_loss is 0.03472038730978966\n",
      "Iteration 710: G_loss is 6.025818347930908 and D_loss is 0.012448644265532494\n",
      "Iteration 711: G_loss is 7.570833683013916 and D_loss is 0.016473503783345222\n",
      "Iteration 712: G_loss is 5.331354141235352 and D_loss is 0.010724736377596855\n",
      "Iteration 713: G_loss is 5.055913925170898 and D_loss is 0.015018454752862453\n",
      "Iteration 714: G_loss is 5.338669776916504 and D_loss is 0.3910801112651825\n",
      "Iteration 715: G_loss is 4.92430305480957 and D_loss is 0.019688794389367104\n",
      "Iteration 716: G_loss is 5.249941825866699 and D_loss is 0.01166682317852974\n",
      "Iteration 717: G_loss is 4.17767333984375 and D_loss is 0.03459861874580383\n",
      "Iteration 718: G_loss is 3.2008397579193115 and D_loss is 0.09553615003824234\n",
      "Iteration 719: G_loss is 2.8697738647460938 and D_loss is 0.1358552873134613\n",
      "Iteration 720: G_loss is 2.159013032913208 and D_loss is 0.29940471053123474\n",
      "Iteration 721: G_loss is 3.3763537406921387 and D_loss is 0.07923492044210434\n",
      "Iteration 722: G_loss is 2.090822696685791 and D_loss is 0.32312658429145813\n",
      "Iteration 723: G_loss is 3.084434986114502 and D_loss is 0.10749459266662598\n",
      "Iteration 724: G_loss is 4.304258346557617 and D_loss is 0.030653048306703568\n",
      "Iteration 725: G_loss is 5.472828388214111 and D_loss is 0.009443575516343117\n",
      "Iteration 726: G_loss is 4.578587532043457 and D_loss is 0.02328311651945114\n",
      "Iteration 727: G_loss is 4.9051594734191895 and D_loss is 0.01681755669414997\n",
      "Iteration 728: G_loss is 5.44474458694458 and D_loss is 0.010213488712906837\n",
      "Iteration 729: G_loss is 7.40017557144165 and D_loss is 0.0014487907756119967\n",
      "Iteration 730: G_loss is 4.994154453277588 and D_loss is 0.017017323523759842\n",
      "Iteration 731: G_loss is 8.108260154724121 and D_loss is 0.001589170889928937\n",
      "Iteration 732: G_loss is 7.791696071624756 and D_loss is 0.002108784392476082\n",
      "Iteration 733: G_loss is 7.070719242095947 and D_loss is 0.011636092327535152\n",
      "Iteration 734: G_loss is 7.1405229568481445 and D_loss is 0.007678346708416939\n",
      "Iteration 735: G_loss is 7.148573875427246 and D_loss is 0.003635718021541834\n",
      "Iteration 736: G_loss is 7.510382652282715 and D_loss is 0.0021536690182983875\n",
      "Iteration 737: G_loss is 6.916941165924072 and D_loss is 0.03837212175130844\n",
      "Iteration 738: G_loss is 6.167423248291016 and D_loss is 0.0047576213255524635\n",
      "Iteration 739: G_loss is 6.615818977355957 and D_loss is 0.0030906437896192074\n",
      "Iteration 740: G_loss is 5.758073329925537 and D_loss is 0.007930546998977661\n",
      "Iteration 741: G_loss is 5.8725104331970215 and D_loss is 0.0069586108438670635\n",
      "Iteration 742: G_loss is 6.714056968688965 and D_loss is 0.0034018519800156355\n",
      "Iteration 743: G_loss is 4.88772439956665 and D_loss is 0.0209400225430727\n",
      "Iteration 744: G_loss is 5.582376480102539 and D_loss is 0.008751526474952698\n",
      "Iteration 745: G_loss is 4.228119850158691 and D_loss is 0.03609403222799301\n",
      "Iteration 746: G_loss is 4.766756534576416 and D_loss is 0.01958630606532097\n",
      "Iteration 747: G_loss is 4.45662784576416 and D_loss is 0.0272247102111578\n",
      "Iteration 748: G_loss is 4.413717746734619 and D_loss is 0.06303620338439941\n",
      "Iteration 749: G_loss is 3.6219141483306885 and D_loss is 0.06331333518028259\n",
      "Iteration 750: G_loss is 4.40144157409668 and D_loss is 0.028808968141674995\n",
      "Iteration 751: G_loss is 4.218797206878662 and D_loss is 0.034835197031497955\n",
      "Iteration 752: G_loss is 5.466220378875732 and D_loss is 0.009860467165708542\n",
      "Iteration 753: G_loss is 6.231795787811279 and D_loss is 0.0049124713987112045\n",
      "Iteration 754: G_loss is 6.642723083496094 and D_loss is 0.003839867888018489\n",
      "Iteration 755: G_loss is 8.816192626953125 and D_loss is 0.00040584139060229063\n",
      "Iteration 756: G_loss is 6.517228126525879 and D_loss is 0.004501327406615019\n",
      "Iteration 757: G_loss is 7.264785289764404 and D_loss is 0.0070777651853859425\n",
      "Iteration 758: G_loss is 7.448450088500977 and D_loss is 0.001382797840051353\n",
      "Iteration 759: G_loss is 7.5218915939331055 and D_loss is 0.07633645832538605\n",
      "Iteration 760: G_loss is 8.28609561920166 and D_loss is 0.0006257821223698556\n",
      "Iteration 761: G_loss is 7.395686626434326 and D_loss is 0.001455830060876906\n",
      "Iteration 762: G_loss is 6.4758124351501465 and D_loss is 0.003637739922851324\n",
      "Iteration 763: G_loss is 4.963932991027832 and D_loss is 0.01675962470471859\n",
      "Iteration 764: G_loss is 5.9628167152404785 and D_loss is 0.006107521243393421\n",
      "Iteration 765: G_loss is 4.991198539733887 and D_loss is 0.016036108136177063\n",
      "Iteration 766: G_loss is 7.058974266052246 and D_loss is 0.0021922062151134014\n",
      "Iteration 767: G_loss is 8.379088401794434 and D_loss is 0.001749970018863678\n",
      "Iteration 768: G_loss is 6.466562747955322 and D_loss is 0.0050140065141022205\n",
      "Iteration 769: G_loss is 8.361421585083008 and D_loss is 0.0005603365134447813\n",
      "Iteration 770: G_loss is 8.040742874145508 and D_loss is 0.0008108450565487146\n",
      "Iteration 771: G_loss is 7.389938831329346 and D_loss is 0.001478350255638361\n",
      "Iteration 772: G_loss is 6.6532158851623535 and D_loss is 0.003153521101921797\n",
      "Iteration 773: G_loss is 8.3016357421875 and D_loss is 0.0006451461813412607\n",
      "Iteration 774: G_loss is 7.681535243988037 and D_loss is 0.001088925520889461\n",
      "Iteration 775: G_loss is 8.233341217041016 and D_loss is 0.0006182630895636976\n",
      "Iteration 776: G_loss is 4.504195213317871 and D_loss is 0.025728849694132805\n",
      "Iteration 777: G_loss is 6.511038303375244 and D_loss is 0.0036458480171859264\n",
      "Iteration 778: G_loss is 5.865826606750488 and D_loss is 0.006459595635533333\n",
      "Iteration 779: G_loss is 4.32592248916626 and D_loss is 0.030377285555005074\n",
      "Iteration 780: G_loss is 7.78297758102417 and D_loss is 0.0010184665443375707\n",
      "Iteration 781: G_loss is 7.57885217666626 and D_loss is 0.0016588859725743532\n",
      "Iteration 782: G_loss is 8.11109733581543 and D_loss is 0.0007136680651456118\n",
      "Iteration 783: G_loss is 6.279146671295166 and D_loss is 0.004276482854038477\n",
      "Iteration 784: G_loss is 6.242505073547363 and D_loss is 0.004341877065598965\n",
      "Iteration 785: G_loss is 7.344872951507568 and D_loss is 0.001623491058126092\n",
      "Iteration 786: G_loss is 8.243738174438477 and D_loss is 0.0007401180337183177\n",
      "Iteration 787: G_loss is 7.36768102645874 and D_loss is 0.0013988666469231248\n",
      "Iteration 788: G_loss is 7.629995822906494 and D_loss is 0.0020797275938093662\n",
      "Iteration 789: G_loss is 5.054637908935547 and D_loss is 0.014007670804858208\n",
      "Iteration 790: G_loss is 5.493516445159912 and D_loss is 0.009202000685036182\n",
      "Iteration 791: G_loss is 7.546580791473389 and D_loss is 0.001194927142933011\n",
      "Iteration 792: G_loss is 5.681779384613037 and D_loss is 0.007481443230062723\n",
      "Iteration 793: G_loss is 7.2166948318481445 and D_loss is 0.0016385001363232732\n",
      "Iteration 794: G_loss is 5.595484256744385 and D_loss is 0.00810093991458416\n",
      "Iteration 795: G_loss is 5.290927886962891 and D_loss is 0.011004310101270676\n",
      "Iteration 796: G_loss is 5.029278755187988 and D_loss is 0.014552641659975052\n",
      "Iteration 797: G_loss is 5.880031108856201 and D_loss is 0.006170258391648531\n",
      "Iteration 798: G_loss is 5.481586456298828 and D_loss is 0.012297241017222404\n",
      "Iteration 799: G_loss is 5.392828941345215 and D_loss is 0.012424174696207047\n",
      "Iteration 800: G_loss is 7.830054759979248 and D_loss is 0.003623679280281067\n",
      "Iteration 801: G_loss is 8.597479820251465 and D_loss is 0.0004297516425140202\n",
      "Iteration 802: G_loss is 5.1328535079956055 and D_loss is 0.013794134370982647\n",
      "Iteration 803: G_loss is 5.974334239959717 and D_loss is 0.00987176038324833\n",
      "Iteration 804: G_loss is 5.412111759185791 and D_loss is 0.013445052318274975\n",
      "Iteration 805: G_loss is 8.724406242370605 and D_loss is 0.00132884515915066\n",
      "Iteration 806: G_loss is 6.003259181976318 and D_loss is 0.005608077626675367\n",
      "Iteration 807: G_loss is 6.875052452087402 and D_loss is 0.12437816709280014\n",
      "Iteration 808: G_loss is 6.141167163848877 and D_loss is 0.006668744143098593\n",
      "Iteration 809: G_loss is 5.795722007751465 and D_loss is 0.006651636213064194\n",
      "Iteration 810: G_loss is 4.146457672119141 and D_loss is 0.035162217915058136\n",
      "Iteration 811: G_loss is 4.582476615905762 and D_loss is 0.022643836215138435\n",
      "Iteration 812: G_loss is 4.453983306884766 and D_loss is 0.02582487091422081\n",
      "Iteration 813: G_loss is 4.071536540985107 and D_loss is 0.03821362182497978\n",
      "Iteration 814: G_loss is 4.118988990783691 and D_loss is 0.036605335772037506\n",
      "Iteration 815: G_loss is 3.7371397018432617 and D_loss is 0.053849443793296814\n",
      "Iteration 816: G_loss is 4.861433506011963 and D_loss is 0.017150556668639183\n",
      "Iteration 817: G_loss is 7.414422035217285 and D_loss is 0.0013329758075997233\n",
      "Iteration 818: G_loss is 6.519125461578369 and D_loss is 0.009574336931109428\n",
      "Iteration 819: G_loss is 5.158600807189941 and D_loss is 0.012657210230827332\n",
      "Iteration 820: G_loss is 7.2483296394348145 and D_loss is 0.002674562856554985\n",
      "Iteration 821: G_loss is 5.508516311645508 and D_loss is 0.011885605752468109\n",
      "Iteration 822: G_loss is 7.191333770751953 and D_loss is 0.0017109494656324387\n",
      "Iteration 823: G_loss is 5.704403877258301 and D_loss is 0.009968316182494164\n",
      "Iteration 824: G_loss is 5.974461078643799 and D_loss is 0.013406995683908463\n",
      "Iteration 825: G_loss is 6.687870979309082 and D_loss is 0.0032764882780611515\n",
      "Iteration 826: G_loss is 6.759306907653809 and D_loss is 0.0025923692155629396\n",
      "Iteration 827: G_loss is 8.468816757202148 and D_loss is 0.002773983869701624\n",
      "Iteration 828: G_loss is 6.591361045837402 and D_loss is 0.013268320821225643\n",
      "Iteration 829: G_loss is 6.894341945648193 and D_loss is 0.0030680373311042786\n",
      "Iteration 830: G_loss is 9.916240692138672 and D_loss is 0.030986297875642776\n",
      "Iteration 831: G_loss is 7.471975326538086 and D_loss is 0.0014758810866624117\n",
      "Iteration 832: G_loss is 7.167244911193848 and D_loss is 0.001787327928468585\n",
      "Iteration 833: G_loss is 7.875667095184326 and D_loss is 0.0008522939751856029\n",
      "Iteration 834: G_loss is 6.361506462097168 and D_loss is 0.0038176027592271566\n",
      "Iteration 835: G_loss is 7.937015533447266 and D_loss is 0.0012696280609816313\n",
      "Iteration 836: G_loss is 6.172108173370361 and D_loss is 0.00539747066795826\n",
      "Iteration 837: G_loss is 5.834057331085205 and D_loss is 0.011877577751874924\n",
      "Iteration 838: G_loss is 7.586784839630127 and D_loss is 0.0012025831965729594\n",
      "Iteration 839: G_loss is 6.267725944519043 and D_loss is 0.00423392141237855\n",
      "Iteration 840: G_loss is 5.678579807281494 and D_loss is 0.0074859014712274075\n",
      "Iteration 841: G_loss is 8.627876281738281 and D_loss is 0.0004212261410430074\n",
      "Iteration 842: G_loss is 6.1754608154296875 and D_loss is 0.0045357090421020985\n",
      "Iteration 843: G_loss is 4.746169090270996 and D_loss is 0.01921866089105606\n",
      "Iteration 844: G_loss is 4.708246231079102 and D_loss is 0.020088737830519676\n",
      "Iteration 845: G_loss is 5.628140926361084 and D_loss is 0.008062902837991714\n",
      "Iteration 846: G_loss is 5.636067867279053 and D_loss is 0.02317548543214798\n",
      "Iteration 847: G_loss is 7.543408393859863 and D_loss is 0.0011722724884748459\n",
      "Iteration 848: G_loss is 4.720490455627441 and D_loss is 0.01972651109099388\n",
      "Iteration 849: G_loss is 5.6984052658081055 and D_loss is 0.007586087565869093\n",
      "Iteration 850: G_loss is 5.768794536590576 and D_loss is 0.006886269897222519\n",
      "Iteration 851: G_loss is 6.199373722076416 and D_loss is 0.004523766227066517\n",
      "Iteration 852: G_loss is 7.300933837890625 and D_loss is 0.0017101626144722104\n",
      "Iteration 853: G_loss is 6.983405113220215 and D_loss is 0.0020374490413814783\n",
      "Iteration 854: G_loss is 6.395704746246338 and D_loss is 0.0037113723810762167\n",
      "Iteration 855: G_loss is 7.78410005569458 and D_loss is 0.0012889066711068153\n",
      "Iteration 856: G_loss is 6.099142074584961 and D_loss is 0.005414636805653572\n",
      "Iteration 857: G_loss is 7.841904163360596 and D_loss is 0.0013784457696601748\n",
      "Iteration 858: G_loss is 7.4538187980651855 and D_loss is 0.008789651095867157\n",
      "Iteration 859: G_loss is 5.093870639801025 and D_loss is 0.01361975260078907\n",
      "Iteration 860: G_loss is 5.813838958740234 and D_loss is 0.0066434904001653194\n",
      "Iteration 861: G_loss is 8.72325325012207 and D_loss is 0.0016798339784145355\n",
      "Iteration 862: G_loss is 5.155537128448486 and D_loss is 0.012884752824902534\n",
      "Iteration 863: G_loss is 6.812069416046143 and D_loss is 0.289998322725296\n",
      "Iteration 864: G_loss is 5.44718074798584 and D_loss is 0.010184284299612045\n",
      "Iteration 865: G_loss is 6.114593029022217 and D_loss is 0.004902268759906292\n",
      "Iteration 866: G_loss is 4.292055130004883 and D_loss is 0.030558215454220772\n",
      "Iteration 867: G_loss is 4.6443891525268555 and D_loss is 0.021284278482198715\n",
      "Iteration 868: G_loss is 3.388449192047119 and D_loss is 0.0767328217625618\n",
      "Iteration 869: G_loss is 3.442821979522705 and D_loss is 0.07256610691547394\n",
      "Iteration 870: G_loss is 4.032072067260742 and D_loss is 0.03963755443692207\n",
      "Iteration 871: G_loss is 3.069666862487793 and D_loss is 0.10782239586114883\n",
      "Iteration 872: G_loss is 3.570769786834717 and D_loss is 0.06348692625761032\n",
      "Iteration 873: G_loss is 4.0348896980285645 and D_loss is 0.039627473801374435\n",
      "Iteration 874: G_loss is 4.14199161529541 and D_loss is 0.03562014922499657\n",
      "Iteration 875: G_loss is 6.068904876708984 and D_loss is 0.00509758573025465\n",
      "Iteration 876: G_loss is 6.37623405456543 and D_loss is 0.0037440115120261908\n",
      "Iteration 877: G_loss is 6.557202339172363 and D_loss is 0.0031353572849184275\n",
      "Iteration 878: G_loss is 5.422769069671631 and D_loss is 0.00978748220950365\n",
      "Iteration 879: G_loss is 7.263459205627441 and D_loss is 0.001571398344822228\n",
      "Iteration 880: G_loss is 8.236014366149902 and D_loss is 0.0005844966508448124\n",
      "Iteration 881: G_loss is 6.694469451904297 and D_loss is 0.002730651991441846\n",
      "Iteration 882: G_loss is 7.044624328613281 and D_loss is 0.0019563762471079826\n",
      "Iteration 883: G_loss is 5.360334396362305 and D_loss is 0.010295704007148743\n",
      "Iteration 884: G_loss is 5.526561737060547 and D_loss is 0.008806219324469566\n",
      "Iteration 885: G_loss is 8.100698471069336 and D_loss is 0.0006599627085961401\n",
      "Iteration 886: G_loss is 6.340217113494873 and D_loss is 0.0038456222973763943\n",
      "Iteration 887: G_loss is 7.986313343048096 and D_loss is 0.0007647082093171775\n",
      "Iteration 888: G_loss is 6.3291215896606445 and D_loss is 0.003903439501300454\n",
      "Iteration 889: G_loss is 9.652463912963867 and D_loss is 0.00015986646758392453\n",
      "Iteration 890: G_loss is 7.086569786071777 and D_loss is 0.0020477098878473043\n",
      "Iteration 891: G_loss is 6.4504313468933105 and D_loss is 0.003388040466234088\n",
      "Iteration 892: G_loss is 6.3870439529418945 and D_loss is 0.003615307854488492\n",
      "Iteration 893: G_loss is 4.881600379943848 and D_loss is 0.016380004584789276\n",
      "Iteration 894: G_loss is 6.668418884277344 and D_loss is 0.002755936002358794\n",
      "Iteration 895: G_loss is 6.535696029663086 and D_loss is 0.0031161943916231394\n",
      "Iteration 896: G_loss is 5.885824203491211 and D_loss is 0.006104713771492243\n",
      "Iteration 897: G_loss is 8.58739185333252 and D_loss is 0.0004500387003645301\n",
      "Iteration 898: G_loss is 6.621792793273926 and D_loss is 0.0028473581187427044\n",
      "Iteration 899: G_loss is 7.07188606262207 and D_loss is 0.0019107990665361285\n",
      "Iteration 900: G_loss is 7.204914093017578 and D_loss is 0.0016152752796187997\n",
      "Iteration 901: G_loss is 7.291588306427002 and D_loss is 0.0021693240851163864\n",
      "Iteration 902: G_loss is 5.720373630523682 and D_loss is 0.007012477610260248\n",
      "Iteration 903: G_loss is 7.196266174316406 and D_loss is 0.001625034841708839\n",
      "Iteration 904: G_loss is 5.625352382659912 and D_loss is 0.007722729351371527\n",
      "Iteration 905: G_loss is 8.187088966369629 and D_loss is 0.00059377436991781\n",
      "Iteration 906: G_loss is 9.078371047973633 and D_loss is 0.00025558084598742425\n",
      "Iteration 907: G_loss is 5.722049713134766 and D_loss is 0.006965178996324539\n",
      "Iteration 908: G_loss is 5.955050468444824 and D_loss is 0.005736711900681257\n",
      "Iteration 909: G_loss is 6.283129692077637 and D_loss is 0.006142917089164257\n",
      "Iteration 910: G_loss is 7.590538024902344 and D_loss is 0.0011426479322835803\n",
      "Iteration 911: G_loss is 5.609260559082031 and D_loss is 0.008384112268686295\n",
      "Iteration 912: G_loss is 5.9062724113464355 and D_loss is 0.03229621797800064\n",
      "Iteration 913: G_loss is 7.575375080108643 and D_loss is 0.006883962079882622\n",
      "Iteration 914: G_loss is 7.193079471588135 and D_loss is 0.0016795966075733304\n",
      "Iteration 915: G_loss is 6.705883979797363 and D_loss is 0.0029093201737850904\n",
      "Iteration 916: G_loss is 6.382358551025391 and D_loss is 0.008297578431665897\n",
      "Iteration 917: G_loss is 5.101480007171631 and D_loss is 0.012988348491489887\n",
      "Iteration 918: G_loss is 6.2189812660217285 and D_loss is 0.004232446197420359\n",
      "Iteration 919: G_loss is 4.607531547546387 and D_loss is 0.022257691249251366\n",
      "Iteration 920: G_loss is 5.263601303100586 and D_loss is 0.011048637330532074\n",
      "Iteration 921: G_loss is 5.6849870681762695 and D_loss is 0.007436632178723812\n",
      "Iteration 922: G_loss is 5.232702255249023 and D_loss is 0.011622140184044838\n",
      "Iteration 923: G_loss is 6.40809965133667 and D_loss is 0.003503408282995224\n",
      "Iteration 924: G_loss is 7.073298931121826 and D_loss is 0.002061640378087759\n",
      "Iteration 925: G_loss is 6.338872909545898 and D_loss is 0.0043081967160105705\n",
      "Iteration 926: G_loss is 5.818331718444824 and D_loss is 0.006395654287189245\n",
      "Iteration 927: G_loss is 5.3865742683410645 and D_loss is 0.010270710103213787\n",
      "Iteration 928: G_loss is 4.739255905151367 and D_loss is 0.020514748990535736\n",
      "Iteration 929: G_loss is 6.068513870239258 and D_loss is 0.0049613299779593945\n",
      "Iteration 930: G_loss is 8.330803871154785 and D_loss is 0.0005564948660321534\n",
      "Iteration 931: G_loss is 6.557070732116699 and D_loss is 0.005686450749635696\n",
      "Iteration 932: G_loss is 6.036512851715088 and D_loss is 0.11547315120697021\n",
      "Iteration 933: G_loss is 6.305736541748047 and D_loss is 0.01531907543540001\n",
      "Iteration 934: G_loss is 4.388858795166016 and D_loss is 0.028423016890883446\n",
      "Iteration 935: G_loss is 3.9814343452453613 and D_loss is 0.04060761258006096\n",
      "Iteration 936: G_loss is 2.0070698261260986 and D_loss is 0.3418843150138855\n",
      "Iteration 937: G_loss is 4.285401344299316 and D_loss is 0.02977721020579338\n",
      "Iteration 938: G_loss is 6.9911699295043945 and D_loss is 0.0021822683047503233\n",
      "Iteration 939: G_loss is 4.975623607635498 and D_loss is 0.033391594886779785\n",
      "Iteration 940: G_loss is 8.004313468933105 and D_loss is 0.0007314957911148667\n",
      "Iteration 941: G_loss is 7.4748687744140625 and D_loss is 0.0017198629211634398\n",
      "Iteration 942: G_loss is 5.5357985496521 and D_loss is 0.010363128036260605\n",
      "Iteration 943: G_loss is 6.595937252044678 and D_loss is 0.09904550015926361\n",
      "Iteration 944: G_loss is 8.15294361114502 and D_loss is 0.00577936228364706\n",
      "Iteration 945: G_loss is 8.158880233764648 and D_loss is 0.007032275199890137\n",
      "Iteration 946: G_loss is 8.08563232421875 and D_loss is 0.005446463357657194\n",
      "Iteration 947: G_loss is 4.837652206420898 and D_loss is 0.01749160699546337\n",
      "Iteration 948: G_loss is 3.0534603595733643 and D_loss is 0.10764321684837341\n",
      "Iteration 949: G_loss is 5.003967761993408 and D_loss is 0.01997910439968109\n",
      "Iteration 950: G_loss is 2.104372262954712 and D_loss is 0.3066745698451996\n",
      "Iteration 951: G_loss is 2.557718276977539 and D_loss is 0.24292753636837006\n",
      "Iteration 952: G_loss is 3.8239200115203857 and D_loss is 0.05080961808562279\n",
      "Iteration 953: G_loss is 5.351626873016357 and D_loss is 0.0449058823287487\n",
      "Iteration 954: G_loss is 7.29473352432251 and D_loss is 0.006018585059791803\n",
      "Iteration 955: G_loss is 8.845699310302734 and D_loss is 0.3563452661037445\n",
      "Iteration 956: G_loss is 4.304244518280029 and D_loss is 0.044472768902778625\n",
      "Iteration 957: G_loss is 3.1036744117736816 and D_loss is 0.12625670433044434\n",
      "Iteration 958: G_loss is 4.989223957061768 and D_loss is 0.0159777719527483\n",
      "Iteration 959: G_loss is 1.9308586120605469 and D_loss is 0.41297829151153564\n",
      "Iteration 960: G_loss is 2.901017427444458 and D_loss is 0.13662327826023102\n",
      "Iteration 961: G_loss is 2.891512393951416 and D_loss is 0.13693460822105408\n",
      "Iteration 962: G_loss is 1.9695627689361572 and D_loss is 0.3841537833213806\n",
      "Iteration 963: G_loss is 6.302799224853516 and D_loss is 0.0049860114231705666\n",
      "Iteration 964: G_loss is 5.456775665283203 and D_loss is 0.00995857734233141\n",
      "Iteration 965: G_loss is 6.956021308898926 and D_loss is 0.0028445799835026264\n",
      "Iteration 966: G_loss is 6.5641279220581055 and D_loss is 0.003780737752094865\n",
      "Iteration 967: G_loss is 8.609081268310547 and D_loss is 0.0051743038929998875\n",
      "Iteration 968: G_loss is 9.325761795043945 and D_loss is 0.0003861951408907771\n",
      "Iteration 969: G_loss is 6.660888671875 and D_loss is 0.25124040246009827\n",
      "Iteration 970: G_loss is 9.24601936340332 and D_loss is 0.0033609087113291025\n",
      "Iteration 971: G_loss is 7.811654567718506 and D_loss is 0.0157951507717371\n",
      "Iteration 972: G_loss is 5.434059143066406 and D_loss is 0.010121920146048069\n",
      "Iteration 973: G_loss is 4.617560386657715 and D_loss is 0.022626537829637527\n",
      "Iteration 974: G_loss is 5.326612949371338 and D_loss is 0.012379336170852184\n",
      "Iteration 975: G_loss is 6.230014324188232 and D_loss is 0.010089091956615448\n",
      "Iteration 976: G_loss is 4.300552845001221 and D_loss is 0.031338561326265335\n",
      "Iteration 977: G_loss is 2.975613594055176 and D_loss is 0.12368820607662201\n",
      "Iteration 978: G_loss is 4.008882522583008 and D_loss is 0.04213450849056244\n",
      "Iteration 979: G_loss is 5.082880020141602 and D_loss is 0.014188027009367943\n",
      "Iteration 980: G_loss is 2.701937198638916 and D_loss is 0.16417433321475983\n",
      "Iteration 981: G_loss is 3.1340792179107666 and D_loss is 0.10442347079515457\n",
      "Iteration 982: G_loss is 5.568046569824219 and D_loss is 0.009448491968214512\n",
      "Iteration 983: G_loss is 3.0398106575012207 and D_loss is 0.11462701112031937\n",
      "Iteration 984: G_loss is 7.353199005126953 and D_loss is 0.008736285381019115\n",
      "Iteration 985: G_loss is 7.82977294921875 and D_loss is 0.005966663360595703\n",
      "Iteration 986: G_loss is 9.822532653808594 and D_loss is 0.01567026600241661\n",
      "Iteration 987: G_loss is 11.761853218078613 and D_loss is 0.08452708274126053\n",
      "Iteration 988: G_loss is 8.88438606262207 and D_loss is 0.02986212819814682\n",
      "Iteration 989: G_loss is 13.384161949157715 and D_loss is 0.01700698398053646\n",
      "Iteration 990: G_loss is 9.984816551208496 and D_loss is 0.010243077762424946\n",
      "Iteration 991: G_loss is 10.87690258026123 and D_loss is 2.396108388900757\n",
      "Iteration 992: G_loss is 7.602662086486816 and D_loss is 0.0878414511680603\n",
      "Iteration 993: G_loss is 5.109732151031494 and D_loss is 0.01311547216027975\n",
      "Iteration 994: G_loss is 3.443411350250244 and D_loss is 0.07113436609506607\n",
      "Iteration 995: G_loss is 1.6515018939971924 and D_loss is 0.5312812924385071\n",
      "Iteration 996: G_loss is 1.005308985710144 and D_loss is 1.5523320436477661\n",
      "Iteration 997: G_loss is 0.9401254653930664 and D_loss is 1.859237551689148\n",
      "Iteration 998: G_loss is 1.6249477863311768 and D_loss is 0.5533856749534607\n",
      "Iteration 999: G_loss is 0.9752362370491028 and D_loss is 1.7260032892227173\n",
      "Iteration 1000: G_loss is 4.302429676055908 and D_loss is 0.03031090274453163\n",
      "Iteration 1001: G_loss is 5.495846271514893 and D_loss is 0.009133734740316868\n",
      "Iteration 1002: G_loss is 8.647459983825684 and D_loss is 0.0010263558942824602\n",
      "Iteration 1003: G_loss is 8.248641014099121 and D_loss is 0.0005942315910942852\n",
      "Iteration 1004: G_loss is 11.636749267578125 and D_loss is 0.0012690410949289799\n",
      "Iteration 1005: G_loss is 10.79438304901123 and D_loss is 0.007232884410768747\n",
      "Iteration 1006: G_loss is 11.010125160217285 and D_loss is 0.011365569196641445\n",
      "Iteration 1007: G_loss is 12.311415672302246 and D_loss is 0.8297455310821533\n",
      "Iteration 1008: G_loss is 12.567880630493164 and D_loss is 0.025614803656935692\n",
      "Iteration 1009: G_loss is 10.85880184173584 and D_loss is 0.02885095775127411\n",
      "Iteration 1010: G_loss is 10.84712028503418 and D_loss is 0.13353028893470764\n",
      "Iteration 1011: G_loss is 8.534319877624512 and D_loss is 0.03479784354567528\n",
      "Iteration 1012: G_loss is 10.747491836547852 and D_loss is 0.004087022505700588\n",
      "Iteration 1013: G_loss is 8.478225708007812 and D_loss is 0.005124220624566078\n",
      "Iteration 1014: G_loss is 7.8160600662231445 and D_loss is 0.005668111611157656\n",
      "Iteration 1015: G_loss is 8.17671012878418 and D_loss is 0.002030814066529274\n",
      "Iteration 1016: G_loss is 7.051875591278076 and D_loss is 0.0030016289092600346\n",
      "Iteration 1017: G_loss is 6.6072163581848145 and D_loss is 0.01260708924382925\n",
      "Iteration 1018: G_loss is 7.0838093757629395 and D_loss is 0.0022946838289499283\n",
      "Iteration 1019: G_loss is 7.152408123016357 and D_loss is 0.0028001756872981787\n",
      "Iteration 1020: G_loss is 6.593016624450684 and D_loss is 0.003233426483348012\n",
      "Iteration 1021: G_loss is 7.337973594665527 and D_loss is 0.0014503090642392635\n",
      "Iteration 1022: G_loss is 6.512200832366943 and D_loss is 0.003687512129545212\n",
      "Iteration 1023: G_loss is 6.841795444488525 and D_loss is 0.003092508763074875\n",
      "Iteration 1024: G_loss is 5.9815993309021 and D_loss is 0.005915774963796139\n",
      "Iteration 1025: G_loss is 5.6399006843566895 and D_loss is 0.008404639549553394\n",
      "Iteration 1026: G_loss is 4.839073181152344 and D_loss is 0.018244396895170212\n",
      "Iteration 1027: G_loss is 5.320613384246826 and D_loss is 0.012088513001799583\n",
      "Iteration 1028: G_loss is 4.204308986663818 and D_loss is 0.03462058678269386\n",
      "Iteration 1029: G_loss is 5.180139064788818 and D_loss is 0.012953255325555801\n",
      "Iteration 1030: G_loss is 4.027368545532227 and D_loss is 0.04166099429130554\n",
      "Iteration 1031: G_loss is 5.247568130493164 and D_loss is 0.01200614869594574\n",
      "Iteration 1032: G_loss is 5.29829740524292 and D_loss is 0.011496937833726406\n",
      "Iteration 1033: G_loss is 4.491410732269287 and D_loss is 0.02661891281604767\n",
      "Iteration 1034: G_loss is 4.11525821685791 and D_loss is 0.03852749615907669\n",
      "Iteration 1035: G_loss is 4.4688401222229 and D_loss is 0.02643130160868168\n",
      "Iteration 1036: G_loss is 3.519171714782715 and D_loss is 0.07092389464378357\n",
      "Iteration 1037: G_loss is 3.6363117694854736 and D_loss is 0.06292380392551422\n",
      "Iteration 1038: G_loss is 4.794233322143555 and D_loss is 0.019396206364035606\n",
      "Iteration 1039: G_loss is 4.9199347496032715 and D_loss is 0.017781030386686325\n",
      "Iteration 1040: G_loss is 2.7326126098632812 and D_loss is 0.1661660224199295\n",
      "Iteration 1041: G_loss is 4.970968723297119 and D_loss is 0.016375912353396416\n",
      "Iteration 1042: G_loss is 3.4288206100463867 and D_loss is 0.07800456136465073\n",
      "Iteration 1043: G_loss is 4.052789688110352 and D_loss is 0.04186566174030304\n",
      "Iteration 1044: G_loss is 4.80424165725708 and D_loss is 0.019589433446526527\n",
      "Iteration 1045: G_loss is 4.771963119506836 and D_loss is 0.02064763568341732\n",
      "Iteration 1046: G_loss is 5.083376884460449 and D_loss is 0.014658288098871708\n",
      "Iteration 1047: G_loss is 5.298553943634033 and D_loss is 0.011822955682873726\n",
      "Iteration 1048: G_loss is 4.770858287811279 and D_loss is 0.02158588543534279\n",
      "Iteration 1049: G_loss is 5.030238628387451 and D_loss is 0.015920091420412064\n",
      "Iteration 1050: G_loss is 5.167697906494141 and D_loss is 0.014070060104131699\n",
      "Iteration 1051: G_loss is 4.967907905578613 and D_loss is 0.016992563381791115\n",
      "Iteration 1052: G_loss is 5.085535049438477 and D_loss is 0.015009305439889431\n",
      "Iteration 1053: G_loss is 6.29929256439209 and D_loss is 0.0055376868695020676\n",
      "Iteration 1054: G_loss is 6.51527214050293 and D_loss is 0.003961822018027306\n",
      "Iteration 1055: G_loss is 5.397124290466309 and D_loss is 0.01373114064335823\n",
      "Iteration 1056: G_loss is 5.522794246673584 and D_loss is 0.014455631375312805\n",
      "Iteration 1057: G_loss is 5.293720722198486 and D_loss is 0.012593363411724567\n",
      "Iteration 1058: G_loss is 4.290189743041992 and D_loss is 0.033804163336753845\n",
      "Iteration 1059: G_loss is 5.435384273529053 and D_loss is 0.0107970479875803\n",
      "Iteration 1060: G_loss is 6.136541366577148 and D_loss is 0.005296642892062664\n",
      "Iteration 1061: G_loss is 4.957694053649902 and D_loss is 0.016791226342320442\n",
      "Iteration 1062: G_loss is 4.032131671905518 and D_loss is 0.042456600815057755\n",
      "Iteration 1063: G_loss is 4.602282524108887 and D_loss is 0.029210999608039856\n",
      "Iteration 1064: G_loss is 4.480584144592285 and D_loss is 0.027830906212329865\n",
      "Iteration 1065: G_loss is 5.012936115264893 and D_loss is 0.016027554869651794\n",
      "Iteration 1066: G_loss is 5.716187477111816 and D_loss is 0.025736190378665924\n",
      "Iteration 1067: G_loss is 7.2405266761779785 and D_loss is 0.0036784629337489605\n",
      "Iteration 1068: G_loss is 4.153700351715088 and D_loss is 0.038114871829748154\n",
      "Iteration 1069: G_loss is 6.146562576293945 and D_loss is 0.00504769803956151\n",
      "Iteration 1070: G_loss is 5.04226541519165 and D_loss is 0.019251152873039246\n",
      "Iteration 1071: G_loss is 5.2535719871521 and D_loss is 0.012819617055356503\n",
      "Iteration 1072: G_loss is 5.7845683097839355 and D_loss is 0.007448009680956602\n",
      "Iteration 1073: G_loss is 6.266598701477051 and D_loss is 0.02539461851119995\n",
      "Iteration 1074: G_loss is 4.411836624145508 and D_loss is 0.03174212947487831\n",
      "Iteration 1075: G_loss is 5.551115036010742 and D_loss is 0.01724417135119438\n",
      "Iteration 1076: G_loss is 4.394193649291992 and D_loss is 0.033537812530994415\n",
      "Iteration 1077: G_loss is 5.6571736335754395 and D_loss is 0.017349593341350555\n",
      "Iteration 1078: G_loss is 4.010979652404785 and D_loss is 0.05473814904689789\n",
      "Iteration 1079: G_loss is 4.041065216064453 and D_loss is 0.05242443457245827\n",
      "Iteration 1080: G_loss is 4.9876627922058105 and D_loss is 0.025099992752075195\n",
      "Iteration 1081: G_loss is 4.714809417724609 and D_loss is 0.7025707364082336\n",
      "Iteration 1082: G_loss is 5.804029941558838 and D_loss is 0.009444620460271835\n",
      "Iteration 1083: G_loss is 3.0846734046936035 and D_loss is 0.11561743915081024\n",
      "Iteration 1084: G_loss is 5.545389175415039 and D_loss is 0.009413927793502808\n",
      "Iteration 1085: G_loss is 3.6329503059387207 and D_loss is 0.06585381180047989\n",
      "Iteration 1086: G_loss is 2.8807427883148193 and D_loss is 0.14279218018054962\n",
      "Iteration 1087: G_loss is 4.0989789962768555 and D_loss is 0.04010972008109093\n",
      "Iteration 1088: G_loss is 4.2804975509643555 and D_loss is 0.033868975937366486\n",
      "Iteration 1089: G_loss is 5.142570972442627 and D_loss is 0.013988649472594261\n",
      "Iteration 1090: G_loss is 6.4646196365356445 and D_loss is 0.0036632795818150043\n",
      "Iteration 1091: G_loss is 4.825995445251465 and D_loss is 0.018946291878819466\n",
      "Iteration 1092: G_loss is 6.279230117797852 and D_loss is 0.004686341155320406\n",
      "Iteration 1093: G_loss is 5.071502208709717 and D_loss is 0.014575062319636345\n",
      "Iteration 1094: G_loss is 4.856196880340576 and D_loss is 0.017908357083797455\n",
      "Iteration 1095: G_loss is 5.38707971572876 and D_loss is 0.010532804764807224\n",
      "Iteration 1096: G_loss is 2.2723464965820312 and D_loss is 0.26892590522766113\n",
      "Iteration 1097: G_loss is 3.6141326427459717 and D_loss is 0.06277189403772354\n",
      "Iteration 1098: G_loss is 4.974181175231934 and D_loss is 0.015786798670887947\n",
      "Iteration 1099: G_loss is 4.581934928894043 and D_loss is 0.02349110320210457\n",
      "Iteration 1100: G_loss is 5.321897506713867 and D_loss is 0.01078423298895359\n",
      "Iteration 1101: G_loss is 6.563179969787598 and D_loss is 0.014485079795122147\n",
      "Iteration 1102: G_loss is 6.438458442687988 and D_loss is 0.009209481999278069\n",
      "Iteration 1103: G_loss is 5.399295330047607 and D_loss is 0.010242738761007786\n",
      "Iteration 1104: G_loss is 6.986263275146484 and D_loss is 0.0021166640799492598\n",
      "Iteration 1105: G_loss is 6.810371398925781 and D_loss is 0.11574586480855942\n",
      "Iteration 1106: G_loss is 7.852991580963135 and D_loss is 0.0008841066737659276\n",
      "Iteration 1107: G_loss is 3.6058156490325928 and D_loss is 0.0639755055308342\n",
      "Iteration 1108: G_loss is 6.787763595581055 and D_loss is 0.0024948352947831154\n",
      "Iteration 1109: G_loss is 6.3407673835754395 and D_loss is 0.003736024722456932\n",
      "Iteration 1110: G_loss is 4.860244274139404 and D_loss is 0.016823379322886467\n",
      "Iteration 1111: G_loss is 7.970462799072266 and D_loss is 0.004663586150854826\n",
      "Iteration 1112: G_loss is 5.162812232971191 and D_loss is 0.01222705002874136\n",
      "Iteration 1113: G_loss is 5.336690902709961 and D_loss is 0.012095445767045021\n",
      "Iteration 1114: G_loss is 4.490041732788086 and D_loss is 0.02453235350549221\n",
      "Iteration 1115: G_loss is 4.718532085418701 and D_loss is 0.028619222342967987\n",
      "Iteration 1116: G_loss is 7.826771259307861 and D_loss is 0.002807754324749112\n",
      "Iteration 1117: G_loss is 6.569436550140381 and D_loss is 0.004546090494841337\n",
      "Iteration 1118: G_loss is 3.307164192199707 and D_loss is 0.07988692820072174\n",
      "Iteration 1119: G_loss is 6.707958221435547 and D_loss is 0.0036400945391505957\n",
      "Iteration 1120: G_loss is 4.868993759155273 and D_loss is 0.13570119440555573\n",
      "Iteration 1121: G_loss is 5.61844539642334 and D_loss is 0.027285443618893623\n",
      "Iteration 1122: G_loss is 5.566416263580322 and D_loss is 0.008249728009104729\n",
      "Iteration 1123: G_loss is 3.737948417663574 and D_loss is 0.052295342087745667\n",
      "Iteration 1124: G_loss is 6.065787315368652 and D_loss is 0.23996850848197937\n",
      "Iteration 1125: G_loss is 3.4065003395080566 and D_loss is 0.07397525757551193\n",
      "Iteration 1126: G_loss is 3.268447160720825 and D_loss is 0.08478674292564392\n",
      "Iteration 1127: G_loss is 2.816333770751953 and D_loss is 0.1350063532590866\n",
      "Iteration 1128: G_loss is 3.4699511528015137 and D_loss is 0.06877479702234268\n",
      "Iteration 1129: G_loss is 4.415761470794678 and D_loss is 0.026274727657437325\n",
      "Iteration 1130: G_loss is 2.4898576736450195 and D_loss is 0.1964053362607956\n",
      "Iteration 1131: G_loss is 2.349972724914551 and D_loss is 0.22861696779727936\n",
      "Iteration 1132: G_loss is 2.634488105773926 and D_loss is 0.16920962929725647\n",
      "Iteration 1133: G_loss is 5.993428707122803 and D_loss is 0.005678688641637564\n",
      "Iteration 1134: G_loss is 5.055540561676025 and D_loss is 0.014959929510951042\n",
      "Iteration 1135: G_loss is 9.768203735351562 and D_loss is 0.0039174240082502365\n",
      "Iteration 1136: G_loss is 7.111755847930908 and D_loss is 0.011737694963812828\n",
      "Iteration 1137: G_loss is 11.55427074432373 and D_loss is 0.010058887302875519\n",
      "Iteration 1138: G_loss is 11.130508422851562 and D_loss is 0.13661928474903107\n",
      "Iteration 1139: G_loss is 9.918658256530762 and D_loss is 0.09020332247018814\n",
      "Iteration 1140: G_loss is 7.987284183502197 and D_loss is 0.003064186777919531\n",
      "Iteration 1141: G_loss is 7.958532333374023 and D_loss is 0.006040138658136129\n",
      "Iteration 1142: G_loss is 8.853104591369629 and D_loss is 0.002299770014360547\n",
      "Iteration 1143: G_loss is 11.26402759552002 and D_loss is 0.0058295694179832935\n",
      "Iteration 1144: G_loss is 5.956304550170898 and D_loss is 0.008819229900836945\n",
      "Iteration 1145: G_loss is 8.46821117401123 and D_loss is 0.14489756524562836\n",
      "Iteration 1146: G_loss is 6.530002117156982 and D_loss is 0.06091337651014328\n",
      "Iteration 1147: G_loss is 7.588626861572266 and D_loss is 0.0011292807757854462\n",
      "Iteration 1148: G_loss is 5.967450141906738 and D_loss is 0.00589956808835268\n",
      "Iteration 1149: G_loss is 5.478501796722412 and D_loss is 0.009138651192188263\n",
      "Iteration 1150: G_loss is 6.402660369873047 and D_loss is 0.0038746949285268784\n",
      "Iteration 1151: G_loss is 7.6646857261657715 and D_loss is 0.003990067169070244\n",
      "Iteration 1152: G_loss is 3.7285537719726562 and D_loss is 0.051412902772426605\n",
      "Iteration 1153: G_loss is 4.655556678771973 and D_loss is 0.02644246630370617\n",
      "Iteration 1154: G_loss is 3.7141127586364746 and D_loss is 0.052249930799007416\n",
      "Iteration 1155: G_loss is 3.6909589767456055 and D_loss is 0.05311518907546997\n",
      "Iteration 1156: G_loss is 4.142051696777344 and D_loss is 0.033871982246637344\n",
      "Iteration 1157: G_loss is 2.252875328063965 and D_loss is 0.2468566745519638\n",
      "Iteration 1158: G_loss is 5.003875732421875 and D_loss is 0.014162282459437847\n",
      "Iteration 1159: G_loss is 3.7515101432800293 and D_loss is 0.05061693117022514\n",
      "Iteration 1160: G_loss is 4.5674262046813965 and D_loss is 0.02203064039349556\n",
      "Iteration 1161: G_loss is 6.874889850616455 and D_loss is 0.0023030731827020645\n",
      "Iteration 1162: G_loss is 5.695793151855469 and D_loss is 0.015145247802138329\n",
      "Iteration 1163: G_loss is 6.512396812438965 and D_loss is 0.00903342291712761\n",
      "Iteration 1164: G_loss is 4.4725728034973145 and D_loss is 0.10808040201663971\n",
      "Iteration 1165: G_loss is 5.979401588439941 and D_loss is 0.006334277335554361\n",
      "Iteration 1166: G_loss is 2.981351375579834 and D_loss is 0.1124323233962059\n",
      "Iteration 1167: G_loss is 5.373083591461182 and D_loss is 0.009868429973721504\n",
      "Iteration 1168: G_loss is 7.097682952880859 and D_loss is 0.007818127050995827\n",
      "Iteration 1169: G_loss is 6.704098701477051 and D_loss is 0.16520129144191742\n",
      "Iteration 1170: G_loss is 6.546259880065918 and D_loss is 0.006318169645965099\n",
      "Iteration 1171: G_loss is 7.405205726623535 and D_loss is 0.025173082947731018\n",
      "Iteration 1172: G_loss is 7.855779647827148 and D_loss is 0.002418787684291601\n",
      "Iteration 1173: G_loss is 6.041128158569336 and D_loss is 0.03214748576283455\n",
      "Iteration 1174: G_loss is 6.027414321899414 and D_loss is 0.005867202766239643\n",
      "Iteration 1175: G_loss is 5.0690717697143555 and D_loss is 0.015101762488484383\n",
      "Iteration 1176: G_loss is 3.8557064533233643 and D_loss is 0.050374872982501984\n",
      "Iteration 1177: G_loss is 4.224272727966309 and D_loss is 0.03176216781139374\n",
      "Iteration 1178: G_loss is 4.408302307128906 and D_loss is 0.0256865955889225\n",
      "Iteration 1179: G_loss is 6.089572429656982 and D_loss is 0.004761934746056795\n",
      "Iteration 1180: G_loss is 7.378037929534912 and D_loss is 0.0013805701164528728\n",
      "Iteration 1181: G_loss is 3.7512738704681396 and D_loss is 0.058146361261606216\n",
      "Iteration 1182: G_loss is 6.1440653800964355 and D_loss is 0.004730001091957092\n",
      "Iteration 1183: G_loss is 3.043703556060791 and D_loss is 0.10698205977678299\n",
      "Iteration 1184: G_loss is 3.4510838985443115 and D_loss is 0.07500498741865158\n",
      "Iteration 1185: G_loss is 7.45880126953125 and D_loss is 0.003102674847468734\n",
      "Iteration 1186: G_loss is 7.261593341827393 and D_loss is 0.0015375139191746712\n",
      "Iteration 1187: G_loss is 6.5954389572143555 and D_loss is 0.004386952146887779\n",
      "Iteration 1188: G_loss is 8.563161849975586 and D_loss is 0.0012032587546855211\n",
      "Iteration 1189: G_loss is 5.812495231628418 and D_loss is 0.18951575458049774\n",
      "Iteration 1190: G_loss is 10.14863109588623 and D_loss is 0.05087476968765259\n",
      "Iteration 1191: G_loss is 9.076436996459961 and D_loss is 0.010091613978147507\n",
      "Iteration 1192: G_loss is 7.509105682373047 and D_loss is 0.0012925007613375783\n",
      "Iteration 1193: G_loss is 4.519776344299316 and D_loss is 0.1392522156238556\n",
      "Iteration 1194: G_loss is 6.600908279418945 and D_loss is 0.005942147690802813\n",
      "Iteration 1195: G_loss is 3.8533706665039062 and D_loss is 0.04617854580283165\n",
      "Iteration 1196: G_loss is 3.0267601013183594 and D_loss is 0.10882749408483505\n",
      "Iteration 1197: G_loss is 2.656099319458008 and D_loss is 0.16358572244644165\n",
      "Iteration 1198: G_loss is 3.421808958053589 and D_loss is 0.07339980453252792\n",
      "Iteration 1199: G_loss is 5.394977569580078 and D_loss is 0.010665519163012505\n",
      "Iteration 1200: G_loss is 5.018852233886719 and D_loss is 0.03007456101477146\n",
      "Iteration 1201: G_loss is 6.9056806564331055 and D_loss is 0.0026140878908336163\n",
      "Iteration 1202: G_loss is 10.622980117797852 and D_loss is 0.004409858491271734\n",
      "Iteration 1203: G_loss is 5.63022518157959 and D_loss is 0.08040047436952591\n",
      "Iteration 1204: G_loss is 6.8925089836120605 and D_loss is 0.0048763989470899105\n",
      "Iteration 1205: G_loss is 4.081740856170654 and D_loss is 0.03783171996474266\n",
      "Iteration 1206: G_loss is 5.467143535614014 and D_loss is 0.009933263063430786\n",
      "Iteration 1207: G_loss is 5.9425764083862305 and D_loss is 0.014487028121948242\n",
      "Iteration 1208: G_loss is 4.7140374183654785 and D_loss is 0.036112405359745026\n",
      "Iteration 1209: G_loss is 9.77869987487793 and D_loss is 0.002821133006364107\n",
      "Iteration 1210: G_loss is 9.527098655700684 and D_loss is 0.0017989076441153884\n",
      "Iteration 1211: G_loss is 6.101945877075195 and D_loss is 0.004832334350794554\n",
      "Iteration 1212: G_loss is 7.566253185272217 and D_loss is 0.04965008795261383\n",
      "Iteration 1213: G_loss is 7.544069766998291 and D_loss is 0.0015112633118405938\n",
      "Iteration 1214: G_loss is 8.073864936828613 and D_loss is 0.007374370936304331\n",
      "Iteration 1215: G_loss is 8.225288391113281 and D_loss is 0.004619083367288113\n",
      "Iteration 1216: G_loss is 6.70621395111084 and D_loss is 0.20548678934574127\n",
      "Iteration 1217: G_loss is 4.600561141967773 and D_loss is 0.03533582761883736\n",
      "Iteration 1218: G_loss is 3.533766746520996 and D_loss is 0.0631117895245552\n",
      "Iteration 1219: G_loss is 6.198484897613525 and D_loss is 0.006914407014846802\n",
      "Iteration 1220: G_loss is 4.568657398223877 and D_loss is 0.022421332076191902\n",
      "Iteration 1221: G_loss is 5.990304470062256 and D_loss is 0.005901465192437172\n",
      "Iteration 1222: G_loss is 3.3605289459228516 and D_loss is 0.07647912949323654\n",
      "Iteration 1223: G_loss is 5.440723896026611 and D_loss is 0.009788753464818\n",
      "Iteration 1224: G_loss is 3.3472869396209717 and D_loss is 0.07691334933042526\n",
      "Iteration 1225: G_loss is 4.683812141418457 and D_loss is 0.01988055370748043\n",
      "Iteration 1226: G_loss is 5.373510360717773 and D_loss is 0.011130484752357006\n",
      "Iteration 1227: G_loss is 7.533520698547363 and D_loss is 0.001829040003940463\n",
      "Iteration 1228: G_loss is 3.1082282066345215 and D_loss is 0.09668957442045212\n",
      "Iteration 1229: G_loss is 6.353020668029785 and D_loss is 0.0036376556381583214\n",
      "Iteration 1230: G_loss is 3.9888510704040527 and D_loss is 0.03913423418998718\n",
      "Iteration 1231: G_loss is 5.250287055969238 and D_loss is 0.014997605234384537\n",
      "Iteration 1232: G_loss is 4.777464866638184 and D_loss is 0.01790376380085945\n",
      "Iteration 1233: G_loss is 7.816384315490723 and D_loss is 0.0009875549003481865\n",
      "Iteration 1234: G_loss is 6.558957099914551 and D_loss is 0.0034802521113306284\n",
      "Iteration 1235: G_loss is 5.363946914672852 and D_loss is 0.009779604151844978\n",
      "Iteration 1236: G_loss is 3.3304898738861084 and D_loss is 0.10470211505889893\n",
      "Iteration 1237: G_loss is 4.925452709197998 and D_loss is 0.03635236248373985\n",
      "Iteration 1238: G_loss is 6.636370658874512 and D_loss is 0.11575526744127274\n",
      "Iteration 1239: G_loss is 9.021184921264648 and D_loss is 0.0017615146934986115\n",
      "Iteration 1240: G_loss is 7.663346290588379 and D_loss is 0.0025458468589931726\n",
      "Iteration 1241: G_loss is 5.930771827697754 and D_loss is 0.2517600953578949\n",
      "Iteration 1242: G_loss is 9.793222427368164 and D_loss is 0.003116122679784894\n",
      "Iteration 1243: G_loss is 7.647705078125 and D_loss is 0.0015166262164711952\n",
      "Iteration 1244: G_loss is 4.607550621032715 and D_loss is 0.026022525504231453\n",
      "Iteration 1245: G_loss is 7.2837233543396 and D_loss is 0.0016535798786208034\n",
      "Iteration 1246: G_loss is 3.0170934200286865 and D_loss is 0.10802094638347626\n",
      "Iteration 1247: G_loss is 6.470974922180176 and D_loss is 0.0033053653314709663\n",
      "Iteration 1248: G_loss is 2.4271411895751953 and D_loss is 0.20258580148220062\n",
      "Iteration 1249: G_loss is 3.7588698863983154 and D_loss is 0.049764614552259445\n",
      "Iteration 1250: G_loss is 9.188361167907715 and D_loss is 0.0018794233910739422\n",
      "Iteration 1251: G_loss is 7.083521366119385 and D_loss is 0.002038032980635762\n",
      "Iteration 1252: G_loss is 5.196950912475586 and D_loss is 0.011783375404775143\n",
      "Iteration 1253: G_loss is 4.440443515777588 and D_loss is 0.02808743715286255\n",
      "Iteration 1254: G_loss is 5.511394023895264 and D_loss is 0.009663961827754974\n",
      "Iteration 1255: G_loss is 3.4670403003692627 and D_loss is 0.06975836306810379\n",
      "Iteration 1256: G_loss is 5.6355695724487305 and D_loss is 0.008635454811155796\n",
      "Iteration 1257: G_loss is 8.278810501098633 and D_loss is 0.05018293485045433\n",
      "Iteration 1258: G_loss is 7.78208065032959 and D_loss is 0.001653913757763803\n",
      "Iteration 1259: G_loss is 9.510882377624512 and D_loss is 0.004510370548814535\n",
      "Iteration 1260: G_loss is 5.56151008605957 and D_loss is 0.00859980657696724\n",
      "Iteration 1261: G_loss is 8.699700355529785 and D_loss is 0.00041023551602847874\n",
      "Iteration 1262: G_loss is 6.370290279388428 and D_loss is 0.004987112712115049\n",
      "Iteration 1263: G_loss is 9.237730979919434 and D_loss is 0.0005135484389029443\n",
      "Iteration 1264: G_loss is 7.861180782318115 and D_loss is 0.004277122672647238\n",
      "Iteration 1265: G_loss is 6.4307427406311035 and D_loss is 0.03041900135576725\n",
      "Iteration 1266: G_loss is 7.495696544647217 and D_loss is 0.01030823029577732\n",
      "Iteration 1267: G_loss is 7.866293430328369 and D_loss is 0.006889946758747101\n",
      "Iteration 1268: G_loss is 5.399167060852051 and D_loss is 0.28636133670806885\n",
      "Iteration 1269: G_loss is 7.035240173339844 and D_loss is 0.0035837762989103794\n",
      "Iteration 1270: G_loss is 3.5543875694274902 and D_loss is 0.0630597472190857\n",
      "Iteration 1271: G_loss is 4.503162384033203 and D_loss is 0.024071626365184784\n",
      "Iteration 1272: G_loss is 3.0803537368774414 and D_loss is 0.10936600714921951\n",
      "Iteration 1273: G_loss is 7.356474876403809 and D_loss is 0.0020071533508598804\n",
      "Iteration 1274: G_loss is 6.675369739532471 and D_loss is 0.00307993171736598\n",
      "Iteration 1275: G_loss is 1.4873063564300537 and D_loss is 0.6583080291748047\n",
      "Iteration 1276: G_loss is 7.669945240020752 and D_loss is 0.0014886314747855067\n",
      "Iteration 1277: G_loss is 6.596979141235352 and D_loss is 0.004016074351966381\n",
      "Iteration 1278: G_loss is 9.177999496459961 and D_loss is 0.01809796504676342\n",
      "Iteration 1279: G_loss is 9.65224838256836 and D_loss is 0.018903939053416252\n",
      "Iteration 1280: G_loss is 10.13542652130127 and D_loss is 0.0038692643865942955\n",
      "Iteration 1281: G_loss is 9.024616241455078 and D_loss is 0.00043129356345161796\n",
      "Iteration 1282: G_loss is 9.626270294189453 and D_loss is 0.021287307143211365\n",
      "Iteration 1283: G_loss is 5.874932289123535 and D_loss is 0.01827692799270153\n",
      "Iteration 1284: G_loss is 10.825118064880371 and D_loss is 0.03372509777545929\n",
      "Iteration 1285: G_loss is 8.7127685546875 and D_loss is 0.0010275249369442463\n",
      "Iteration 1286: G_loss is 10.214723587036133 and D_loss is 0.1583884209394455\n",
      "Iteration 1287: G_loss is 9.732563018798828 and D_loss is 0.012677516788244247\n",
      "Iteration 1288: G_loss is 8.652997970581055 and D_loss is 0.0006032073870301247\n",
      "Iteration 1289: G_loss is 9.716065406799316 and D_loss is 0.0004485921817831695\n",
      "Iteration 1290: G_loss is 5.7816619873046875 and D_loss is 0.010046537034213543\n",
      "Iteration 1291: G_loss is 7.4861297607421875 and D_loss is 0.004539056681096554\n",
      "Iteration 1292: G_loss is 5.411064147949219 and D_loss is 0.06932221353054047\n",
      "Iteration 1293: G_loss is 6.116215705871582 and D_loss is 0.007905857637524605\n",
      "Iteration 1294: G_loss is 2.6412274837493896 and D_loss is 0.16451625525951385\n",
      "Iteration 1295: G_loss is 3.918091297149658 and D_loss is 0.044672176241874695\n",
      "Iteration 1296: G_loss is 5.3140082359313965 and D_loss is 0.011029624380171299\n",
      "Iteration 1297: G_loss is 4.435654640197754 and D_loss is 0.026492895558476448\n",
      "Iteration 1298: G_loss is 7.460169315338135 and D_loss is 0.0013899534242227674\n",
      "Iteration 1299: G_loss is 6.562119007110596 and D_loss is 0.0032558341044932604\n",
      "Iteration 1300: G_loss is 5.556465148925781 and D_loss is 0.008329778909683228\n",
      "Iteration 1301: G_loss is 7.229393482208252 and D_loss is 0.0036451355554163456\n",
      "Iteration 1302: G_loss is 4.71777868270874 and D_loss is 0.019431961700320244\n",
      "Iteration 1303: G_loss is 5.370759963989258 and D_loss is 0.010275104083120823\n",
      "Iteration 1304: G_loss is 9.388487815856934 and D_loss is 0.016160666942596436\n",
      "Iteration 1305: G_loss is 8.731245994567871 and D_loss is 0.018733637407422066\n",
      "Iteration 1306: G_loss is 7.531278133392334 and D_loss is 0.004447866231203079\n",
      "Iteration 1307: G_loss is 8.067293167114258 and D_loss is 0.006853790488094091\n",
      "Iteration 1308: G_loss is 9.061840057373047 and D_loss is 0.004702871665358543\n",
      "Iteration 1309: G_loss is 8.207318305969238 and D_loss is 0.003056638641282916\n",
      "Iteration 1310: G_loss is 9.051888465881348 and D_loss is 0.0004317945276852697\n",
      "Iteration 1311: G_loss is 8.038612365722656 and D_loss is 0.004038174636662006\n",
      "Iteration 1312: G_loss is 5.304243087768555 and D_loss is 0.0383426733314991\n",
      "Iteration 1313: G_loss is 5.68902587890625 and D_loss is 0.03736935555934906\n",
      "Iteration 1314: G_loss is 6.611006259918213 and D_loss is 0.03364788368344307\n",
      "Iteration 1315: G_loss is 4.242476940155029 and D_loss is 0.03921835124492645\n",
      "Iteration 1316: G_loss is 7.316681385040283 and D_loss is 0.011866985820233822\n",
      "Iteration 1317: G_loss is 6.484860420227051 and D_loss is 0.004107872024178505\n",
      "Iteration 1318: G_loss is 4.372315406799316 and D_loss is 0.031143516302108765\n",
      "Iteration 1319: G_loss is 3.5329253673553467 and D_loss is 0.06780339032411575\n",
      "Iteration 1320: G_loss is 5.0184712409973145 and D_loss is 0.014559143222868443\n",
      "Iteration 1321: G_loss is 10.044744491577148 and D_loss is 0.0014756357995793223\n",
      "Iteration 1322: G_loss is 8.327798843383789 and D_loss is 0.000992091721855104\n",
      "Iteration 1323: G_loss is 4.713388919830322 and D_loss is 0.020809771493077278\n",
      "Iteration 1324: G_loss is 10.342350959777832 and D_loss is 0.0017087749438360333\n",
      "Iteration 1325: G_loss is 8.438385009765625 and D_loss is 0.006727437488734722\n",
      "Iteration 1326: G_loss is 12.69014835357666 and D_loss is 0.007871541194617748\n",
      "Iteration 1327: G_loss is 11.33576488494873 and D_loss is 0.00012975414574611932\n",
      "Iteration 1328: G_loss is 9.638240814208984 and D_loss is 0.0680675208568573\n",
      "Iteration 1329: G_loss is 6.323231220245361 and D_loss is 0.00420043058693409\n",
      "Iteration 1330: G_loss is 9.772887229919434 and D_loss is 0.033939313143491745\n",
      "Iteration 1331: G_loss is 7.310037612915039 and D_loss is 0.048061173409223557\n",
      "Iteration 1332: G_loss is 5.2394280433654785 and D_loss is 0.012539166957139969\n",
      "Iteration 1333: G_loss is 5.531874179840088 and D_loss is 0.010231745429337025\n",
      "Iteration 1334: G_loss is 5.015624523162842 and D_loss is 0.013957306742668152\n",
      "Iteration 1335: G_loss is 4.271269798278809 and D_loss is 0.029662959277629852\n",
      "Iteration 1336: G_loss is 4.030930995941162 and D_loss is 0.03859876096248627\n",
      "Iteration 1337: G_loss is 5.055989742279053 and D_loss is 0.013510655611753464\n",
      "Iteration 1338: G_loss is 3.330219268798828 and D_loss is 0.07851679623126984\n",
      "Iteration 1339: G_loss is 4.838123798370361 and D_loss is 0.01762579381465912\n",
      "Iteration 1340: G_loss is 4.6214165687561035 and D_loss is 0.021207569167017937\n",
      "Iteration 1341: G_loss is 5.474144458770752 and D_loss is 0.008913381025195122\n",
      "Iteration 1342: G_loss is 13.583429336547852 and D_loss is 0.00172950210981071\n",
      "Iteration 1343: G_loss is 10.05652904510498 and D_loss is 0.001856329501606524\n",
      "Iteration 1344: G_loss is 8.448410987854004 and D_loss is 0.005423239432275295\n",
      "Iteration 1345: G_loss is 12.431076049804688 and D_loss is 0.5651102662086487\n",
      "Iteration 1346: G_loss is 12.134818077087402 and D_loss is 0.00042574183316901326\n",
      "Iteration 1347: G_loss is 7.286423683166504 and D_loss is 0.0016247238963842392\n",
      "Iteration 1348: G_loss is 4.633420467376709 and D_loss is 0.02627386711537838\n",
      "Iteration 1349: G_loss is 3.4383039474487305 and D_loss is 0.06979191303253174\n",
      "Iteration 1350: G_loss is 3.71712327003479 and D_loss is 0.052224136888980865\n",
      "Iteration 1351: G_loss is 5.024788856506348 and D_loss is 0.0138468062505126\n",
      "Iteration 1352: G_loss is 1.623849868774414 and D_loss is 0.529558002948761\n",
      "Iteration 1353: G_loss is 4.454431533813477 and D_loss is 0.024436872452497482\n",
      "Iteration 1354: G_loss is 3.9540507793426514 and D_loss is 0.040313154458999634\n",
      "Iteration 1355: G_loss is 4.346459865570068 and D_loss is 0.02724338322877884\n",
      "Iteration 1356: G_loss is 9.49125862121582 and D_loss is 0.00036640471080318093\n",
      "Iteration 1357: G_loss is 10.729447364807129 and D_loss is 4.915294630336575e-05\n",
      "Iteration 1358: G_loss is 11.589630126953125 and D_loss is 0.0010649770265445113\n",
      "Iteration 1359: G_loss is 12.416993141174316 and D_loss is 0.000825471943244338\n",
      "Iteration 1360: G_loss is 9.990553855895996 and D_loss is 0.00012767199950758368\n",
      "Iteration 1361: G_loss is 10.465072631835938 and D_loss is 0.027600282803177834\n",
      "Iteration 1362: G_loss is 11.956482887268066 and D_loss is 0.0005908210296183825\n",
      "Iteration 1363: G_loss is 11.15418815612793 and D_loss is 0.0051618916913867\n",
      "Iteration 1364: G_loss is 12.595300674438477 and D_loss is 0.003582721808925271\n",
      "Iteration 1365: G_loss is 12.376456260681152 and D_loss is 0.009328427724540234\n",
      "Iteration 1366: G_loss is 11.827266693115234 and D_loss is 0.007181370630860329\n",
      "Iteration 1367: G_loss is 14.661258697509766 and D_loss is 0.0028955023735761642\n",
      "Iteration 1368: G_loss is 10.611148834228516 and D_loss is 0.010488067753612995\n",
      "Iteration 1369: G_loss is 13.218318939208984 and D_loss is 0.07347939163446426\n",
      "Iteration 1370: G_loss is 12.962247848510742 and D_loss is 0.04348701611161232\n",
      "Iteration 1371: G_loss is 12.720781326293945 and D_loss is 0.00927130226045847\n",
      "Iteration 1372: G_loss is 8.831761360168457 and D_loss is 0.00043792277574539185\n",
      "Iteration 1373: G_loss is 12.535517692565918 and D_loss is 0.0012039460707455873\n",
      "Iteration 1374: G_loss is 11.204916000366211 and D_loss is 0.002703893929719925\n",
      "Iteration 1375: G_loss is 8.019014358520508 and D_loss is 0.007387962657958269\n",
      "Iteration 1376: G_loss is 12.086498260498047 and D_loss is 0.00017313522403128445\n",
      "Iteration 1377: G_loss is 9.609431266784668 and D_loss is 0.00023849308490753174\n",
      "Iteration 1378: G_loss is 9.697748184204102 and D_loss is 0.0003533175331540406\n",
      "Iteration 1379: G_loss is 8.647286415100098 and D_loss is 0.00651171850040555\n",
      "Iteration 1380: G_loss is 8.684908866882324 and D_loss is 0.0005455909413285553\n",
      "Iteration 1381: G_loss is 7.848562240600586 and D_loss is 0.006673705298453569\n",
      "Iteration 1382: G_loss is 6.664196014404297 and D_loss is 0.002593001816421747\n",
      "Iteration 1383: G_loss is 5.121359825134277 and D_loss is 0.014907747507095337\n",
      "Iteration 1384: G_loss is 5.0131049156188965 and D_loss is 0.013762636110186577\n",
      "Iteration 1385: G_loss is 7.47691011428833 and D_loss is 0.018808240070939064\n",
      "Iteration 1386: G_loss is 5.9629058837890625 and D_loss is 0.005405070725828409\n",
      "Iteration 1387: G_loss is 5.607856273651123 and D_loss is 0.007519553881138563\n",
      "Iteration 1388: G_loss is 5.591503143310547 and D_loss is 0.007671190891414881\n",
      "Iteration 1389: G_loss is 6.101252555847168 and D_loss is 0.004579188302159309\n",
      "Iteration 1390: G_loss is 6.650134086608887 and D_loss is 0.0030058869160711765\n",
      "Iteration 1391: G_loss is 5.401478290557861 and D_loss is 0.009256282821297646\n",
      "Iteration 1392: G_loss is 6.797994613647461 and D_loss is 0.002330244518816471\n",
      "Iteration 1393: G_loss is 6.973459243774414 and D_loss is 0.001998447347432375\n",
      "Iteration 1394: G_loss is 5.882381439208984 and D_loss is 0.0066795870661735535\n",
      "Iteration 1395: G_loss is 9.108668327331543 and D_loss is 0.0003297498042229563\n",
      "Iteration 1396: G_loss is 5.864398956298828 and D_loss is 0.005997530184686184\n",
      "Iteration 1397: G_loss is 5.529298782348633 and D_loss is 0.008066217415034771\n",
      "Iteration 1398: G_loss is 8.685443878173828 and D_loss is 0.0006400941638275981\n",
      "Iteration 1399: G_loss is 6.799858093261719 and D_loss is 0.002564779482781887\n",
      "Iteration 1400: G_loss is 2.7875444889068604 and D_loss is 0.13306619226932526\n",
      "Iteration 1401: G_loss is 6.737335681915283 and D_loss is 0.00249036424793303\n",
      "Iteration 1402: G_loss is 7.492371559143066 and D_loss is 0.00274171051569283\n",
      "Iteration 1403: G_loss is 7.084704875946045 and D_loss is 0.004348154179751873\n",
      "Iteration 1404: G_loss is 6.823819160461426 and D_loss is 0.0029590597841888666\n",
      "Iteration 1405: G_loss is 9.264898300170898 and D_loss is 0.0012817266397178173\n",
      "Iteration 1406: G_loss is 9.87621784210205 and D_loss is 0.0003679851070046425\n",
      "Iteration 1407: G_loss is 8.822845458984375 and D_loss is 0.0012504116166383028\n",
      "Iteration 1408: G_loss is 8.106330871582031 and D_loss is 0.007725282572209835\n",
      "Iteration 1409: G_loss is 8.876726150512695 and D_loss is 0.005127511452883482\n",
      "Iteration 1410: G_loss is 6.8431901931762695 and D_loss is 0.003127740230411291\n",
      "Iteration 1411: G_loss is 10.118963241577148 and D_loss is 0.04647691547870636\n",
      "Iteration 1412: G_loss is 7.921956539154053 and D_loss is 0.0033580821473151445\n",
      "Iteration 1413: G_loss is 7.435199737548828 and D_loss is 0.0036684703081846237\n",
      "Iteration 1414: G_loss is 5.568772315979004 and D_loss is 0.008606186136603355\n",
      "Iteration 1415: G_loss is 7.79069709777832 and D_loss is 0.0017327527748420835\n",
      "Iteration 1416: G_loss is 8.336935997009277 and D_loss is 0.012283497489988804\n",
      "Iteration 1417: G_loss is 8.731765747070312 and D_loss is 0.000986952451057732\n",
      "Iteration 1418: G_loss is 6.331302165985107 and D_loss is 0.004091064445674419\n",
      "Iteration 1419: G_loss is 6.253891468048096 and D_loss is 0.005099188536405563\n",
      "Iteration 1420: G_loss is 6.1052350997924805 and D_loss is 0.006711071357131004\n",
      "Iteration 1421: G_loss is 8.023059844970703 and D_loss is 0.0026578044053167105\n",
      "Iteration 1422: G_loss is 5.798422336578369 and D_loss is 0.006505097262561321\n",
      "Iteration 1423: G_loss is 7.6822428703308105 and D_loss is 0.001808671746402979\n",
      "Iteration 1424: G_loss is 9.969066619873047 and D_loss is 0.0029446445405483246\n",
      "Iteration 1425: G_loss is 5.530651092529297 and D_loss is 0.009782528504729271\n",
      "Iteration 1426: G_loss is 7.6296916007995605 and D_loss is 0.0011190911754965782\n",
      "Iteration 1427: G_loss is 5.895743370056152 and D_loss is 0.006640765815973282\n",
      "Iteration 1428: G_loss is 5.975814342498779 and D_loss is 0.010198108851909637\n",
      "Iteration 1429: G_loss is 7.772841930389404 and D_loss is 0.0028397671412676573\n",
      "Iteration 1430: G_loss is 6.2879743576049805 and D_loss is 0.006614183075726032\n",
      "Iteration 1431: G_loss is 5.906245231628418 and D_loss is 0.00602505449205637\n",
      "Iteration 1432: G_loss is 6.019353866577148 and D_loss is 0.008136913180351257\n",
      "Iteration 1433: G_loss is 5.924415588378906 and D_loss is 0.005788310896605253\n",
      "Iteration 1434: G_loss is 3.815406322479248 and D_loss is 0.04808667674660683\n",
      "Iteration 1435: G_loss is 7.542549133300781 and D_loss is 0.0014723720960319042\n",
      "Iteration 1436: G_loss is 8.30156135559082 and D_loss is 0.011672764085233212\n",
      "Iteration 1437: G_loss is 7.760900974273682 and D_loss is 0.0045258416794240475\n",
      "Iteration 1438: G_loss is 8.96599006652832 and D_loss is 0.0005876558134332299\n",
      "Iteration 1439: G_loss is 5.407465934753418 and D_loss is 0.011389105580747128\n",
      "Iteration 1440: G_loss is 8.037991523742676 and D_loss is 0.014008100144565105\n",
      "Iteration 1441: G_loss is 10.480951309204102 and D_loss is 0.002311453688889742\n",
      "Iteration 1442: G_loss is 8.31513786315918 and D_loss is 0.0012534069828689098\n",
      "Iteration 1443: G_loss is 8.82341194152832 and D_loss is 0.0037047299556434155\n",
      "Iteration 1444: G_loss is 12.037283897399902 and D_loss is 0.00019202721887268126\n",
      "Iteration 1445: G_loss is 10.178277969360352 and D_loss is 0.02409784123301506\n",
      "Iteration 1446: G_loss is 11.365190505981445 and D_loss is 0.009693512693047523\n",
      "Iteration 1447: G_loss is 10.399674415588379 and D_loss is 0.0013881884515285492\n",
      "Iteration 1448: G_loss is 8.811253547668457 and D_loss is 0.040174320340156555\n",
      "Iteration 1449: G_loss is 9.109416007995605 and D_loss is 0.0013966318219900131\n",
      "Iteration 1450: G_loss is 10.397557258605957 and D_loss is 0.00026098923990502954\n",
      "Iteration 1451: G_loss is 7.53924036026001 and D_loss is 0.0063432566821575165\n",
      "Iteration 1452: G_loss is 5.607962131500244 and D_loss is 0.00843214150518179\n",
      "Iteration 1453: G_loss is 4.688155651092529 and D_loss is 0.021758008748292923\n",
      "Iteration 1454: G_loss is 5.45134162902832 and D_loss is 0.010214272886514664\n",
      "Iteration 1455: G_loss is 7.0614800453186035 and D_loss is 0.0019463684875518084\n",
      "Iteration 1456: G_loss is 7.550080299377441 and D_loss is 0.0012122176121920347\n",
      "Iteration 1457: G_loss is 6.3543314933776855 and D_loss is 0.0039455946534872055\n",
      "Iteration 1458: G_loss is 6.7671332359313965 and D_loss is 0.0027845909353345633\n",
      "Iteration 1459: G_loss is 7.209592819213867 and D_loss is 0.002349745947867632\n",
      "Iteration 1460: G_loss is 6.708342552185059 and D_loss is 0.0025920248590409756\n",
      "Iteration 1461: G_loss is 7.2142229080200195 and D_loss is 0.002094088587909937\n",
      "Iteration 1462: G_loss is 8.733071327209473 and D_loss is 0.0009717325447127223\n",
      "Iteration 1463: G_loss is 9.440224647521973 and D_loss is 0.0006407432374544442\n",
      "Iteration 1464: G_loss is 10.058150291442871 and D_loss is 0.00045925541780889034\n",
      "Iteration 1465: G_loss is 8.188360214233398 and D_loss is 0.0031617514323443174\n",
      "Iteration 1466: G_loss is 7.940445899963379 and D_loss is 0.0008755882736295462\n",
      "Iteration 1467: G_loss is 6.051789283752441 and D_loss is 0.006391518749296665\n",
      "Iteration 1468: G_loss is 7.55499792098999 and D_loss is 0.00261587998829782\n",
      "Iteration 1469: G_loss is 5.39889669418335 and D_loss is 0.009920736774802208\n",
      "Iteration 1470: G_loss is 8.303590774536133 and D_loss is 0.0009182082721963525\n",
      "Iteration 1471: G_loss is 5.828739166259766 and D_loss is 0.0063588120974600315\n",
      "Iteration 1472: G_loss is 7.449820041656494 and D_loss is 0.0020643440075218678\n",
      "Iteration 1473: G_loss is 5.250136375427246 and D_loss is 0.011383263394236565\n",
      "Iteration 1474: G_loss is 4.108644485473633 and D_loss is 0.03558739647269249\n",
      "Iteration 1475: G_loss is 7.26191520690918 and D_loss is 0.0033763409592211246\n",
      "Iteration 1476: G_loss is 11.185049057006836 and D_loss is 0.0006074932171031833\n",
      "Iteration 1477: G_loss is 9.406769752502441 and D_loss is 0.00030109641375020146\n",
      "Iteration 1478: G_loss is 12.16447925567627 and D_loss is 0.000310131668811664\n",
      "Iteration 1479: G_loss is 11.380807876586914 and D_loss is 0.0043851519003510475\n",
      "Iteration 1480: G_loss is 11.10555648803711 and D_loss is 0.13346636295318604\n",
      "Iteration 1481: G_loss is 9.422785758972168 and D_loss is 0.0006202117074280977\n",
      "Iteration 1482: G_loss is 8.338104248046875 and D_loss is 0.05623193457722664\n",
      "Iteration 1483: G_loss is 8.09969425201416 and D_loss is 0.0020487005822360516\n",
      "Iteration 1484: G_loss is 4.770705223083496 and D_loss is 0.018124982714653015\n",
      "Iteration 1485: G_loss is 6.105334758758545 and D_loss is 0.004854107741266489\n",
      "Iteration 1486: G_loss is 9.031325340270996 and D_loss is 0.00033940584398806095\n",
      "Iteration 1487: G_loss is 4.38144588470459 and D_loss is 0.026703326031565666\n",
      "Iteration 1488: G_loss is 5.230777263641357 and D_loss is 0.011288123205304146\n",
      "Iteration 1489: G_loss is 5.127121925354004 and D_loss is 0.012513070367276669\n",
      "Iteration 1490: G_loss is 7.371434211730957 and D_loss is 0.0013322423910722136\n",
      "Iteration 1491: G_loss is 4.020898342132568 and D_loss is 0.038199491798877716\n",
      "Iteration 1492: G_loss is 5.928192138671875 and D_loss is 0.005582973826676607\n",
      "Iteration 1493: G_loss is 4.256937503814697 and D_loss is 0.030426817014813423\n",
      "Iteration 1494: G_loss is 6.5611252784729 and D_loss is 0.0029944300185889006\n",
      "Iteration 1495: G_loss is 7.348149299621582 and D_loss is 0.0013691459316760302\n",
      "Iteration 1496: G_loss is 8.96605110168457 and D_loss is 0.0003873694222420454\n",
      "Iteration 1497: G_loss is 4.372931003570557 and D_loss is 0.026395589113235474\n",
      "Iteration 1498: G_loss is 9.148443222045898 and D_loss is 0.00023031503951642662\n",
      "Iteration 1499: G_loss is 9.164259910583496 and D_loss is 0.00022384562180377543\n",
      "Iteration 1500: G_loss is 10.856792449951172 and D_loss is 6.0727379604941234e-05\n",
      "Iteration 1501: G_loss is 11.087867736816406 and D_loss is 7.144287519622594e-05\n",
      "Iteration 1502: G_loss is 11.335062980651855 and D_loss is 0.0020366362296044827\n",
      "Iteration 1503: G_loss is 9.799806594848633 and D_loss is 0.00025427411310374737\n",
      "Iteration 1504: G_loss is 12.19393539428711 and D_loss is 1.587917904544156e-05\n",
      "Iteration 1505: G_loss is 14.127401351928711 and D_loss is 5.172517558094114e-05\n",
      "Iteration 1506: G_loss is 9.672837257385254 and D_loss is 0.00034099232289008796\n",
      "Iteration 1507: G_loss is 10.99387264251709 and D_loss is 0.00031638360815122724\n",
      "Iteration 1508: G_loss is 12.174394607543945 and D_loss is 3.7575267924694344e-05\n",
      "Iteration 1509: G_loss is 11.472463607788086 and D_loss is 0.0030377600342035294\n",
      "Iteration 1510: G_loss is 8.257012367248535 and D_loss is 0.0005380843649618328\n",
      "Iteration 1511: G_loss is 10.450166702270508 and D_loss is 0.0005575552931986749\n",
      "Iteration 1512: G_loss is 7.930492877960205 and D_loss is 0.19098547101020813\n",
      "Iteration 1513: G_loss is 9.103397369384766 and D_loss is 0.0004327425849623978\n",
      "Iteration 1514: G_loss is 9.842816352844238 and D_loss is 0.00013508227129932493\n",
      "Iteration 1515: G_loss is 5.709334850311279 and D_loss is 0.006798801477998495\n",
      "Iteration 1516: G_loss is 6.319319248199463 and D_loss is 0.0038406304083764553\n",
      "Iteration 1517: G_loss is 3.645670175552368 and D_loss is 0.05468153953552246\n",
      "Iteration 1518: G_loss is 4.608101844787598 and D_loss is 0.02044401690363884\n",
      "Iteration 1519: G_loss is 4.456577301025391 and D_loss is 0.023781156167387962\n",
      "Iteration 1520: G_loss is 6.9939703941345215 and D_loss is 0.0018744261469691992\n",
      "Iteration 1521: G_loss is 8.912166595458984 and D_loss is 0.00028995663160458207\n",
      "Iteration 1522: G_loss is 7.077195644378662 and D_loss is 0.0016945756506174803\n",
      "Iteration 1523: G_loss is 4.1779255867004395 and D_loss is 0.031368277966976166\n",
      "Iteration 1524: G_loss is 4.869638442993164 and D_loss is 0.015686163678765297\n",
      "Iteration 1525: G_loss is 7.412105560302734 and D_loss is 0.001246227533556521\n",
      "Iteration 1526: G_loss is 6.199302673339844 and D_loss is 0.004152450244873762\n",
      "Iteration 1527: G_loss is 5.459198951721191 and D_loss is 0.008897103369235992\n",
      "Iteration 1528: G_loss is 4.5850419998168945 and D_loss is 0.02092854119837284\n",
      "Iteration 1529: G_loss is 6.624953746795654 and D_loss is 0.0027026322204619646\n",
      "Iteration 1530: G_loss is 4.528738498687744 and D_loss is 0.02215328998863697\n",
      "Iteration 1531: G_loss is 8.196907997131348 and D_loss is 0.0005684049683623016\n",
      "Iteration 1532: G_loss is 8.36221694946289 and D_loss is 0.0005085248849354684\n",
      "Iteration 1533: G_loss is 8.16881275177002 and D_loss is 0.001437669969163835\n",
      "Iteration 1534: G_loss is 9.617460250854492 and D_loss is 0.002257089363411069\n",
      "Iteration 1535: G_loss is 10.759881973266602 and D_loss is 0.0001946342090377584\n",
      "Iteration 1536: G_loss is 7.765319347381592 and D_loss is 0.000996163347736001\n",
      "Iteration 1537: G_loss is 9.55986499786377 and D_loss is 0.00020896387286484241\n",
      "Iteration 1538: G_loss is 9.908317565917969 and D_loss is 0.0001176160221803002\n",
      "Iteration 1539: G_loss is 9.774818420410156 and D_loss is 0.0005205862107686698\n",
      "Iteration 1540: G_loss is 12.795195579528809 and D_loss is 3.7560232158284634e-05\n",
      "Iteration 1541: G_loss is 7.7646260261535645 and D_loss is 0.0011216073762625456\n",
      "Iteration 1542: G_loss is 6.808638572692871 and D_loss is 0.0025233495980501175\n",
      "Iteration 1543: G_loss is 9.980032920837402 and D_loss is 0.0062437718734145164\n",
      "Iteration 1544: G_loss is 7.534730911254883 and D_loss is 0.001117753330618143\n",
      "Iteration 1545: G_loss is 11.78466510772705 and D_loss is 0.000627820088993758\n",
      "Iteration 1546: G_loss is 6.565041542053223 and D_loss is 0.0032472957391291857\n",
      "Iteration 1547: G_loss is 9.734583854675293 and D_loss is 0.0005419736262410879\n",
      "Iteration 1548: G_loss is 11.142663955688477 and D_loss is 0.00010103161912411451\n",
      "Iteration 1549: G_loss is 8.660762786865234 and D_loss is 0.001012852299027145\n",
      "Iteration 1550: G_loss is 8.157368659973145 and D_loss is 0.000730894273146987\n",
      "Iteration 1551: G_loss is 9.234000205993652 and D_loss is 0.000284588779322803\n",
      "Iteration 1552: G_loss is 10.849424362182617 and D_loss is 6.65490806568414e-05\n",
      "Iteration 1553: G_loss is 10.177719116210938 and D_loss is 8.557266846764833e-05\n",
      "Iteration 1554: G_loss is 10.074257850646973 and D_loss is 0.0006527990335598588\n",
      "Iteration 1555: G_loss is 10.624685287475586 and D_loss is 0.0042971158400177956\n",
      "Iteration 1556: G_loss is 9.498351097106934 and D_loss is 0.0007229691836982965\n",
      "Iteration 1557: G_loss is 12.493392944335938 and D_loss is 6.476668204413727e-05\n",
      "Iteration 1558: G_loss is 8.636979103088379 and D_loss is 0.0006817765533924103\n",
      "Iteration 1559: G_loss is 11.453943252563477 and D_loss is 0.0001681559660937637\n",
      "Iteration 1560: G_loss is 8.494504928588867 and D_loss is 0.0004398855671752244\n",
      "Iteration 1561: G_loss is 8.9522066116333 and D_loss is 0.0003139820764772594\n",
      "Iteration 1562: G_loss is 9.482998847961426 and D_loss is 0.00020734807185363024\n",
      "Iteration 1563: G_loss is 9.072848320007324 and D_loss is 0.00025066701346077025\n",
      "Iteration 1564: G_loss is 10.991893768310547 and D_loss is 5.109694029670209e-05\n",
      "Iteration 1565: G_loss is 9.019937515258789 and D_loss is 0.0008475995273329318\n",
      "Iteration 1566: G_loss is 8.578725814819336 and D_loss is 0.0010136404307559133\n",
      "Iteration 1567: G_loss is 9.66096305847168 and D_loss is 0.0005664522759616375\n",
      "Iteration 1568: G_loss is 8.926156997680664 and D_loss is 0.000313605647534132\n",
      "Iteration 1569: G_loss is 10.22724723815918 and D_loss is 0.00028423868934623897\n",
      "Iteration 1570: G_loss is 10.171278953552246 and D_loss is 8.160425204550847e-05\n",
      "Iteration 1571: G_loss is 8.622254371643066 and D_loss is 0.0005249266978353262\n",
      "Iteration 1572: G_loss is 6.38016414642334 and D_loss is 0.003668491030111909\n",
      "Iteration 1573: G_loss is 8.111475944519043 and D_loss is 0.000689608626998961\n",
      "Iteration 1574: G_loss is 9.5939302444458 and D_loss is 0.00018203785293735564\n",
      "Iteration 1575: G_loss is 8.609402656555176 and D_loss is 0.0004298320855014026\n",
      "Iteration 1576: G_loss is 9.045422554016113 and D_loss is 0.0009456609259359539\n",
      "Iteration 1577: G_loss is 11.537232398986816 and D_loss is 0.0001294401881750673\n",
      "Iteration 1578: G_loss is 8.25951099395752 and D_loss is 0.004583612084388733\n",
      "Iteration 1579: G_loss is 7.915536403656006 and D_loss is 0.0009187842952087522\n",
      "Iteration 1580: G_loss is 7.596747398376465 and D_loss is 0.0010683945147320628\n",
      "Iteration 1581: G_loss is 10.161035537719727 and D_loss is 0.0002876751241274178\n",
      "Iteration 1582: G_loss is 8.849138259887695 and D_loss is 0.006946514826267958\n",
      "Iteration 1583: G_loss is 10.753568649291992 and D_loss is 0.000149542058352381\n",
      "Iteration 1584: G_loss is 7.477780818939209 and D_loss is 0.0014404274988919497\n",
      "Iteration 1585: G_loss is 6.69529390335083 and D_loss is 0.002937852870672941\n",
      "Iteration 1586: G_loss is 7.652266025543213 and D_loss is 0.0013961698859930038\n",
      "Iteration 1587: G_loss is 7.950211524963379 and D_loss is 0.0008448493899777532\n",
      "Iteration 1588: G_loss is 9.122258186340332 and D_loss is 0.0005720527260564268\n",
      "Iteration 1589: G_loss is 8.064523696899414 and D_loss is 0.0013917279429733753\n",
      "Iteration 1590: G_loss is 12.32691764831543 and D_loss is 0.02008827030658722\n",
      "Iteration 1591: G_loss is 8.575641632080078 and D_loss is 0.0005896814982406795\n",
      "Iteration 1592: G_loss is 12.941766738891602 and D_loss is 0.0005220316234044731\n",
      "Iteration 1593: G_loss is 7.070446014404297 and D_loss is 0.0024164312053471804\n",
      "Iteration 1594: G_loss is 7.489717960357666 and D_loss is 0.0072860196232795715\n",
      "Iteration 1595: G_loss is 8.569846153259277 and D_loss is 0.000994298723526299\n",
      "Iteration 1596: G_loss is 3.1610774993896484 and D_loss is 0.09214704483747482\n",
      "Iteration 1597: G_loss is 10.007608413696289 and D_loss is 0.00021736501366831362\n",
      "Iteration 1598: G_loss is 5.592406749725342 and D_loss is 0.008526762947440147\n",
      "Iteration 1599: G_loss is 8.353588104248047 and D_loss is 0.00818530935794115\n",
      "Iteration 1600: G_loss is 11.416374206542969 and D_loss is 0.0002548938209656626\n",
      "Iteration 1601: G_loss is 13.193028450012207 and D_loss is 0.0011810391442850232\n",
      "Iteration 1602: G_loss is 11.466826438903809 and D_loss is 0.000264329049969092\n",
      "Iteration 1603: G_loss is 10.255463600158691 and D_loss is 0.0005411176243796945\n",
      "Iteration 1604: G_loss is 10.621291160583496 and D_loss is 0.041842006146907806\n",
      "Iteration 1605: G_loss is 12.238346099853516 and D_loss is 0.003408602438867092\n",
      "Iteration 1606: G_loss is 11.24724006652832 and D_loss is 0.0031913211569190025\n",
      "Iteration 1607: G_loss is 11.817410469055176 and D_loss is 7.69745311117731e-05\n",
      "Iteration 1608: G_loss is 13.439763069152832 and D_loss is 2.4298697098856792e-05\n",
      "Iteration 1609: G_loss is 8.378913879394531 and D_loss is 0.0005712678539566696\n",
      "Iteration 1610: G_loss is 10.185523986816406 and D_loss is 0.00011770952551160008\n",
      "Iteration 1611: G_loss is 12.553203582763672 and D_loss is 9.99556650640443e-05\n",
      "Iteration 1612: G_loss is 10.030027389526367 and D_loss is 0.007904033176600933\n",
      "Iteration 1613: G_loss is 13.140951156616211 and D_loss is 0.004298107232898474\n",
      "Iteration 1614: G_loss is 12.03376579284668 and D_loss is 0.0001991023018490523\n",
      "Iteration 1615: G_loss is 10.020560264587402 and D_loss is 0.00017565934103913605\n",
      "Iteration 1616: G_loss is 8.033315658569336 and D_loss is 0.001084471121430397\n",
      "Iteration 1617: G_loss is 7.45931339263916 and D_loss is 0.0012258942006155849\n",
      "Iteration 1618: G_loss is 7.501784801483154 and D_loss is 0.0011722067138180137\n",
      "Iteration 1619: G_loss is 8.532393455505371 and D_loss is 0.0004583878326229751\n",
      "Iteration 1620: G_loss is 12.265317916870117 and D_loss is 0.00012045370385749266\n",
      "Iteration 1621: G_loss is 8.87164306640625 and D_loss is 0.0003002095618285239\n",
      "Iteration 1622: G_loss is 10.239653587341309 and D_loss is 0.00026565667940303683\n",
      "Iteration 1623: G_loss is 10.823822021484375 and D_loss is 0.0002051487535936758\n",
      "Iteration 1624: G_loss is 10.446837425231934 and D_loss is 0.0004569136071950197\n",
      "Iteration 1625: G_loss is 10.069196701049805 and D_loss is 9.016090189106762e-05\n",
      "Iteration 1626: G_loss is 11.65715503692627 and D_loss is 0.0004229484184179455\n",
      "Iteration 1627: G_loss is 8.637136459350586 and D_loss is 0.0006392357172444463\n",
      "Iteration 1628: G_loss is 8.42169189453125 and D_loss is 0.001664769952185452\n",
      "Iteration 1629: G_loss is 10.070623397827148 and D_loss is 0.0003011820954270661\n",
      "Iteration 1630: G_loss is 9.957823753356934 and D_loss is 0.00023724717902950943\n",
      "Iteration 1631: G_loss is 10.167959213256836 and D_loss is 0.0005785918328911066\n",
      "Iteration 1632: G_loss is 7.413642883300781 and D_loss is 0.003435178194195032\n",
      "Iteration 1633: G_loss is 8.952432632446289 and D_loss is 0.00027133768890053034\n",
      "Iteration 1634: G_loss is 7.504276752471924 and D_loss is 0.003712071105837822\n",
      "Iteration 1635: G_loss is 7.049013137817383 and D_loss is 0.0017965969163924456\n",
      "Iteration 1636: G_loss is 6.539956569671631 and D_loss is 0.0029551477637141943\n",
      "Iteration 1637: G_loss is 7.895839214324951 and D_loss is 0.0030293837189674377\n",
      "Iteration 1638: G_loss is 10.03104019165039 and D_loss is 9.46962900343351e-05\n",
      "Iteration 1639: G_loss is 9.75134563446045 and D_loss is 0.00013612979091703892\n",
      "Iteration 1640: G_loss is 6.983614921569824 and D_loss is 0.0019761479925364256\n",
      "Iteration 1641: G_loss is 8.065196990966797 and D_loss is 0.0011219808366149664\n",
      "Iteration 1642: G_loss is 8.4953031539917 and D_loss is 0.0005937969544902444\n",
      "Iteration 1643: G_loss is 7.780516624450684 and D_loss is 0.0009086643694899976\n",
      "Iteration 1644: G_loss is 8.794180870056152 and D_loss is 0.0013214302016422153\n",
      "Iteration 1645: G_loss is 10.51392936706543 and D_loss is 0.00046901238965801895\n",
      "Iteration 1646: G_loss is 9.694411277770996 and D_loss is 0.0002065769222099334\n",
      "Iteration 1647: G_loss is 9.02513313293457 and D_loss is 0.00032058588112704456\n",
      "Iteration 1648: G_loss is 9.67206859588623 and D_loss is 0.00012918983702547848\n",
      "Iteration 1649: G_loss is 7.846917152404785 and D_loss is 0.0008116419776342809\n",
      "Iteration 1650: G_loss is 8.137306213378906 and D_loss is 0.004538655746728182\n",
      "Iteration 1651: G_loss is 5.395543098449707 and D_loss is 0.009308820590376854\n",
      "Iteration 1652: G_loss is 6.899521827697754 and D_loss is 0.00208109337836504\n",
      "Iteration 1653: G_loss is 6.9085187911987305 and D_loss is 0.0027316806372255087\n",
      "Iteration 1654: G_loss is 8.019229888916016 and D_loss is 0.0006794919027015567\n",
      "Iteration 1655: G_loss is 6.260653018951416 and D_loss is 0.006501294672489166\n",
      "Iteration 1656: G_loss is 9.556365966796875 and D_loss is 0.00016826328646857291\n",
      "Iteration 1657: G_loss is 9.530953407287598 and D_loss is 0.00022663269191980362\n",
      "Iteration 1658: G_loss is 12.420699119567871 and D_loss is 0.00023657984274905175\n",
      "Iteration 1659: G_loss is 8.969053268432617 and D_loss is 0.0006075863493606448\n",
      "Iteration 1660: G_loss is 8.259690284729004 and D_loss is 0.000719449482858181\n",
      "Iteration 1661: G_loss is 9.267309188842773 and D_loss is 0.0009087110520340502\n",
      "Iteration 1662: G_loss is 10.001134872436523 and D_loss is 0.0048454017378389835\n",
      "Iteration 1663: G_loss is 9.899559020996094 and D_loss is 0.00013167725410312414\n",
      "Iteration 1664: G_loss is 9.010932922363281 and D_loss is 0.0002640152524691075\n",
      "Iteration 1665: G_loss is 8.867934226989746 and D_loss is 0.0003934924607165158\n",
      "Iteration 1666: G_loss is 6.231251239776611 and D_loss is 0.004186570178717375\n",
      "Iteration 1667: G_loss is 10.723483085632324 and D_loss is 0.001266038161702454\n",
      "Iteration 1668: G_loss is 9.640923500061035 and D_loss is 0.0001352086546830833\n",
      "Iteration 1669: G_loss is 9.853277206420898 and D_loss is 0.0001605576544534415\n",
      "Iteration 1670: G_loss is 11.088436126708984 and D_loss is 0.00015403413271997124\n",
      "Iteration 1671: G_loss is 9.156168937683105 and D_loss is 0.0002218505833297968\n",
      "Iteration 1672: G_loss is 11.51152515411377 and D_loss is 0.0001284988538827747\n",
      "Iteration 1673: G_loss is 8.374344825744629 and D_loss is 0.000523769820574671\n",
      "Iteration 1674: G_loss is 8.731192588806152 and D_loss is 0.00034800011781044304\n",
      "Iteration 1675: G_loss is 9.544557571411133 and D_loss is 0.0002878080995287746\n",
      "Iteration 1676: G_loss is 6.960507869720459 and D_loss is 0.0020159203559160233\n",
      "Iteration 1677: G_loss is 7.656979560852051 and D_loss is 0.003352474421262741\n",
      "Iteration 1678: G_loss is 8.658915519714355 and D_loss is 0.0006482318276539445\n",
      "Iteration 1679: G_loss is 9.829300880432129 and D_loss is 0.0018046402838081121\n",
      "Iteration 1680: G_loss is 8.530991554260254 and D_loss is 0.002345732878893614\n",
      "Iteration 1681: G_loss is 7.75201416015625 and D_loss is 0.0009428716730326414\n",
      "Iteration 1682: G_loss is 10.347482681274414 and D_loss is 0.0002027462178375572\n",
      "Iteration 1683: G_loss is 7.98085355758667 and D_loss is 0.0035995568614453077\n",
      "Iteration 1684: G_loss is 9.244745254516602 and D_loss is 0.00021367457520682365\n",
      "Iteration 1685: G_loss is 9.485406875610352 and D_loss is 0.0009095012792386115\n",
      "Iteration 1686: G_loss is 8.48880386352539 and D_loss is 0.0005243232008069754\n",
      "Iteration 1687: G_loss is 9.072656631469727 and D_loss is 0.00024593042326159775\n",
      "Iteration 1688: G_loss is 8.013476371765137 and D_loss is 0.0007603316335007548\n",
      "Iteration 1689: G_loss is 6.816799163818359 and D_loss is 0.00226969993673265\n",
      "Iteration 1690: G_loss is 5.346617698669434 and D_loss is 0.010522561147809029\n",
      "Iteration 1691: G_loss is 7.687097072601318 and D_loss is 0.0009614479495212436\n",
      "Iteration 1692: G_loss is 10.478693962097168 and D_loss is 0.00012032515223836526\n",
      "Iteration 1693: G_loss is 6.80336856842041 and D_loss is 0.0026438389904797077\n",
      "Iteration 1694: G_loss is 11.145310401916504 and D_loss is 0.0005068209720775485\n",
      "Iteration 1695: G_loss is 9.748231887817383 and D_loss is 0.0002851688477676362\n",
      "Iteration 1696: G_loss is 9.708499908447266 and D_loss is 0.0004075965262018144\n",
      "Iteration 1697: G_loss is 8.64178466796875 and D_loss is 0.0004490338615141809\n",
      "Iteration 1698: G_loss is 3.5623412132263184 and D_loss is 0.06041258946061134\n",
      "Iteration 1699: G_loss is 10.098284721374512 and D_loss is 0.0004600347892846912\n",
      "Iteration 1700: G_loss is 10.196889877319336 and D_loss is 0.0008409989532083273\n",
      "Iteration 1701: G_loss is 11.607744216918945 and D_loss is 0.0001580409734742716\n",
      "Iteration 1702: G_loss is 10.890726089477539 and D_loss is 0.00419836537912488\n",
      "Iteration 1703: G_loss is 13.333097457885742 and D_loss is 0.0012479131110012531\n",
      "Iteration 1704: G_loss is 12.53597640991211 and D_loss is 0.0003314190835226327\n",
      "Iteration 1705: G_loss is 14.120835304260254 and D_loss is 0.0018323719268664718\n",
      "Iteration 1706: G_loss is 13.757648468017578 and D_loss is 0.0014908573357388377\n",
      "Iteration 1707: G_loss is 12.82044792175293 and D_loss is 0.024014128372073174\n",
      "Iteration 1708: G_loss is 13.306568145751953 and D_loss is 0.00042626747745089233\n",
      "Iteration 1709: G_loss is 14.577437400817871 and D_loss is 0.0007460227934643626\n",
      "Iteration 1710: G_loss is 13.972905158996582 and D_loss is 0.0016900933114811778\n",
      "Iteration 1711: G_loss is 12.980827331542969 and D_loss is 0.010103591717779636\n",
      "Iteration 1712: G_loss is 11.823149681091309 and D_loss is 0.002780417213216424\n",
      "Iteration 1713: G_loss is 9.317410469055176 and D_loss is 0.0003661810187622905\n",
      "Iteration 1714: G_loss is 13.04662799835205 and D_loss is 0.00018234884191770107\n",
      "Iteration 1715: G_loss is 11.02143669128418 and D_loss is 0.0003485997731331736\n",
      "Iteration 1716: G_loss is 10.826457023620605 and D_loss is 0.00013623107224702835\n",
      "Iteration 1717: G_loss is 9.272807121276855 and D_loss is 0.00021237506007310003\n",
      "Iteration 1718: G_loss is 12.967537879943848 and D_loss is 0.0003851056389976293\n",
      "Iteration 1719: G_loss is 12.954849243164062 and D_loss is 0.0006821239949204028\n",
      "Iteration 1720: G_loss is 12.013378143310547 and D_loss is 0.002358554396778345\n",
      "Iteration 1721: G_loss is 10.171422958374023 and D_loss is 0.0004851458652410656\n",
      "Iteration 1722: G_loss is 7.993849277496338 and D_loss is 0.0016841525211930275\n",
      "Iteration 1723: G_loss is 9.935225486755371 and D_loss is 0.0005109331686981022\n",
      "Iteration 1724: G_loss is 9.83474349975586 and D_loss is 0.007165182381868362\n",
      "Iteration 1725: G_loss is 13.260350227355957 and D_loss is 0.00030875072116032243\n",
      "Iteration 1726: G_loss is 12.583070755004883 and D_loss is 1.2763508493662812e-05\n",
      "Iteration 1727: G_loss is 11.95246696472168 and D_loss is 0.00018044565513264388\n",
      "Iteration 1728: G_loss is 11.271602630615234 and D_loss is 0.00020877861243207008\n",
      "Iteration 1729: G_loss is 10.2599458694458 and D_loss is 9.947126090992242e-05\n",
      "Iteration 1730: G_loss is 12.144096374511719 and D_loss is 0.0011486825533211231\n",
      "Iteration 1731: G_loss is 11.583168983459473 and D_loss is 0.00028682025731541216\n",
      "Iteration 1732: G_loss is 9.89492416381836 and D_loss is 0.0001495002506999299\n",
      "Iteration 1733: G_loss is 10.335262298583984 and D_loss is 0.00024121516617015004\n",
      "Iteration 1734: G_loss is 8.284332275390625 and D_loss is 0.001246470957994461\n",
      "Iteration 1735: G_loss is 7.422425746917725 and D_loss is 0.0013050904963165522\n",
      "Iteration 1736: G_loss is 10.277607917785645 and D_loss is 0.00011082157288910821\n",
      "Iteration 1737: G_loss is 11.439850807189941 and D_loss is 0.0001132040488300845\n",
      "Iteration 1738: G_loss is 8.133223533630371 and D_loss is 0.0007498973864130676\n",
      "Iteration 1739: G_loss is 9.210211753845215 and D_loss is 0.0036689059343189\n",
      "Iteration 1740: G_loss is 9.347211837768555 and D_loss is 0.00021255455794744194\n",
      "Iteration 1741: G_loss is 9.181570053100586 and D_loss is 0.00027390517061576247\n",
      "Iteration 1742: G_loss is 7.790929317474365 and D_loss is 0.0010598287917673588\n",
      "Iteration 1743: G_loss is 6.5031514167785645 and D_loss is 0.0037394629325717688\n",
      "Iteration 1744: G_loss is 8.1362943649292 and D_loss is 0.001804544823244214\n",
      "Iteration 1745: G_loss is 10.765254020690918 and D_loss is 6.307893636403605e-05\n",
      "Iteration 1746: G_loss is 10.13464641571045 and D_loss is 0.00010766435298137367\n",
      "Iteration 1747: G_loss is 5.9240522384643555 and D_loss is 0.005523438099771738\n",
      "Iteration 1748: G_loss is 9.188411712646484 and D_loss is 0.0009510080562904477\n",
      "Iteration 1749: G_loss is 9.317302703857422 and D_loss is 0.0002212556719314307\n",
      "Iteration 1750: G_loss is 10.41893482208252 and D_loss is 6.406727334251627e-05\n",
      "Iteration 1751: G_loss is 7.148866653442383 and D_loss is 0.0020609120838344097\n",
      "Iteration 1752: G_loss is 7.2699055671691895 and D_loss is 0.0014372769510373473\n",
      "Iteration 1753: G_loss is 8.740873336791992 and D_loss is 0.00033693137811496854\n",
      "Iteration 1754: G_loss is 8.18017292022705 and D_loss is 0.004899369087070227\n",
      "Iteration 1755: G_loss is 11.481639862060547 and D_loss is 0.0001334796688752249\n",
      "Iteration 1756: G_loss is 9.820647239685059 and D_loss is 0.0003013524692505598\n",
      "Iteration 1757: G_loss is 10.35665512084961 and D_loss is 6.6844564571511e-05\n",
      "Iteration 1758: G_loss is 8.475120544433594 and D_loss is 0.0004828466335311532\n",
      "Iteration 1759: G_loss is 7.784203052520752 and D_loss is 0.0008659319719299674\n",
      "Iteration 1760: G_loss is 9.412352561950684 and D_loss is 0.0003172190045006573\n",
      "Iteration 1761: G_loss is 13.567557334899902 and D_loss is 2.5075396479223855e-05\n",
      "Iteration 1762: G_loss is 8.374933242797852 and D_loss is 0.00048130046343430877\n",
      "Iteration 1763: G_loss is 10.022218704223633 and D_loss is 0.00016025450895540416\n",
      "Iteration 1764: G_loss is 12.101142883300781 and D_loss is 3.324598947074264e-05\n",
      "Iteration 1765: G_loss is 10.087570190429688 and D_loss is 0.00010552234016358852\n",
      "Iteration 1766: G_loss is 12.709856986999512 and D_loss is 4.9899153964361176e-05\n",
      "Iteration 1767: G_loss is 7.446962833404541 and D_loss is 0.0014188834466040134\n",
      "Iteration 1768: G_loss is 9.210099220275879 and D_loss is 0.00038573049823753536\n",
      "Iteration 1769: G_loss is 8.166994094848633 and D_loss is 0.000629753340035677\n",
      "Iteration 1770: G_loss is 8.321352005004883 and D_loss is 0.0005357961636036634\n",
      "Iteration 1771: G_loss is 7.77254581451416 and D_loss is 0.0008925650618039072\n",
      "Iteration 1772: G_loss is 5.888068199157715 and D_loss is 0.005740780383348465\n",
      "Iteration 1773: G_loss is 8.45922565460205 and D_loss is 0.0008307832758873701\n",
      "Iteration 1774: G_loss is 8.897692680358887 and D_loss is 0.00028424750780686736\n",
      "Iteration 1775: G_loss is 7.639573574066162 and D_loss is 0.001216332078911364\n",
      "Iteration 1776: G_loss is 9.882833480834961 and D_loss is 0.00010803391342051327\n",
      "Iteration 1777: G_loss is 9.690977096557617 and D_loss is 0.0001447130780434236\n",
      "Iteration 1778: G_loss is 9.065374374389648 and D_loss is 0.0004262194852344692\n",
      "Iteration 1779: G_loss is 11.056746482849121 and D_loss is 3.3162501495098695e-05\n",
      "Iteration 1780: G_loss is 6.731311798095703 and D_loss is 0.002487660152837634\n",
      "Iteration 1781: G_loss is 10.768987655639648 and D_loss is 7.377969450317323e-05\n",
      "Iteration 1782: G_loss is 9.706981658935547 and D_loss is 0.00015258725034072995\n",
      "Iteration 1783: G_loss is 10.352736473083496 and D_loss is 0.00014401061343960464\n",
      "Iteration 1784: G_loss is 8.958762168884277 and D_loss is 0.0003623840748332441\n",
      "Iteration 1785: G_loss is 10.566374778747559 and D_loss is 0.00031158063211478293\n",
      "Iteration 1786: G_loss is 11.261367797851562 and D_loss is 6.28308262093924e-05\n",
      "Iteration 1787: G_loss is 8.707104682922363 and D_loss is 0.0034994673915207386\n",
      "Iteration 1788: G_loss is 9.376396179199219 and D_loss is 0.00030576071003451943\n",
      "Iteration 1789: G_loss is 14.028876304626465 and D_loss is 0.00028647962608374655\n",
      "Iteration 1790: G_loss is 12.972991943359375 and D_loss is 0.0005930516053922474\n",
      "Iteration 1791: G_loss is 11.506281852722168 and D_loss is 9.050454536918551e-05\n",
      "Iteration 1792: G_loss is 10.094913482666016 and D_loss is 0.0009890496730804443\n",
      "Iteration 1793: G_loss is 8.868964195251465 and D_loss is 0.001060854410752654\n",
      "Iteration 1794: G_loss is 12.312324523925781 and D_loss is 0.0010748626664280891\n",
      "Iteration 1795: G_loss is 8.746594429016113 and D_loss is 0.000693810055963695\n",
      "Iteration 1796: G_loss is 9.922306060791016 and D_loss is 0.016083378344774246\n",
      "Iteration 1797: G_loss is 10.482612609863281 and D_loss is 7.066840043989941e-05\n",
      "Iteration 1798: G_loss is 11.750967979431152 and D_loss is 4.639266990125179e-05\n",
      "Iteration 1799: G_loss is 9.849143028259277 and D_loss is 0.0006656459299847484\n",
      "Iteration 1800: G_loss is 9.915534973144531 and D_loss is 0.00020883175602648407\n",
      "Iteration 1801: G_loss is 10.847999572753906 and D_loss is 0.00526398466899991\n",
      "Iteration 1802: G_loss is 5.967872142791748 and D_loss is 0.0053258612751960754\n",
      "Iteration 1803: G_loss is 13.801970481872559 and D_loss is 0.0001223019789904356\n",
      "Iteration 1804: G_loss is 10.734552383422852 and D_loss is 9.883848542813212e-05\n",
      "Iteration 1805: G_loss is 11.618331909179688 and D_loss is 0.000356291770003736\n",
      "Iteration 1806: G_loss is 6.148866176605225 and D_loss is 0.005002839490771294\n",
      "Iteration 1807: G_loss is 8.678373336791992 and D_loss is 0.00041058199713006616\n",
      "Iteration 1808: G_loss is 6.380291938781738 and D_loss is 0.003509189933538437\n",
      "Iteration 1809: G_loss is 7.621798038482666 and D_loss is 0.0010124529944732785\n",
      "Iteration 1810: G_loss is 10.244630813598633 and D_loss is 0.00034159066854044795\n",
      "Iteration 1811: G_loss is 11.2550687789917 and D_loss is 0.00015384945436380804\n",
      "Iteration 1812: G_loss is 13.25644302368164 and D_loss is 4.1579438402550295e-05\n",
      "Iteration 1813: G_loss is 9.42320442199707 and D_loss is 0.00035356672015041113\n",
      "Iteration 1814: G_loss is 11.345229148864746 and D_loss is 0.00026422954397276044\n",
      "Iteration 1815: G_loss is 10.391382217407227 and D_loss is 0.00019946425163652748\n",
      "Iteration 1816: G_loss is 10.32143497467041 and D_loss is 0.00031591049628332257\n",
      "Iteration 1817: G_loss is 9.086995124816895 and D_loss is 0.000273712445050478\n",
      "Iteration 1818: G_loss is 8.487886428833008 and D_loss is 0.000518192071467638\n",
      "Iteration 1819: G_loss is 12.4362154006958 and D_loss is 4.3575513700488955e-05\n",
      "Iteration 1820: G_loss is 11.932953834533691 and D_loss is 0.00039560196455568075\n",
      "Iteration 1821: G_loss is 9.155073165893555 and D_loss is 0.0002466977166477591\n",
      "Iteration 1822: G_loss is 8.528791427612305 and D_loss is 0.0005032630870118737\n",
      "Iteration 1823: G_loss is 7.1903886795043945 and D_loss is 0.0015579024329781532\n",
      "Iteration 1824: G_loss is 11.387101173400879 and D_loss is 0.0002216276479884982\n",
      "Iteration 1825: G_loss is 8.839387893676758 and D_loss is 0.0007066664984449744\n",
      "Iteration 1826: G_loss is 9.098793029785156 and D_loss is 0.0015988132217898965\n",
      "Iteration 1827: G_loss is 9.903447151184082 and D_loss is 0.0003152230638079345\n",
      "Iteration 1828: G_loss is 10.464836120605469 and D_loss is 7.200414984254166e-05\n",
      "Iteration 1829: G_loss is 12.726510047912598 and D_loss is 0.0003304166020825505\n",
      "Iteration 1830: G_loss is 8.932595252990723 and D_loss is 0.00032277655554935336\n",
      "Iteration 1831: G_loss is 10.940592765808105 and D_loss is 0.0006368275498971343\n",
      "Iteration 1832: G_loss is 10.721656799316406 and D_loss is 0.00016609129670541734\n",
      "Iteration 1833: G_loss is 8.59501838684082 and D_loss is 0.0005703836213797331\n",
      "Iteration 1834: G_loss is 6.491583824157715 and D_loss is 0.010997948236763477\n",
      "Iteration 1835: G_loss is 9.42444896697998 and D_loss is 0.00018359185196459293\n",
      "Iteration 1836: G_loss is 5.5624918937683105 and D_loss is 0.007995514199137688\n",
      "Iteration 1837: G_loss is 7.258016586303711 and D_loss is 0.0015131131513044238\n",
      "Iteration 1838: G_loss is 7.58477258682251 and D_loss is 0.001176821650005877\n",
      "Iteration 1839: G_loss is 8.731634140014648 and D_loss is 0.0005946934106759727\n",
      "Iteration 1840: G_loss is 9.22182846069336 and D_loss is 0.0003472644602879882\n",
      "Iteration 1841: G_loss is 9.969898223876953 and D_loss is 0.00022065421217121184\n",
      "Iteration 1842: G_loss is 8.535545349121094 and D_loss is 0.0008364224922843277\n",
      "Iteration 1843: G_loss is 12.097527503967285 and D_loss is 3.512750845402479e-05\n",
      "Iteration 1844: G_loss is 10.17648983001709 and D_loss is 0.00037791000795550644\n",
      "Iteration 1845: G_loss is 10.646352767944336 and D_loss is 0.00013052807480562478\n",
      "Iteration 1846: G_loss is 10.966207504272461 and D_loss is 5.794948810944334e-05\n",
      "Iteration 1847: G_loss is 10.033921241760254 and D_loss is 0.00014222801837604493\n",
      "Iteration 1848: G_loss is 10.688544273376465 and D_loss is 0.0005645478377118707\n",
      "Iteration 1849: G_loss is 7.049676418304443 and D_loss is 0.0019759065471589565\n",
      "Iteration 1850: G_loss is 8.224757194519043 and D_loss is 0.0006247795536182821\n",
      "Iteration 1851: G_loss is 5.8648576736450195 and D_loss is 0.005992237012833357\n",
      "Iteration 1852: G_loss is 8.3823881149292 and D_loss is 0.0005152976955287158\n",
      "Iteration 1853: G_loss is 9.702291488647461 and D_loss is 0.00013745398609898984\n",
      "Iteration 1854: G_loss is 10.41098403930664 and D_loss is 0.00022235520009417087\n",
      "Iteration 1855: G_loss is 9.825974464416504 and D_loss is 0.00016310966748278588\n",
      "Iteration 1856: G_loss is 10.123845100402832 and D_loss is 0.00034132576547563076\n",
      "Iteration 1857: G_loss is 6.656960964202881 and D_loss is 0.005517870187759399\n",
      "Iteration 1858: G_loss is 11.929715156555176 and D_loss is 2.196806963183917e-05\n",
      "Iteration 1859: G_loss is 8.597118377685547 and D_loss is 0.00043237462523393333\n",
      "Iteration 1860: G_loss is 11.293329238891602 and D_loss is 9.434161620447412e-05\n",
      "Iteration 1861: G_loss is 13.830190658569336 and D_loss is 1.9446053556748666e-05\n",
      "Iteration 1862: G_loss is 9.388259887695312 and D_loss is 0.00018381085828877985\n",
      "Iteration 1863: G_loss is 8.089786529541016 and D_loss is 0.0008239882881753147\n",
      "Iteration 1864: G_loss is 9.072781562805176 and D_loss is 0.0002736126189120114\n",
      "Iteration 1865: G_loss is 12.572797775268555 and D_loss is 0.00024527907953597605\n",
      "Iteration 1866: G_loss is 10.008146286010742 and D_loss is 0.0001613256463315338\n",
      "Iteration 1867: G_loss is 14.724433898925781 and D_loss is 2.143976053048391e-05\n",
      "Iteration 1868: G_loss is 11.082630157470703 and D_loss is 0.0020629095379263163\n",
      "Iteration 1869: G_loss is 9.664657592773438 and D_loss is 0.00014899800589773804\n",
      "Iteration 1870: G_loss is 13.814525604248047 and D_loss is 0.0002480662369634956\n",
      "Iteration 1871: G_loss is 7.976247787475586 and D_loss is 0.0007183573325164616\n",
      "Iteration 1872: G_loss is 8.004841804504395 and D_loss is 0.024385415017604828\n",
      "Iteration 1873: G_loss is 8.958395004272461 and D_loss is 0.0006464029429480433\n",
      "Iteration 1874: G_loss is 12.0164155960083 and D_loss is 7.336635462706909e-05\n",
      "Iteration 1875: G_loss is 10.842185020446777 and D_loss is 4.196297231828794e-05\n",
      "Iteration 1876: G_loss is 9.613362312316895 and D_loss is 0.00022392033133655787\n",
      "Iteration 1877: G_loss is 9.915162086486816 and D_loss is 0.0015353626804426312\n",
      "Iteration 1878: G_loss is 5.406017780303955 and D_loss is 0.02023664303123951\n",
      "Iteration 1879: G_loss is 8.982675552368164 and D_loss is 0.00039050247869454324\n",
      "Iteration 1880: G_loss is 6.741241455078125 and D_loss is 0.0025255652144551277\n",
      "Iteration 1881: G_loss is 11.202362060546875 and D_loss is 3.458874562056735e-05\n",
      "Iteration 1882: G_loss is 13.348613739013672 and D_loss is 0.00014250072126742452\n",
      "Iteration 1883: G_loss is 9.524324417114258 and D_loss is 0.0007987656863406301\n",
      "Iteration 1884: G_loss is 9.023249626159668 and D_loss is 0.0003557592863216996\n",
      "Iteration 1885: G_loss is 9.71143627166748 and D_loss is 0.00017911662871483713\n",
      "Iteration 1886: G_loss is 7.600654125213623 and D_loss is 0.0010633511701598763\n",
      "Iteration 1887: G_loss is 7.002121448516846 and D_loss is 0.001945418305695057\n",
      "Iteration 1888: G_loss is 9.376102447509766 and D_loss is 0.00017698833835311234\n",
      "Iteration 1889: G_loss is 9.33337116241455 and D_loss is 0.00023088970920071006\n",
      "Iteration 1890: G_loss is 5.718292236328125 and D_loss is 0.006896461825817823\n",
      "Iteration 1891: G_loss is 9.888655662536621 and D_loss is 0.00040144415106624365\n",
      "Iteration 1892: G_loss is 8.686209678649902 and D_loss is 0.0003690448356792331\n",
      "Iteration 1893: G_loss is 8.12348747253418 and D_loss is 0.0007331179222092032\n",
      "Iteration 1894: G_loss is 9.305294036865234 and D_loss is 0.003407076233997941\n",
      "Iteration 1895: G_loss is 11.198140144348145 and D_loss is 0.0001307140482822433\n",
      "Iteration 1896: G_loss is 9.992170333862305 and D_loss is 0.0004860167682636529\n",
      "Iteration 1897: G_loss is 9.769298553466797 and D_loss is 0.00014301382179837674\n",
      "Iteration 1898: G_loss is 11.241276741027832 and D_loss is 2.8885153369628824e-05\n",
      "Iteration 1899: G_loss is 7.634134769439697 and D_loss is 0.0010128571884706616\n",
      "Iteration 1900: G_loss is 9.776028633117676 and D_loss is 0.000187539350008592\n",
      "Iteration 1901: G_loss is 10.121854782104492 and D_loss is 8.517712558386847e-05\n",
      "Iteration 1902: G_loss is 8.890602111816406 and D_loss is 0.00029972067568451166\n",
      "Iteration 1903: G_loss is 9.778770446777344 and D_loss is 0.00034310846240259707\n",
      "Iteration 1904: G_loss is 8.336587905883789 and D_loss is 0.0005109278135932982\n",
      "Iteration 1905: G_loss is 8.974535942077637 and D_loss is 0.00029994966462254524\n",
      "Iteration 1906: G_loss is 11.002192497253418 and D_loss is 5.331010470399633e-05\n",
      "Iteration 1907: G_loss is 10.54736042022705 and D_loss is 0.00013004415086470544\n",
      "Iteration 1908: G_loss is 7.699764728546143 and D_loss is 0.001054466818459332\n",
      "Iteration 1909: G_loss is 13.47249984741211 and D_loss is 1.2391135896905325e-05\n",
      "Iteration 1910: G_loss is 9.041893005371094 and D_loss is 0.000268374482402578\n",
      "Iteration 1911: G_loss is 9.565970420837402 and D_loss is 0.00020113182836212218\n",
      "Iteration 1912: G_loss is 6.9568915367126465 and D_loss is 0.0034677539952099323\n",
      "Iteration 1913: G_loss is 10.168920516967773 and D_loss is 0.00011470764002297074\n",
      "Iteration 1914: G_loss is 10.913910865783691 and D_loss is 4.275578248780221e-05\n",
      "Iteration 1915: G_loss is 10.918185234069824 and D_loss is 0.00030944039463065565\n",
      "Iteration 1916: G_loss is 10.69544792175293 and D_loss is 9.611373388906941e-05\n",
      "Iteration 1917: G_loss is 11.005202293395996 and D_loss is 3.827834007097408e-05\n",
      "Iteration 1918: G_loss is 7.670950889587402 and D_loss is 0.0010854466818273067\n",
      "Iteration 1919: G_loss is 13.209237098693848 and D_loss is 1.7478872905485332e-05\n",
      "Iteration 1920: G_loss is 8.83071231842041 and D_loss is 0.00037608412094414234\n",
      "Iteration 1921: G_loss is 11.803650856018066 and D_loss is 0.00011688014637911692\n",
      "Iteration 1922: G_loss is 9.171815872192383 and D_loss is 0.00024225142260547727\n",
      "Iteration 1923: G_loss is 9.391462326049805 and D_loss is 0.0001897527981782332\n",
      "Iteration 1924: G_loss is 13.012608528137207 and D_loss is 0.00018629187252372503\n",
      "Iteration 1925: G_loss is 11.039993286132812 and D_loss is 0.0005552718648687005\n",
      "Iteration 1926: G_loss is 12.729628562927246 and D_loss is 0.00012272161256987602\n",
      "Iteration 1927: G_loss is 9.552092552185059 and D_loss is 0.0003394255763851106\n",
      "Iteration 1928: G_loss is 8.363357543945312 and D_loss is 0.0012227335246279836\n",
      "Iteration 1929: G_loss is 9.162795066833496 and D_loss is 0.00023287665680982172\n",
      "Iteration 1930: G_loss is 8.360928535461426 and D_loss is 0.0030265781097114086\n",
      "Iteration 1931: G_loss is 11.671855926513672 and D_loss is 0.00010563696559984237\n",
      "Iteration 1932: G_loss is 9.728362083435059 and D_loss is 0.00014126402675174177\n",
      "Iteration 1933: G_loss is 9.56791877746582 and D_loss is 0.0008794976165518165\n",
      "Iteration 1934: G_loss is 9.722176551818848 and D_loss is 0.0001530233130324632\n",
      "Iteration 1935: G_loss is 9.165966033935547 and D_loss is 0.00026083734701387584\n",
      "Iteration 1936: G_loss is 12.651530265808105 and D_loss is 5.3011684940429404e-05\n",
      "Iteration 1937: G_loss is 8.503340721130371 and D_loss is 0.0005610426887869835\n",
      "Iteration 1938: G_loss is 9.19594669342041 and D_loss is 0.0002257555170217529\n",
      "Iteration 1939: G_loss is 11.083330154418945 and D_loss is 0.0008665778441354632\n",
      "Iteration 1940: G_loss is 10.218643188476562 and D_loss is 0.00011215890845051035\n",
      "Iteration 1941: G_loss is 9.251603126525879 and D_loss is 0.00020245820633135736\n",
      "Iteration 1942: G_loss is 10.67800235748291 and D_loss is 0.0001170925606857054\n",
      "Iteration 1943: G_loss is 7.844597816467285 and D_loss is 0.0009181195055134594\n",
      "Iteration 1944: G_loss is 15.565242767333984 and D_loss is 3.009268948517274e-05\n",
      "Iteration 1945: G_loss is 11.05764102935791 and D_loss is 0.00010805686179082841\n",
      "Iteration 1946: G_loss is 9.44202995300293 and D_loss is 0.00017807701078709215\n",
      "Iteration 1947: G_loss is 9.021456718444824 and D_loss is 0.00026187009643763304\n",
      "Iteration 1948: G_loss is 10.184535026550293 and D_loss is 0.00016380773740820587\n",
      "Iteration 1949: G_loss is 9.958924293518066 and D_loss is 0.00011173331586178392\n",
      "Iteration 1950: G_loss is 13.018475532531738 and D_loss is 6.761803888366558e-06\n",
      "Iteration 1951: G_loss is 11.371779441833496 and D_loss is 3.301272226963192e-05\n",
      "Iteration 1952: G_loss is 9.834291458129883 and D_loss is 0.00014916967484168708\n",
      "Iteration 1953: G_loss is 11.260039329528809 and D_loss is 9.099651651922613e-05\n",
      "Iteration 1954: G_loss is 7.471873760223389 and D_loss is 0.0012352055637165904\n",
      "Iteration 1955: G_loss is 11.46351432800293 and D_loss is 8.132390212267637e-05\n",
      "Iteration 1956: G_loss is 8.79687213897705 and D_loss is 0.00040678432560525835\n",
      "Iteration 1957: G_loss is 10.853599548339844 and D_loss is 0.0009520702878944576\n",
      "Iteration 1958: G_loss is 12.397805213928223 and D_loss is 6.060848681954667e-05\n",
      "Iteration 1959: G_loss is 12.305639266967773 and D_loss is 5.5427473853342235e-05\n",
      "Iteration 1960: G_loss is 8.023948669433594 and D_loss is 0.0008195378468371928\n",
      "Iteration 1961: G_loss is 10.660029411315918 and D_loss is 6.774943904019892e-05\n",
      "Iteration 1962: G_loss is 9.522705078125 and D_loss is 0.00027634180150926113\n",
      "Iteration 1963: G_loss is 8.516936302185059 and D_loss is 0.0005811545997858047\n",
      "Iteration 1964: G_loss is 12.334644317626953 and D_loss is 0.0006356711382977664\n",
      "Iteration 1965: G_loss is 7.275418758392334 and D_loss is 0.0014435568591579795\n",
      "Iteration 1966: G_loss is 12.085630416870117 and D_loss is 0.00015705416444689035\n",
      "Iteration 1967: G_loss is 10.800216674804688 and D_loss is 6.162131467135623e-05\n",
      "Iteration 1968: G_loss is 13.50160026550293 and D_loss is 0.00022300053387880325\n",
      "Iteration 1969: G_loss is 5.234516143798828 and D_loss is 0.011289436370134354\n",
      "Iteration 1970: G_loss is 8.576370239257812 and D_loss is 0.0003942402545362711\n",
      "Iteration 1971: G_loss is 10.415122032165527 and D_loss is 0.0005018716328777373\n",
      "Iteration 1972: G_loss is 13.186131477355957 and D_loss is 5.372522718971595e-05\n",
      "Iteration 1973: G_loss is 7.951627731323242 and D_loss is 0.0008769005653448403\n",
      "Iteration 1974: G_loss is 11.090763092041016 and D_loss is 8.770138083491474e-05\n",
      "Iteration 1975: G_loss is 13.425104141235352 and D_loss is 0.000672449532430619\n",
      "Iteration 1976: G_loss is 9.218594551086426 and D_loss is 0.0002450014872010797\n",
      "Iteration 1977: G_loss is 10.146209716796875 and D_loss is 0.00017494833446107805\n",
      "Iteration 1978: G_loss is 13.324725151062012 and D_loss is 4.0630391595186666e-05\n",
      "Iteration 1979: G_loss is 12.09878921508789 and D_loss is 0.00049117038724944\n",
      "Iteration 1980: G_loss is 10.205183029174805 and D_loss is 0.00013287836918607354\n",
      "Iteration 1981: G_loss is 8.650091171264648 and D_loss is 0.0029558674432337284\n",
      "Iteration 1982: G_loss is 9.611347198486328 and D_loss is 0.00037542980862781405\n",
      "Iteration 1983: G_loss is 10.58824634552002 and D_loss is 0.00012265275290701538\n",
      "Iteration 1984: G_loss is 11.339134216308594 and D_loss is 0.00012654006422962993\n",
      "Iteration 1985: G_loss is 8.584647178649902 and D_loss is 0.0005528558394871652\n",
      "Iteration 1986: G_loss is 10.71358585357666 and D_loss is 5.4530613851966336e-05\n",
      "Iteration 1987: G_loss is 10.976133346557617 and D_loss is 4.0742022974882275e-05\n",
      "Iteration 1988: G_loss is 11.41499137878418 and D_loss is 0.002437891438603401\n",
      "Iteration 1989: G_loss is 12.155885696411133 and D_loss is 3.717015715665184e-05\n",
      "Iteration 1990: G_loss is 11.640283584594727 and D_loss is 4.4463129597716033e-05\n",
      "Iteration 1991: G_loss is 13.386946678161621 and D_loss is 6.449593456636649e-06\n",
      "Iteration 1992: G_loss is 11.546936988830566 and D_loss is 6.0254562413319945e-05\n",
      "Iteration 1993: G_loss is 9.39527702331543 and D_loss is 0.0003201406798325479\n",
      "Iteration 1994: G_loss is 10.894768714904785 and D_loss is 0.00030814536148682237\n",
      "Iteration 1995: G_loss is 12.7932767868042 and D_loss is 0.0019406890496611595\n",
      "Iteration 1996: G_loss is 9.859103202819824 and D_loss is 0.00044878001790493727\n",
      "Iteration 1997: G_loss is 10.432936668395996 and D_loss is 7.904220547061414e-05\n",
      "Iteration 1998: G_loss is 7.105916976928711 and D_loss is 0.002015532460063696\n",
      "Iteration 1999: G_loss is 13.187304496765137 and D_loss is 0.00023129000328481197\n",
      "Iteration 2000: G_loss is 8.98601245880127 and D_loss is 0.0003583325305953622\n"
     ]
    }
   ],
   "source": [
    "train_obj = GAN3d(train_input, train_output, iter_num=2000)\n",
    "recon = train_obj.train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = recon.numpy()\n",
    "\n",
    "tifffile.imwrite('/data/3d_test.tiff', recon.reshape((128, 128, 128)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tifffile.imwrite('/data/3d_output.tiff', train_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
